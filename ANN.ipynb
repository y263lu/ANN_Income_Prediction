{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To help you read this notebook, the structure of this notebook is as follows**: \n",
    "\n",
    "\n",
    "Table of Content:\n",
    "- Import Libraries and Load Data\n",
    "- EDA\n",
    "- Model Development\n",
    "    - Baseline Model\n",
    "    - Parameter Tuning (GridSearch)\n",
    "        - Best Performing Model \n",
    "    - Parameter Tuning on a more constrained space (to ovoid having large model variace)\n",
    "    - Final Model\n",
    "- Making Predictions\n",
    "- Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"USCensusTraining.csv\")\n",
    "test_data = pd.read_csv(\"USCensusTest.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable Selection and Covaraince Matrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>demogweight</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  demogweight  education  education-num  \\\n",
       "0   39         State-gov        77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc        83311  Bachelors             13   \n",
       "2   38           Private       215646    HS-grad              9   \n",
       "3   53           Private       234721       11th              7   \n",
       "4   28           Private       338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country  income  \n",
       "0          2174             0              40  United-States  <=50K.  \n",
       "1             0             0              13  United-States  <=50K.  \n",
       "2             0             0              40  United-States  <=50K.  \n",
       "3             0             0              40  United-States  <=50K.  \n",
       "4             0             0              40           Cuba  <=50K.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA1=data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OHE for data\n",
    "##### Observe 0 appearence value and prepare data for box plot and correlation matrics to identify correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA1=data\n",
    "lebal_dict={}\n",
    "for i in EDA1.select_dtypes(['object']):\n",
    "    le=LabelEncoder()\n",
    "    EDA1[i]=le.fit_transform(EDA1[i])\n",
    "    lebal_dict[i]=dict(zip(le.classes_,le.transform(le.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19c147917c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='occupation',y='income',data=EDA1,estimator=sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19c148dd310>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAboklEQVR4nO3de5RdZZnn8e/PACGBRMAUJiZhAnQAIWMHiMg0StMT1ICYgA1NWAiotEEGGm21C5AexZ6VtSQKjt09RIOkuQxXuUjaAbmNQvcaaKhgSMLVAFGqUpUEFUzADiR55o/9Vvqkck7tU3X2uVTq91nrrL33u9/9nKeuz9nvvikiMDMz68+7mp2AmZm1PhcLMzPL5WJhZma5XCzMzCyXi4WZmeXapdkJ1Mu4ceNiypQpzU7DzGxIWbp06WsR0da3factFlOmTKGjo6PZaZiZDSmSflWu3cNQZmaWy8XCzMxyuViYmVkuFwszM8vlYmFmZrlcLMzMLJeLhZmZ5XKxMDOzXHW7KE/SYuAkYF1ETEtttwEHpy57Aa9HxHRJU4DngBfSuscj4gtpmyOB64BRwL3AF8MP4TAbsPb2dnp6ehg/fjwLFixodjo2xNTzCu7rgH8EbuhtiIjTe+clXQm8UdL/pYiYXibOQmAe8DhZsZgF3FeHfM12aj09PXR1dTU7DRui6jYMFRGPAr8tt06SgL8AbukvhqQJwNiIeCztTdwAnFx0rmZm1r9mHbP4CLA2In5Z0ra/pF9IekTSR1LbRKCzpE9najMzswZq1o0Ez2D7vYpuYL+I+E06RvFjSYcBKrNtxeMVkuaRDVmx3377FZiumdnw1vA9C0m7AJ8Cbutti4hNEfGbNL8UeAk4iGxPYlLJ5pOANZViR8SiiJgRETPa2na4w66ZmQ1SM4ahjgeej4htw0uS2iSNSPMHAFOBlyOiG9gg6eh0nONs4J4m5GxmNqzVrVhIugV4DDhYUqekc9Oquex4YPtYYLmkp4E7gC9ERO/B8fOBHwKryPY4fCaUmVmD1e2YRUScUaH9M2Xa7gTurNC/A5hWaHJmO6k5d1T+LPXmxrcAWLPxrX773XPqCYXnZUOfr+A2M7NcLhZmZpbLxcLMzHK5WJiZWS4XCzMzy+ViYWZmuVwszMwsV7PuDWVmDfauMWPZmqZmA+ViYTZMjPrkac1OwYYwD0OZmVkuFwszM8vlYmFmZrlcLMzMLJeLhZmZ5XKxMDOzXC4WZmaWy8XCzMxyuViYmVkuFwszM8vlYmFmZrlcLMzMLFfdioWkxZLWSVpZ0na5pC5Jy9LrxJJ1l0paJekFSR8vaT9S0oq07u8lqV45m5lZefXcs7gOmFWm/bsRMT297gWQdCgwFzgsbXO1pBGp/0JgHjA1vcrFNDOzOqpbsYiIR4HfVtl9DnBrRGyKiFeAVcBRkiYAYyPisYgI4Abg5PpkbGZmlTTjmMWFkpanYaq9U9tE4NWSPp2pbWKa79telqR5kjokdaxfv77ovM3Mhq1GF4uFwIHAdKAbuDK1lzsOEf20lxURiyJiRkTMaGtrqzVXMzNLGlosImJtRGyJiK3ANcBRaVUnMLmk6yRgTWqfVKbdzMwaqKHFIh2D6HUK0Hum1BJgrqSRkvYnO5D9RER0AxskHZ3OgjobuKeROZuZWR2fwS3pFuA4YJykTuAbwHGSppMNJa0GzgOIiGck3Q48C2wGLoiILSnU+WRnVo0C7ksvMzNroLoVi4g4o0zztf30nw/ML9PeAUwrMDUzMxsgX8FtZma5XCzMzCyXi4WZmeVysTAzs1wuFmZmlsvFwszMcrlYmJlZLhcLMzPL5WJhZma56nYFt5nZYLS3t9PT08P48eNZsGBBs9OxxMXCzFpKT08PXV1dzU7D+vAwlJmZ5XKxMDOzXC4WZmaWy8XCzMxyuViYmVkuFwszM8vlYmFmZrl8nYWZNdwVd3dXXPe7jVu2Tfvrd/EpEwrPyyrznoWZmeWqW7GQtFjSOkkrS9q+Lel5Scsl3S1pr9Q+RdIfJC1Lr++XbHOkpBWSVkn6e0mqV85mZlZePfcsrgNm9Wl7EJgWER8AXgQuLVn3UkRMT68vlLQvBOYBU9Orb0wzM6uzuhWLiHgU+G2ftgciYnNafByY1F8MSROAsRHxWEQEcANwcj3yNTOzypp5zOJzwH0ly/tL+oWkRyR9JLVNBDpL+nSmtrIkzZPUIalj/fr1xWdsZjZMNaVYSLoM2AzclJq6gf0i4nDgy8DNksYC5Y5PRKW4EbEoImZExIy2trai0zYzG7YafuqspHOAk4CZaWiJiNgEbErzSyW9BBxEtidROlQ1CVjT2IzNzKyhexaSZgEXA7Mj4q2S9jZJI9L8AWQHsl+OiG5gg6Sj01lQZwP3NDJnM2usUWPHMfrd4xk1dlyzU7ESdduzkHQLcBwwTlIn8A2ys59GAg+mM2AfT2c+HQv8naTNwBbgCxHRe3D8fLIzq0aRHeMoPc5hZjuZI+dc0uwUrIy6FYuIOKNM87UV+t4J3FlhXQcwrcDUzMxsgHwFt5mZ5XKxMDOzXC4WZmaWy8XCzMxyuViYmVkuFwszM8vlYmFmZrlcLMzMLJeLhZmZ5XKxMDOzXC4WZmaWy8XCzMxyuViYmVmuhj/8yMzMGqe9vZ2enh7Gjx/PggULBh3HxcLMbCfW09NDV1dXzXE8DGVmZrmqKhaSDpL0sKSVafkDkv62vqmZmVmrqHbP4hqyR6K+AxARy4G59UrKzMxaS7XFYnREPNGnbXPRyZiZWWuqtli8JulAIAAknQp01y0rMzNrKdWeDXUBsAg4RFIX8Arw6f42kLQYOAlYFxHTUts+wG3AFGA18BcR8bu07lLgXGALcFFE3J/ajwSuA0YB9wJfjIio+is0M9vJrfuHn1Vct+X1P2ybVuq371/9We57VLVnEREvR8TxQBtwSER8OCJW52x2HTCrT9slwMMRMRV4OC0j6VCyYyCHpW2uljQibbMQmAdMTa++Mc3MrM6q2rOQtBdwNtkewS6SAIiIiyptExGPSprSp3kOcFyavx74OXBxar81IjYBr0haBRwlaTUwNiIeS3ncAJwM3FdN3mZmVoxqh6HuBR4HVgBba3i/90ZEN0BEdEvaN7VPTPF7daa2d9J83/ayJM0j2wthv/32qyFNMzMrVW2x2D0ivlzHPFSmLfppLysiFpEdW2HGjBk+rmFmVpBqz4a6UdLnJU2QtE/vaxDvt1bSBIA0XZfaO4HJJf0mAWtS+6Qy7WZm1kDVFou3gW8DjwFL06tjEO+3BDgnzZ8D3FPSPlfSSEn7kx3IfiINWW2QdLSyAyVnl2xjZmYNUu0w1JeBP4qI16oNLOkWsoPZ4yR1At8AvgXcLulc4NfAaQAR8Yyk24FnyS72uyAitqRQ5/Mfp87ehw9um5k1XLXF4hngrYEEjogzKqyaWaH/fGB+mfYOYNpA3tvMzDJto9+93XSwqi0WW4Blkn4GbOpt7O/UWTMza76vHXNmIXGqLRY/Ti8zMxuGqioWEXG9pN2Ag1LTCxHxTv3SMjOzVlLtFdzHkV1xvZrs2ofJks6JiEfrl5qZmbWKaoehrgQ+FhEvQPYwJOAW4Mh6JWZmZq2j2ussdu0tFAAR8SKwa31SMjOzVlPtnkWHpGuBG9PymWQX5pmZ2TBQbbE4n+yZFheRHbN4FLi6XkmZmVlrqbZY7AJ8LyKuAkjPmhhZt6zMzKylVHvM4mGy2230GgU8VHw6ZmbWiqotFrtHxMbehTQ/uj4pmZlZq6m2WLwp6YjehfRc7D/UJyUzM2s11R6z+BLwI0m9z5KYAJxen5TMzKzVVHu7jyclHQIcTHY21PO+3YeZ2fBR7Z4FwAeBKWmbwyURETfUJSszM2sp1d4b6kbgQGAZ2e3KIXsWtouFmdkwUO2exQzg0IiIeiZjZmatqdqzoVYC4+uZiJmZta5q9yzGAc9KeoLtn5Q3uy5ZmZlZS6m2WFxezyTMzKy1VXvq7CNFvaGkg4HbSpoOAL4O7AV8Hlif2r8WEfembS4FziU7uH5RRNxfVD5mZpav32Ih6V8j4sOSNpCd/bRtFRARMXagb5ieizE9xR8BdAF3A58FvhsR3+mTw6HAXOAw4H3AQ5IOiogtmJlVob29nZ6eHsaPH8+CBQuanc6Q1G+xiIgPp+mYOr3/TOCliPiVpEp95gC3RsQm4BVJq4CjgMfqlJOZ7WR6enro6upqdhpDWrVnQ9XLXLLHs/a6UNJySYsl7Z3aJgKvlvTpTG07kDRPUoekjvXr15frYmZmg9C0YiFpN2A28KPUtJDswr/pQDfZc78hG/Lqq+z1HhGxKCJmRMSMtra2gjM2Mxu+mrlncQLwVESsBYiItRGxJSK2AteQDTVBticxuWS7ScAazMysYQZyb6iinUHJEJSkCRHRnRZPIbsQEGAJcLOkq8gOcE8FnmhkombW+u677bWK697auHXbtL9+J5w+rvC8dhZNKRaSRgMfBc4raV4gaTrZENPq3nUR8Yyk24Fngc3ABT4TysyssZpSLCLiLeA9fdrO6qf/fGB+vfMyM7Pymn02lJmZDQHNPGZhZtYQY/ds225qA+diYWY7vdM+cVmzUxjyPAxlZma5XCzMzCyXi4WZmeVysTAzs1wuFmZmlsvFwszMcrlYmJlZLhcLMzPL5WJhZma5XCzMzCyXi4WZmeVysTAzs1wuFmZmlsvFwszMcrlYmJlZLhcLMzPL5WJhZma5mlIsJK2WtELSMkkdqW0fSQ9K+mWa7l3S/1JJqyS9IOnjzcjZzGw4a+aexZ9FxPSImJGWLwEejoipwMNpGUmHAnOBw4BZwNWSRjQjYTOz4aqVhqHmANen+euBk0vab42ITRHxCrAKOKoJ+ZmZDVvNKhYBPCBpqaR5qe29EdENkKb7pvaJwKsl23amth1ImiepQ1LH+vXr65S6mdnws0uT3veYiFgjaV/gQUnP99NXZdqiXMeIWAQsApgxY0bZPmZmNnBN2bOIiDVpug64m2xYaa2kCQBpui517wQml2w+CVjTuGzNzKzhxULSHpLG9M4DHwNWAkuAc1K3c4B70vwSYK6kkZL2B6YCTzQ2azOz4a0Zw1DvBe6W1Pv+N0fETyU9Cdwu6Vzg18BpABHxjKTbgWeBzcAFEbGlCXmbmQ1bDS8WEfEy8Mdl2n8DzKywzXxgfp1TMzOzClrp1FkzM2tRLhZmZpbLxcLMzHK5WJiZWS4XCzMzy+ViYWZmuVwszMwsl4uFmZnlcrEwM7NcLhZmZpbLxcLMzHK5WJiZWS4XCzMzy9WsJ+WZmVkf7e3t9PT0MH78eBYsWNDsdLbjYmFm1iJ6enro6upqdhpleRjKzMxyec/CzKyBeq58vuK6Lb97Z9u0Ur/xXzmkLnnlcbEwa1GtPH5tw4+LhVmLauXxaxt+XCzMzFrEuNH7bDdtJQ0vFpImAzcA44GtwKKI+J6ky4HPA+tT169FxL1pm0uBc4EtwEURcX+j8zYzq7dLj/qrZqdQUTP2LDYDX4mIpySNAZZKejCt+25EfKe0s6RDgbnAYcD7gIckHRQRWxqatVnBTrrjpn7X//vGDQCs2bihYt+fnHpm4XmZldPwU2cjojsinkrzG4DngIn9bDIHuDUiNkXEK8Aq4Kj6Z2pmZr2aep2FpCnA4cC/paYLJS2XtFjS3qltIvBqyWad9F9czKxB2tvbOfvss2lvb292KlZnTSsWkvYE7gS+FBG/BxYCBwLTgW7gyt6uZTaPCjHnSeqQ1LF+/fpyXcysQL1nbPX09DQ7FauzphQLSbuSFYqbIuIugIhYGxFbImIrcA3/MdTUCUwu2XwSsKZc3IhYFBEzImJGW1tb/b4AswbQmD3Ru8eiMXs2OxWzppwNJeBa4LmIuKqkfUJEdKfFU4CVaX4JcLOkq8gOcE8Fnmhgyma56nEB3chPziokTq1OvfOpiuve2LgJgO6Nm/rtd8efH1F4XtZYzTgb6hjgLGCFpGWp7WvAGZKmkw0xrQbOA4iIZyTdDjxLdibVBT4TylqNL6CznV3Di0VE/Cvlj0Pc288284H5dUvKzMz65Su4zarwibv+od/1mza+DsCaja9X7Pt/PtW6F1wN1rvG7L3d1HZeLhZmNmhjZs9rdgrWIH6ehZmZ5XKxMDOzXB6GMiuAxo7ebmq2s3GxMCvAbrOPaXYKZnXlYSgzM8vlYmFmZrlcLMzMLJeLhZmZ5XKxMDOzXC4WZmaWy8XCzMxyuViYmVkuFwszM8s1rK/grsfTzeoR08ys2YZ1sajH0838xDQz2xnt9MVi/cL/XXHdljc2bJv216/t/E8XnpeZ2VCy0xeLeui++uKK67a88dq2aaV+E/7bFXXJa2fkYT2z1uBiMQQM53+Y9RjWG87fT7PBGtbFom30nttNizBu9MjtpkXYmY+DXHzHrH7Xv7bxnTTtqtj3ilN/OqD33Jm/n2b1MmSKhaRZwPeAEcAPI+Jbtca87NiP15xXX5d85KBBbffkDz5Zcd2mN/6Qpmsq9vvgef88qPctUqt8Yj/xx1/pd/3bb2ZDhWvefK1i33tPvrLwvMyGsiFRLCSNAP4X8FGgE3hS0pKIeLa5mQ1d9fjHXo9P7CPHCIg0NbNmGRLFAjgKWBURLwNIuhWYAwyLYrH3HtpuWq17Fp9Qcd1LL77N6xvgzd93Vew353P3bbf8gxv73xN7Y8PmNO2q2Pe8s+7vN0ZfB32yDr+iY3ZDaWpm1VFENDuHXJJOBWZFxF+m5bOAD0XEhX36zQPmpcWDgReqCD8OeK3AdB3TMVs55lDI0TGbG/M/RURb38ahsmdR7iP1DlUuIhYBiwYUWOqIiBmDTcwxHXMoxRwKOTpma8YcKveG6gQmlyxPAtY0KRczs2FnqBSLJ4GpkvaXtBswF1jS5JzMzIaNITEMFRGbJV0I3E926uziiHimoPADGrZyTMcc4jGHQo6O2YIxh8QBbjMza66hMgxlZmZN5GJhZma5hnWxkDRL0guSVkm6pIB4iyWtk7SyiPxSzMmSfibpOUnPSPpijfF2l/SEpKdTvG8WmOsISb+Q9JOC4q2WtELSMkkdBcXcS9Idkp5P39P/UmO8g1N+va/fS/pSAXn+dfr5rJR0i6TdC4j5xRTvmcHmWO53XNI+kh6U9Ms03buAmKelPLdKGvApnxVifjv93JdLulvSXgXE/B8p3jJJD0h6X60xS9Z9VVJIGldAnpdL6ir5PT1xIDEBiIhh+SI7UP4ScACwG/A0cGiNMY8FjgBWFpjnBOCIND8GeLGWPMmuWdkzze8K/BtwdEG5fhm4GfhJQfFWA+MK/rlfD/xlmt8N2Kvg36kesouaaokzEXgFGJWWbwc+U2PMacBKYDTZiS0PAVMHEWeH33FgAXBJmr8EuKKAmO8nu7D258CMgvL8GLBLmr+ioDzHlsxfBHy/1pipfTLZCT2/GujfQIU8Lwe+Wsvv0HDes9h2C5GIeBvovYXIoEXEo8Bvi0iuJGZ3RDyV5jcAz5H9MxlsvIiIjWlx1/Sq+SwHSZOATwA/rDVWvUgaS/aHdC1ARLwdEa8X+BYzgZci4lcFxNoFGCVpF7J/8LVeV/R+4PGIeCsiNgOPAKcMNEiF3/E5ZEWYND251pgR8VxEVHMHhoHEfCB97QCPk12vVWvM35cs7sEA/5b6+Z/xXaB9oPFyYtZkOBeLicCrJcud1PBPuBEkTQEOJ9sbqCXOCEnLgHXAgxFRU7zkf5L9cm8tIFavAB6QtDTdyqVWBwDrgX9Kw2U/lLRHAXF7zQVuqTVIRHQB3wF+DXQDb0TEAzWGXQkcK+k9kkYDJ7L9ha61eG9EdEP24QbYt6C49fQ54L7cXlWQNF/Sq8CZwNcLiDcb6IqIp2tObnsXpiGzxQMdKoThXSyquoVIq5C0J3An8KU+n2YGLCK2RMR0sk9WR0maVmNuJwHrImJpLXHKOCYijgBOAC6QdGyN8XYh2z1fGBGHA2+SDZvULF0sOhv4UQGx9ib7tL4/8D5gD0k1Pds3Ip4jG3p5EPgp2bDr5n432klJuozsa7+piHgRcVlETE7xLszrn5PbaOAyCig6fSwEDgSmk30AGfA9+IdzsRgytxCRtCtZobgpIu4qKm4agvk50P8TiPIdA8yWtJpsOO+/Sqr8UPMqRcSaNF0H3E02dFiLTqCzZE/qDrLiUYQTgKciYm0BsY4HXomI9RHxDnAX8Ce1Bo2IayPiiIg4lmyY4pe1xkzWSpoAkKbrCopbOEnnACcBZ0YazC/QzcCf1xjjQLIPCU+nv6dJwFOSxtcSNCLWpg+JW4FrGMTf0nAuFkPiFiKSRDbG/lxEXFVAvLbes0AkjSL7x/R8LTEj4tKImBQRU8i+j/83Imr6JCxpD0ljeufJDk7WdJZZRPQAr0o6ODXNpLjb3J9BAUNQya+BoyWNTj//mWTHqmoiad803Q/4FMXluwQ4J82fA9xTUNxCKXuA2sXA7Ih4q6CYU0sWZ1P739KKiNg3Iqakv6dOshNcemqJ21vMk1MYzN9SLUfHh/qLbNz2RbKzoi4rIN4tZLt476Qf8rkFxPww2fDYcmBZep1YQ7wPAL9I8VYCXy/4e3ocBZwNRXZ84en0eqaIn0+KOx3oSF//j4G9C4g5GvgN8O4Cv4/fJPvHsxK4ERhZQMx/ISuOTwMzBxljh99x4D3Aw2R7Kg8D+xQQ85Q0vwlYC9xfQMxVZMcpe/+OBnrmUrmYd6af0XLgn4GJtcbss341Az8bqlyeNwIrUp5LgAkD/dn7dh9mZpZrOA9DmZlZlVwszMwsl4uFmZnlcrEwM7NcLhZmZpbLxcJsECR9RtI/FhzzZEmHliz/naTji3wPs8FysTBrHScD24pFRHw9Ih5qYj5m27hYmJUh6dPKnvuxTNIP0s0XPyvpRUmPkN3ipLfvdZJOLVneWDLfruyZHE9L+lZq+7ykJ1PbnelK7T8huwL42+k9DyyNK2lmuvnhinQjuJGpfbWkb0p6Kq07pEHfIhtmXCzM+pD0fuB0shsZTge2AJ8mu6r6GOCjlOwB9BPnBLK9hQ9FxB+TPfcB4K6I+GBqe47sqt3/R3Zl7d9ExPSIeKkkzu7AdcDpEfGfyW6IeH7JW70W2Q0XFwJfHfxXblaZi4XZjmYCRwJPplu5zwT+Gvh5ZDf3exu4rYo4xwP/FOk+RBHR+4yBaZL+RdIKsttaH5YT52CyGwu+mJavJ3suR6/em0suBaZUkZfZgLlYmO1IwPXpE/70iDiY7Eljle6Ns5n0t5Ru/LdbSZxy21wHXJj2Er4J5D0ytdzt9EttStMtZHsdZoVzsTDb0cPAqSV3ad2H7OaLx6WHB+0KnFbSfzXZnghkz6HYNc0/AHwuPaOgNw5kj8ftTnHOLImzIa3r63lgiqQ/SstnkT3pzqxhXCzM+oiIZ4G/JXtK33KyBwZNINu7eIzs+dVPlWxyDfCnkp4APkT2UCUi4qdkxyE60nBW7/GE/072tMMH2f6W1rcCf5MOZB9Yks+/A58FfpSGrrYC3y/yazbL47vOmplZLu9ZmJlZLhcLMzPL5WJhZma5XCzMzCyXi4WZmeVysTAzs1wuFmZmluv/A6As7QoLQHzNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='education',y='income',data=EDA1,estimator=sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAIWCAYAAACFuNqGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5hsZ10n+u+bK7nsQDAJHQENegAFD4MYGD04Eo3DPQkh4TYKqDhRAQFBG5CZAz4Oc7A96ODMoBMFRUYRTAhgQK6KHD0gBIwxgCAjEdI7RcIll07IbfPOH1V707X3WqtqX+qyuj+f5+ln9ar1vvX+Vv/6ra5fr0uVWmsAAACgTw5bdAAAAACwvxSzAAAA9I5iFgAAgN5RzAIAANA7ilkAAAB6RzELAABA7xyx6AAOxkknnVRPO+20RYcBAADADHz84x//cq315KZtvS5mTzvttFx22WWLDgMAAIAZKKX8S9s2pxkDAADQO4pZAAAAekcxCwAAQO8oZgEAAOgdxSwAAAC9o5gFAACgdxSzAAAA9I5iFgAAgN5RzAIAANA7ilkAAAB6RzELAABA7yhmAQAA6B3FLAAAAL2jmAUAAKB3FLMAAAD0jmIWAACA3lHMAgAA0DuKWQAAAHpHMQsAAEDvKGYBAADonSMWHQDA/lhdXc1gMMjKykrW1tYWHQ4AAAuimAV6ZTAYZH19fdFhAACwYE4zBgAAoHcUswAAAPSOYhYAAIDeUcwCAADQO4pZAAAAekcxCwAAQO8oZgEAAOgdxSwAAAC9o5gFAACgdxSzAAAA9I5iFgAAgN5RzAIAANA7ilkAAAB6Z2bFbCnl3qWUvyylfLqU8slSyvNHj7+ilLJeSrl89PXYTX1eWkr5XCnlM6WUR80qNgAAAPrtiBk+951JXlRr/UQpZUeSj5dS3jfa9pu11v93c+NSygOSPDXJA5N8a5L3l1LuV2vdNcMYAQAA6KGZHZmttV5Ta/3E6Pubknw6yT07upyT5E9qrbfVWj+f5HNJHjar+AAAAOivuVwzW0o5Lcn3Jvnb0UPPLaVcUUp5fSnlxNFj90zyxU3drk538QsAAMA2NfNitpRyfJKLk7yg1npjkt9O8p1JHpzkmiSv3t20oXtteL4LSimXlVIuu+6662YUNQAAAMtspsVsKeXIDAvZP6q1vjVJaq1fqrXuqrV+I8nv5punEl+d5N6but8ryc69n7PWemGt9fRa6+knn3zyLMMHAABgSc3ybsYlyeuSfLrW+hubHj91U7Nzk1w5+v4dSZ5aSjm6lHKfJPdN8tFZxQcAAEB/zfJuxg9P8vQk/1BKuXz02C8neVop5cEZnkJ8VZKfSZJa6ydLKW9J8qkM74T8HHcyBgAAoMnMitla61+n+TrYd3X0eWWSV84qJgAWZ3V1NYPBICsrK1lbW1t0OABAz83yyCwA7DEYDLK+vr7oMACALUIxC4CjpgBA7yhmAXDUFADonZl/ziwAAAAcaopZAAAAekcxCwAAQO+4ZhZgEzdCAgDoB8UswCZuhAQA0A+KWQCWliPlAEAbxSwAS8uRcgCgjRtAAQAA0DuKWQAAAHrHacYAc+Y6UACAg6eYBZgz14ECABw8pxkDAADQO4pZAAAAekcxCwAAQO8oZgEAAOgdxSwAAAC9427GABwQHzEEACySYhaAA+IjhgCARXKaMQAAAL2jmAUAAKB3nGYMLLVXv+lRY+tfu+nO0XJ9z7YXPe09c48LAIDFUswCbEFuzgQAbHWKWYAtyM2ZAICtzjWzAAAA9I5iFgAAgN5xmjGwpbl2FABga1LMAluaa0cBALYmpxkDAADQO47MAvSA06UBAMYpZgF6wOnSAADjnGYMAABA7yhmAQAA6B3FLAAAAL2jmAUAAKB3FLMAAAD0jmIWAACA3lHMAgAA0Ds+ZxbgIK2urmYwGGRlZSVra2uLDmdpPPaSV46t377x1STJzo2vjm1717kvm2tcAMDWoJgFOEiDwSDr6+uLDgMAYFtRzAIL44gmAAAHSjELLIwjmgAAHCjFLADsB2cUAMByUMwCbEOPfduLxtZvv/nLSZKdN395bNu7nvDqucbVB84oAIDl4KN5AAAA6B3FLAAAAL2jmAUAAKB3XDMLbGv/4U8fPbb+lY07Rsv1sW3/6Unvnmtc29XjLvn1sfXbNr6WJNm58bU929557i/NPS4AYPk4MgsAAEDvKGYBAADoHcUsAAAAvaOYBQAAoHcUswAAAPSOYhYAAIDe8dE8ADP2k5eMf/zPl0Yf//OljfWxbb9/ro//AQCYliOzAAAA9I4jswBM5bFv+49j67ff/JUkyc6bvzK27V1P+NW5xgUAbE+OzAIAANA7ilkAAAB6RzELAABA7yhmAQAA6B3FLAAAAL2jmAUAAKB3FLMAAAD0js+ZBXrl2B0lSR0t2e0xb//3Y+u333xtkmT95mvHtv35Ob8717gAAGZFMQv0ysMec/iiQwAAYAkoZoEt5ZVvftTY+lc37hwt18e2vewp75lrXAAAHFqumQUAAKB3FLMAAAD0jmIWAACA3lHMAgAA0DuKWQAAAHpHMQsAAEDv+GgegCX0mHc8fmz99ptvTZKs37xzz7Y/P/vSuccFALAsHJkFAACgdxSzAAAA9I5iFgAAgN5RzAIAANA7bgAFwHyccJeU0RIA4GDNrJgtpdw7yR8mWUnyjSQX1lpfU0q5e5I3JzktyVVJnlxr/dqoz0uTPCvJriTPq7W+Z1bxATBfR53zvYsOAQDYQmZ5ZPbOJC+qtX6ilLIjycdLKe9L8hNJPlBrfVUp5SVJXpLkxaWUByR5apIHJvnWJO8vpdyv1rprhjECwEytrq5mMBhkZWUla2triw4HALaMmRWztdZrklwz+v6mUsqnk9wzyTlJzhg1e0OSDyZ58ejxP6m13pbk86WUzyV5WJIPzypGoJ034O1+4eJHj61ft3HHaLk+tu03z3v3XONiOQ0Gg6yvry86DADYcuZyzWwp5bQk35vkb5PcY1ToptZ6TSnllFGzeyb5yKZuV48e2/u5LkhyQZJ827d92+yChm1uFm/A/+sfPWps/fqb7hwt18e2/fyPucKA5fG4iy8cW79t44Ykyc6NG8a2vfO8C+YaFwBsdzO/m3Ep5fgkFyd5Qa31xq6mDY/VfR6o9cJa6+m11tNPPvnkQxUmwPa246iUux2d7Dhq0ZEAAExlpkdmSylHZljI/lGt9a2jh79USjl1dFT21CTXjh6/Osm9N3W/V5Kds4wPgKGjnvCdiw4BAGC/zOzIbCmlJHldkk/XWn9j06Z3JHnm6PtnJnn7psefWko5upRynyT3TfLRWcUHAABAf83yyOzDkzw9yT+UUi4fPfbLSV6V5C2llGcl+UKSJyVJrfWTpZS3JPlUhndCfo47GQMAANBklncz/us0XwebJGe29HllklfOKiYAAAC2hpnfAAoAAAAONcUsAAAAvTOXz5kFtofV1dUMBoOsrKxkbW1t0eEAALCFKWaBQ2YwGGR9fX3RYRyUo3eUJHW0ZNHKCceMLQEAdlPMAmzygMd7WVwmR53z0EWHAAAsKdfMAgAA0DuKWQAAAHpHMQsAAEDvuDgMYM6OOGF4k6nhEgCAA6GYBZizU87x0gsAcLC8owLgwOw4OmW0BACYN8UsAAfkqCc8cNEhAADbmBtAAQAA0DuKWQAAAHpHMQsAAEDvKGYBAADoHcUsAAAAvaOYBQAAoHcUswAAAPSOz5kF2ILKjiNSR0sAgK3IuxxgS7vL8SVJHS23jyPPPXXRISzE6upqBoNBVlZWsra2tuhwAIAZUswCW9r3Pu7wRYfAHA0Gg6yvry86DABgDlwzCwAAQO8oZgEAAOgdpxkD9EA5oQxv6HTC9rr2FwCgjWIWoAeOPPfoRYcAALBUnGYMAABA7zgyCwCH0OMvfv3Y+q0bNyZJdm7cOLbt0vN+aq5xAcBW48gsAAAAvaOYBQAAoHcUswAAAPSOa2YBDtJRO0qSOlqy1ZUdx40tAYDFUMwCHKTvONtL6XZy1NlnLDoEACBOMwYAAKCHFLMAAAD0jnPjgIU59vjhtabDJczf6upqBoNBVlZWsra2tuhwAID9oJgFkiSvf8Mjx9ZvvHHXaLk+tu2nnvneQzbmwx99+CF7LjgQg8Eg6+vriw4DADgATjMGAACgdxSzAAAA9I5iFgAAgN5xzSxsE250AwDAVqKYhW3CjW4AANhKnGYMAABA7yhmAQAA6B3FLAAAAL3jmlnggP2PNz5qbP2Gm+4cLdfHtv3M098z17gAANj6HJkFAACgdxSzAAAA9I5iFgAAgN5RzAIAANA7ilkAAAB6RzELAABA7yhmAQAA6B3FLAAAAL2jmAUAAKB3FLMAAAD0zhGLDgA4MKurqxkMBllZWcna2tqiwwEWyOsBANuRYhZ6ajAYZH19fdFhAEvA6wEA25HTjAEAAOgdR2YB6K3HvfU1Y+u3bVyfJNm5cf3Ytnc+8flzjQsAmD3FLAAsGdfAAsBkilkAWDKugQWAyVwzCwAAQO8oZgEAAOgdxSwAAAC945pZWAJu9gJbV9lx3NgSADg0FLOwBNzsBbauo88+c9EhAMCW5DRjAAAAeseRWQC2jce99bVj67dt3JAk2blxw9i2dz7x2XONCwDYf47MAgAA0DuKWQAAAHpHMQsAAEDvKGYBAADoHcUsAAAAveNuxkCj444fXwIAwDJRzAKNzvy3hy86BAAAaOU0YwAAAHpHMQsAAEDvKGYBAADoHcUsAAAAveMGULBFvfEPHjW2ftONd46W62Pbnv4T75lrXAAAcCjM7MhsKeX1pZRrSylXbnrsFaWU9VLK5aOvx27a9tJSyudKKZ8ppTyq+VkBAABgtqcZ/0GSRzc8/pu11gePvt6VJKWUByR5apIHjvq8tpTic0EAAABoNLPTjGutHyqlnDZl83OS/Emt9bYkny+lfC7Jw5J8eEbhwUytrq5mMBhkZWUla2triw4HAAC2nEXcAOq5pZQrRqchnzh67J5JvripzdWjx/ZRSrmglHJZKeWy6667btaxwgEZDAZZX1/PYDBYdCgAALAlzbuY/e0k35nkwUmuSfLq0eOloW1teoJa64W11tNrraeffPLJs4kSOCDHHV9y/AnDJQAAzNJc72Zca/3S7u9LKb+b5NLR6tVJ7r2p6b2S7JxjaMAh8IhHutQdAID5mOuR2VLKqZtWz02y+07H70jy1FLK0aWU+yS5b5KPzjM2AAAA+mNmR2ZLKW9KckaSk0opVyd5eZIzSikPzvAU4quS/EyS1Fo/WUp5S5JPJbkzyXNqrbtmFRsAAAD9Nsu7GT+t4eHXdbR/ZZJXzioeAAAAto5F3M0YAAAADopiFgAAgN6Z692MAWCWygnHji0BgK1rqmK2lHK/DD8j9h611u8ppTwoydm11v800+gAYD8cdfYPLDqEA/L4i/9wbP3WjZuSJDs3btqz7dLznvHN9hf9UXv7TdsuPf/HZhIvACyDaU8z/t0kL01yR5LUWq9I8tRZBQUAAABdpj3N+Nha60dLKZsfu3MG8QAt3vz7jx5b37jxjtFyfc+2p/zku+ceFwAALMK0R2a/XEr5zgw/HzallPOTXDOzqAAAAKDDtEdmn5PkwiTfVUpZT/L5JD8+s6gAAACgw1TFbK31n5P8aCnluCSH1Vpvmm1YAAAA0G7auxnfLckzkpyW5Ijd187WWp83s8gAgJlYXV3NYDDIyspK1tbWFh0OAByQaU8zfleSjyT5hyTfmF04AMCsDQaDrK+vLzoMADgo0xazd6m1vnCmkQAAAMCUpi1m31hK+fdJLk1y2+4Ha61fnUlUsMVd0vExO5u3neujdgAAoNG0xeztSX49ycsy+nie0fI7ZhEUAMxDOeHYsSUA0B/TFrMvTPJ/1Fq/PMtgAGCejjr73yw6BADgAB02ZbtPJrllloEAAADAtKY9MrsryeWllL/M+DWzPpoHAACAuZu2mH3b6AsAAAAWbqpittb6hlLKUUnuN3roM7XWO2YXFgAAALSbqpgtpZyR5A1JrkpSkty7lPLMWuuHZhcaAAAANJv2NONXJ3lkrfUzSVJKuV+SNyX5vlkFBgAAAG2mvZvxkbsL2SSptX42yZGzCQkAAAC6TXtk9rJSyuuSvHG0/mNJPj6bkAAAAKDbtMXszyV5TpLnZXjN7IeSvHZWQQEAAECXaYvZI5K8ptb6G0lSSjk8ydEziwoAAAA6THvN7AeSHLNp/Zgk7z/04QAAAMBk0xazd6m1buxeGX1/7GxCAgAAgG7TFrM3l1IesnullPJ9Sb4+m5AAAACg27TXzL4gyZ+WUnaO1k9N8pTZhAQAAADdpipma60fK6V8V5L7Z3g343+std4x08iAQ+r440uSOloCAEC/TXtkNkkemuS0UZ/vLaWk1vqHM4kKeubS1z9mbP3mG28fLdfHtj3+p/58rnFt9sgfPXxhYwMAwKE2VTFbSnljku9McnmSXaOHaxLFLAAAAHM37ZHZ05M8oNZaZxkMAAAATGPaYvbKJCtJrplhLADAASg7jh9bAsB2MG0xe1KST5VSPprktt0P1lrPnklUAMDUjj7r0YsOAQDmbtpi9hWzDAIAAAD2x7QfzfNXsw4EAAAAptVZzJZS/rrW+oOllJsyvHvxnk1Jaq31hJlGBwAAAA06i9la6w+OljvmEw4AUHYcN7YEAPY17TWzAMCcHH32IxcdAgAsPcUsADDR6upqBoNBVlZWsra2tuhwAEAxCwBb3eMvevPY+q0bG0mSnRsbY9suPf8prc8xGAyyvr4+mwAB4AAoZqGnjj++JKmjJQAAbC+KWeipx51p+gIAsH0dtugAAAAAYH8pZgEAAOgdxSwAAAC9o5gFAACgdxSzAAAA9I7boQIAS2F1dTWDwSArKytZW1tbdDgALDnFLACwFAaDQdbX1xcdBgA94TRjAAAAeseRWVgCJxxfktTREgAAmEQxC0vgnDNNRQAA2B/eQQMAvbS/N4xygymArUUxCwD00v7eMMoNpgC2FsUsTOA/+QAAsHwUszCB/+QDAMDy8dE8AAAA9I5iFgAAgN5RzAIAANA7ilkAAAB6RzELAABA7yhmAQAA6B3FLAAAAL2jmAUAAKB3FLMAAAD0zhGLDgC2ohOOK0nqaAkAABxqilmYgfPOPHLRIQAAwJammAUA9vH4iy4aW791YyNJsnNjY2zbpeefP9e4AGA3xSzbzurqagaDQVZWVrK2trbocAAAgAOgmGXbGQwGWV9fX3QYAADAQVDMAsA2U3YcP7YEgD5SzALANnP0WY9bdAgAcNB8ziwAAAC9o5gFAACgdxSzAAAA9I5iFgAAgN5xAygAYCHOvujSsfVbNm5OkuzcuHnPtnec//i5xwVAPzgyCwAAQO/MrJgtpby+lHJtKeXKTY/dvZTyvlLKP42WJ27a9tJSyudKKZ8ppTxqVnEBAADQf7M8MvsHSR6912MvSfKBWut9k3xgtJ5SygOSPDXJA0d9XltKOXyGsQEAM7S6uppnPOMZWV1dXXQoAGxRM7tmttb6oVLKaXs9fE6SM0bfvyHJB5O8ePT4n9Rab0vy+VLK55I8LMmHZxUfADA7g8Eg6+vrC43hCRd9YGx9Y+PrSZKdG18f2/a288+ca1wAHBrzvmb2HrXWa5JktDxl9Pg9k3xxU7urR48BAADAPpblBlCl4bHa2LCUC0opl5VSLrvuuutmHBYAAADLaN4fzfOlUsqptdZrSimnJrl29PjVSe69qd29kuxseoJa64VJLkyS008/vbHgBQC2nnMues/Y+s0btyRJdm7cMrbt7ee7jyTAdjDvI7PvSPLM0ffPTPL2TY8/tZRydCnlPknum+Sjc44NAACAnpjZkdlSypsyvNnTSaWUq5O8PMmrkryllPKsJF9I8qQkqbV+spTyliSfSnJnkufUWnfNKjYAAAD6bZZ3M35ay6bGWwbWWl+Z5JWzigcAAICtY97XzMLSe8/rHju2fsuNt4+WO8e2PepZ75prXAAAwDcty92MAQAAYGqKWQAAAHpHMQsAAEDvKGYBAADoHcUsAAAAvaOYBQAAoHcUswAAAPSOYhYAAIDeUcwCAADQO4pZAAAAekcxCwAAQO8csegAAIDlV3bsGFsCwKIpZtny/vL3Hje2/vUbbxstd45t++Gffudc4wLok6PPOmvRISzE6upqBoNBVlZWsra2tuhwANhEMQsA0GIwGGR9fX3RYQDQwDWzAAAA9I5iFgAAgN5xmjEAsBTKjhPGlgDQRTELACyFY846b9EhANAjTjMGAACgdxyZBQAO2lkXvW1s/esbNydJdm7cPLbtz85/wlzjAmDrcmQWAACA3nFkFgDYFg7bcdd8Y7QEoP8UswDAtnDsWU9bdAgAHEKKWQCglxxpBdjeFLMAQC8dc9aTFx0CAAukmAUAOERWV1czGAyysrKStbW1RYcDsKUpZgEADpHBYJD19fVFhwGwLfhoHgAAAHpHMQsAAEDvKGYBAADoHdfMwgR3PS5JymgJAAAsA8UsTPDkHzlq0SEAAAB7cZoxAAAAvaOYBQAAoHcUswAAAPSOYhYAAIDeUcwCAADQO4pZAAAAekcxCwAAQO8oZgEAAOidIxYdAADAsjj34g+NrW9sfD1Jcs3G18e2XXLeD801LgD25cgsAAAAvaOYBQAAoHecZkzvra6uZjAYZGVlJWtraxPb3/W4MrYEAAD6RzFL7w0Gg6yvr0/d/sd++KgZRgMAAMyD04wBAADoHcUsAAAAvaOYBQAAoHdcMwsAHHJlx46xJQAcaopZAOCQu8tZT1h0CHPxxIs/MrZ+08atSZJrNm4d2/bW875/rnEBbAdOMwYAAKB3FLMAAAD0jmIWAACA3lHMAgAA0DuKWQAAAHrH3YwBABZodXU1g8EgKysrWVtbW3Q4AL2hmAUAWKDBYJD19fVFhwHQO04zBgAAoHcUswAAAPSOYhYAAIDeUcwCAADQO24ABQDQI+5+DDCkmAUA6BF3PwYYcpoxAAAAvaOYBQAAoHcUswAAAPSOa2YBAFqUHXfLYaMlAMtFMUvv/M2Fjx9bv/WGW0fLnXu2PfyCS+ceFwBbz3FnP33RIQDQwmnGAAAA9I5iFgAAgN5xmjFLxQfBAwAA01DMslR8EDwAADANxSwAwCFy2I4Tx5YAzI5ilply2jAA28lxZ//kokMA2DYUs8yU04YBAIBZcDdjAAAAekcxCwAAQO8oZgEAAOgd18wCAMzR+Rd/Ymz9ho3bkiTXbNy2Z9tF5z1k7nEB9I0jswAAAPTOQo7MllKuSnJTkl1J7qy1nl5KuXuSNyc5LclVSZ5ca/3aIuIDAABguS3yNOMfrrV+edP6S5J8oNb6qlLKS0brL15MaAAAy+FJF39ybP36jduTJNds3D627U/Pe+Bc4wJYtGU6zficJG8Yff+GJE9YYCwAAAAssUUVszXJe0spHy+lXDB67B611muSZLQ8paljKeWCUsplpZTLrrvuujmFCwAAwDJZ1GnGD6+17iylnJLkfaWUf5y2Y631wiQXJsnpp59eZxUgAAAAy2shR2ZrrTtHy2uTXJLkYUm+VEo5NUlGy2sXERsAAADLb+7FbCnluFLKjt3fJ3lkkiuTvCPJM0fNnpnk7fOODQAAgH5YxGnG90hySSll9/h/XGt9dynlY0neUkp5VpIvJHnSAmIDAACgB+ZezNZa/znJv2p4/CtJzpx3PAAAAPTPIj9nFgCAGVtdXc1gMMjKykrW1tZm1gdg3hSzAABb2GAwyPr6+sz7AMybYpbeu9txZWwJAABsfYpZFupj/+OssfXbbvj6aLlzbNtDf+bPWp/jmWccPZvgAACApbWQz5kFAACAg6GYBQAAoHcUswAAAPSOYhYAAIDeUcwCAADQO+5mzCF1xW+fPbZ++w23jJY7x7Y96OfeMde4AACArUUxCwCwQIftOHFsCcB0FLMAAAu04+wLFh0CQC+5ZhYAAIDeUcwCAADQO4pZAAAAesc1s0xtdXU1g8EgKysrWVtbW3Q4AADANqaYZWqDwSDr6+uLDgMA2AL8kxw4WIpZAIAeOWzH3ceWfeWf5MDBUswCAPTICWc/Z9EhACwFN4ACAACgdxyZBQDgoLj+FVgExSwAwBbylLf+89j6VzfuSJJcs3HH2LY3P/E79nz/vEu+ONbnuo079yw3b/utc+/dOKbrX4FFcJoxAAAAvaOYBQAAoHecZsxSOfG4MrYEAABoophlqTzrEXdZdAgAAEAPOM0YAACA3lHMAgAA0DuKWQAAAHrHNbPM1InHlrElAADAoaCYZaZ+7oeOWXQIAADAFuQ0YwAAAHpHMQsAAEDvOM0YAIClt7q6msFgkJWVlaytrS06HGAJKGYBAJi5/3LJYGz9+o1de5a7t73g3JXW/oPBIOvr67MLEOgdxSytPvvfzhlbv+P6m0fLnWPb7vfct881LgAAANfMAgAA0DuOzAIAsF9+5ZKdY+tfHZ0y/NWNXWPbXn7ut841LmB7UcwCADDmyBNOGlsCLCPFLAAAY04755cWHQLARK6ZBQAAoHcUswAAAPSO04wBALaww0fXvR7u+ldgi1HMAgBsYXc9+xcWHcJCrK6uZjAYZGVlJWtra4sOB5gBxSwAAFvOYDDI+vr6osMAZkgxCwAAcTQX+kYxCwAAcTQX+sbdjAEAAOgdR2YBAFg6v/fWa8fWb9zYtWe5edtPP/GUucYFLA/FLAAAc3fM6KOCjunxRwa5xhYWSzELAMDc/cA5L110CAfNNbawWK6ZBQAAoHcUswAAAPSO04wBADgoR4+uez26x9e/Av2jmN1CZn0Tgm857rAk3xgtAQCGHnTOixcdArANKWa3kFnfhOB5Dz9mZs8NAACwPxxiAwAAoHccmQUAoPfedPF1Y+s3bezas9y87WnnnTzXuIDZUcxuYz7oGwAA6CvF7Dbmg74BgO3sbRd9eWz95o1v7Flu3vaE8w/dXZodTIBDRzELAABz4mACHDqKWQAAmMKfv3n8SO4toyO5t2x8Y2zbY56yuCO5jvzSRwf6e6uYBQCAJbW/R3Id+aWPDvT3VjELAMDSO+6Ek8eWAIpZAACW3g+f/QWXr8YAABWOSURBVMuLDgFYMopZAABgast4Xe4yxsTsKWYBAICpLeN1ucsYE7OnmAUAgG1sHkc1HTllFhSzPbb+3583tn7nDdftWe7eds/n/Nbc4wIAoD/mcVRzf8dQ/DINxew28oXfOn9s/c7rbxgtrxnb9m3Pu2iucQEAbFV/8cfXja1//aZde5a7t/3Iv3OH5r05bZhpKGaXlP9GAQAcuB07Th5bzqoPsDiK2SXlv1EAAAfuMWe/bL/7POGs/e9zqP3NH44fyb11dCT31pt2jW17+DOGBffHfv/asfa33bhrz3Lztof+5CkziRcOxLWvHT8TdNcNG3uWm7ed8uzxM0v3ppg9AI6aAgBwwvEnjy2B+VLMHgBHTQEAeNLjFn8kd7sa/Prnx9Z3fe3OPcvN21Z+6T5zjYv5UswCAADbzv6ebenszOWjmAUAgG3kigvHr7O9/YZde5abtz3oguF1tp957ZfG2t8xan/HDbvGtt3/2ffY8/1V/2Uw1ufO63ftWe7edtoLVg5qPw7W/p5t6ezM5aOYBQAAWAKO/u4fxSwAALBQ1/zaNWPru762a89y87ZTX3zqXOOat/09+rvdi1/F7JIYvPblY+u7bvjKnuXmbSvP/pXW5zj52CPHlgAAwNa13U99VsxuIas/eNp+tT/p2MPGlgAAzNZdRx/jc9cZfZzPiaPnPdHHBdEjJx+7Y2w5raUrZkspj07ymiSHJ/m9WuurFhxSrvud146t77rhhj3LzdtO/tlnzzWug/WL/9f+/bIAAHBw/t1jZvtxPs8685dn+vx9Nnj1P46t7/raHXuWm7etvOi7kiRf+s0rxttff/ue5eZt9/iFBx1wTF96zYf3GuPWPcvN2+7x/B844DH64Jf/zVkH1G+pitlSyuFJ/nuSf5vk6iQfK6W8o9b6qcVGBgAA83e3404eW9LspGO+ZWzJ9rBUxWyShyX5XK31n5OklPInSc5JopgFAGDbeeYjZ3skd6t46UNfuOgQ5uJLv/VXY+u7rv/6nuXmbfd43iPmGteiLFsxe88kX9y0fnWSf72gWAAAYMs7cXTU98Qpj/7e/diTx5bT+JZjThpbTnLSqN1JU7Zneyq11kXHsEcp5UlJHlVr/enR+tOTPKzW+vOb2lyQ5ILR6v2TfKbl6U5K8uX9GH7W7bfKGMsY0zzGWMaY5jHGMsY0jzGWMaZ5jLGMMc1jjGWMaR5jLGNM8xhjGWOaxxjLGNM8xljGmOYxxjLGNI8xljGmeYyxjDEdyjG+vdba/J+TWuvSfCX5gSTv2bT+0iQvPcDnumyZ2m+VMZYxJvu9PO23yhjLGJP9Xp72W2WMZYzJfi9P+60yxjLGZL+Xp/1WGWMZY5rXGMv2mSwfS3LfUsp9SilHJXlqkncsOCYAAACWzFJdM1trvbOU8twk78nwo3leX2v95ILDAgAAYMksVTGbJLXWdyV51yF4qguXrP1WGWMZY5rHGMsY0zzGWMaY5jHGMsY0jzGWMaZ5jLGMMc1jjGWMaR5jLGNM8xhjGWOaxxjLGNM8xljGmOYxxjLGNI8xljGmuYyxVDeAAgAAgGks2zWzAAAAMNn+3jFq2b6SvD7JtUmu3PTYm5NcPvq6KsnlU/R5cJKPjPpcluFHAnW1/1dJPpzkH5L8WZITNm27d5K/TPLpJJ9M8vzR43dP8r4k/zRanjhFnyeN1r+R5PQp2v96kn9MckWSS5LcbUL7Xx21vTzJe5N866QxNm3/xSQ1yUkTxnhFkvVNOXnsNGMk+fkMP3rpk0nWJozRmPOO9l35buvTmPMkd0ny0SR/P2r/K1357mjfmOsJfdry3da+K9+NfTry3TZGY767nr8p1xPGaMt3W/uufLf1aZ3jo+2HJ/m7JJdOmt8t7Vvz3dGnMd8d7Vvz3dS+LdcTxmjMd9cYbfnuGGPSa/re7Vvz3dJ+Uq6vGm27PKM7LU6R76Y+XXO8qX1rvlvaT8r3Pn26ct4yxqR8N47RlvOWMVrz3dJ+Ur6b+nT9Db9bkotGP/tPZ/hJC11/v5vad87vlj5d+W5qPynf+/SZkO+mMVrz3fb8bbnuGKMr303tJ+W7qU/b3+/7bxr78iQ3JnnBhHy39Wl7v9bWvu3vd1v7rr/fjX3a8t0xRle+W8doynnHGG1/v9vad/39buvTNb9/YRTnlUnelOF7gK58N7WfNL+b+nTN76b2k+b3Pn0mzO+mMbry3fj8TbmeMEZX/p4/avvJfPN3qfNva9PXQReTi/5K8kNJHpJNheZe21+d5P+e1Gf0i/KY0fePTfLBCe0/luQRo+9/Ksmvbtp2apKHjL7fkeSzSR6QZC3JS0aPvyTJr03R57sznKwfzPiLY1v7RyY5YvT4r+0eo6P95gn+vCS/M2mM0fq9M7xR17/kmy+ObWO8IskvtuSnrc8PJ3l/kqNH206ZFFNTzjuevyvfbX0ac56kJDl+9P2RSf42yfe35bujfWOuJ/Rpy3db+658N/bpyHfbGI357mjfmOtJMbXku22Mrny39Wmd46PHXpjkj/PNgqh1fre0b813R5/GfHe0b813U/u2XE8YozHfHe1b890VV1O+O8ZozXdL+0m5vmrvn8UU+W7q0zXHm9q35rul/aR879OnK+ctY0zKd1OfrjneGFNbvluef1K+m/p0/Q1/Q5KfHn1/VIbFUdff76b2nfO7pU9XvpvaT8r3Pn0m5LtpjNZ8t7TvnN9tMXXku2mMSflu6tM5x0ePH55kkOTbu/Ld0Wea1/TN7Ttfzxvad+a7qU9XvlvGaM13R59pXtPHYmrLd8vzd+a7pU/b+7V7Jvl8kmNG629J8hNt+e5o3/Va3tan7f1aW/uu92uNfdry3TFGY7472ne9lrf1acxfku/JsJA9NsN7OL0/yX3bctH11fvTjGutH0ry1aZtpZSS5MkZ/ndgUp+a5ITR93dNsnNC+/sn+dDo+/clOW9T+2tqrZ8YfX9Thv8ZvGeSczJ8kc1o+YRJfWqtn661fqZhv9vav7fWeueo2UeS3GtC+xs3Pe1xo5/DpP1Ikt9Msrof7Rt19Pm5JK+qtd422nbtNGPsnfOO9l35buvTmPM6tDF6/MjRV01Lvtvat+V6Qp+2fLe178p3234kzfnuaj/1PqQl19OM0ZDvtvZd+W7r0zrHSyn3SvK4JL+3aRdb53dT+658d/RpzHdH+9Z8t+xD0pDrKfpMvQ/pyPekMZpe01vat+a7pX1rrju05rvNpJw3tG/Nd0v71nxP0JrzQ6Qz523a/oY3aM13h8acl1JOyPAf2K8bxXp7rfX6tOS7rX1Xrjv6NOa7o33X/G7bj6Qh3xPaT70P6cj1pDH2zndH+6753dZnmjl+ZpL/VWv9l0w/v/f0mXJ+b24/zfze3H7a+b15P5LJ83vv9tPY3Gea+b3PGBPm9+b2087vzX268n1EkmNKKUdkWEjtTHe+92k/Ra6b+nTlu6n9pHw37UfSnu+29lPvQybnuqlPW/6+O8lHaq23jH4uf5Xk3BzA39bOSrcvX0lOS8OR2Qxf0Bo/fHfvPqMf6heSfDHDQ+7fPqH9/5/knNH3L0xyU8c4Xxgl8vq9tn1tUp9Nj30w7f/p26f96PE/S/Ljk9oneeVov69McvIU+3F2kteMHr8qzf/p29z+FaN2V2R4ynbjKQN79bk8ya9keJTsr5I8dMqf06Sc737+zny39GnNeYb/Ebw8yUa++d+21nw3tZ+U664+Tflua9+V75b9aM13S/vWfLe078z1hJ/VPvluGWPS/G7q05Xvi5J8X5Iz8s2je1353qf9FPlu7dOS78b2bflu2YfOud3SpyvfTe0n5bvrZ9WU76YxWvPd0r7z9TzD/zZ/IsnHk1wwKd9tfbpy3tW+Jd+N7dvy3bEfXfO7qX1rvjv6tOZ8ws+pKd9Nzz9pfjf1acx5hqfEfTTJH2R4KvrvZfhGsjHfbe0n5Lqzz9757mrflu+O/WjMd0f7xnx3tO/K9aSf1Vi+O8bomt9tfSa+Zxvt33Onmd9Nfbpy3tW+aX63tW/Ld8d+TPN+bXP7xnxP6DPN+7Wmn1PX+7XNzz/t+7XNfbr+fj8/w7/11yX5o0n5bmo/KdddfZry3da+K98t+9H1et7UvjXfLe0n/f1u6tOYv9Hjn03yLRkWvh9O8l+7ctH21bmxL19pL2Z/O8mLpumT5LeSnDf6/slJ3j+h/XdleOj840lenuQrDWMcP9r+xEmTpa3PFBOmrf3LMjwnv0zTfrTtpdnrOsm9+4x+4f42yV2bJkvLft8jw2LhsAwn5uun+FldOcpJSfKwDN+MlCn2uzHnDc/fme+WPtPk/G4ZXm/7PVPme0/7Sbme0Kcx323tu/K9V58HTcp3w35Pk+/N7TtzPWG/u+b45jEm5ruhT2O+kzw+yWtH35+RCcVsW/uufE/RZyzfk9rvne+m9pkwtzv2uzHfHe1b8z3Ffo/lu2OMxnx3tO+c2xldq5TklAyvrf6htnx39ZmQ8672+8zvrvZt87tlP7py3tS+c3639OnKedd+7zO/W55/0t/vpj5t8/v0JHcm+dej9ddkeO1a2/xubD8h15P67D2/O9s35bulz6+35btjv9vmd1v7rlxP2u+953fbGK357ugzaY4fleTLSe4xWp/m7/dYn66cT2jf9n6tsX3b/N67T6Z7v7b3fk/z93vvPpPer7Xtd9v7tb2ff5r3a3v3aZvfJyb5iyQnZ3gW1tuS/HhbvtvaT5jfk/rsPb8727fM76Y+z2jLd8d+t83vtvZd87utT9d8fVaG/2j8UJLfyfCosmJ202NHJPlSkntN0yfJDZsSUpLcOGmMTdvul+Sjez12ZIbnrL9w02OfSXLq6PtTk3xmUp8JE6axfZJnZvgfjmOnff7R9m9v+DmO9Unyf2Z4M6yrRl93Zvgfl5Upx2jKVdPP6t1Jzti0/r8y+q9Ux3435rzl+Sfle9J+7JPzTdtenuHF95353rt9V667+rTlu2uMtnw39PmPXfmeYox98t3wc2rN9YT97pzje43Rme8p9mNPvpP8P0muHv08BkluSfI/2/Ld1n7C3G7t05TvSWPsne+W9hd35XrKMU6bMMb/7Mr3hP3eJ98dYzTme8p9aJ3bo+2vyH7M7819pp3jm9s35XvS8085v1+R/ZvfTWOcNsUYU8/xvfZ7mvm9+/n3Z3437cfm+b2S5KpN2/5Nkne25but/YT53dqnKd+TxmjKd0ufD7Tle8ox9uS74+fUNb+79rtpfreN0ZrvKfej6T3bOUneu2l94vzeu8+k+d3Uvinfk56/a35v7pMJ79emGOO0SWOM1jvnd8t+t87vhuefOL8n7Mfm+f2kJK/btO0ZSV7blu+29hPmd2ufpnxPGqNlfjf1+cu2fE85xp58d/ycuuZ3W5+pXp+T/Ockz27LRddX76+Z7fCjSf6x1nr1lO13JnnE6PsfyfAuWq1KKaeMlocl+Q8Z/kdh97aS4fUan661/sambu/I8Bc5o+Xbp+jTNn5j+1LKo5O8OMnZtdZbpmh/301Pe3aGd1pr7VNr/Yda6ym11tNqradl+MbwIbXWQccYp24a49wM/7Mzab/flmEeUkq5X0b/dZvwc9on5x3tW/PdsR+NOS+lnFxKudvo+2N2x5GWfHe0b9XWpyPfbe278t3U5+868t02RmO+O/a7MddT/Kya8t3WvivfbfvRmO9a60trrfca/TyemuQvaq0/npZ8d7Rv1danLd8d7Rvz3dL+vLZcTxijMd8d+92a7wk/q33y3dG+Md8d+9D1en5cKWXH7u8zvInHlel+PW/r06itfcf8bmvfNb+b+nysY363jdH1et62322v510/p6b53da+a3637Ufb/B4k+WIp5f6jpzgzyafSPr/b2rdq69Mxv9vat+a7pc8n2vLdMUbb/G7b76753fWzaprfbe1b892xH61zfORpGb92s3V+d/SZZKx9W7472rfmu6lP1/u1jjFa53dbn3TkvKV90v0efe/207w/33s/2vL9hSTfX0o5dvRe78wM74vSlu+29l0a+3Tku619V76b+ry1I99tY7Tlu22/u3Ld1qfr9Xl3nr4tw7M/35Tp5t64SdXusn+NdvyaJHeMEves0eN/kORnp+2T5AczPB3h7zM8TP99E9o/P8NzvT+b5FUZP6XiBzO84Hn3LbUvz/AOXt+S4X9G/2m0vPsUfc4djXlbhv/Fes+E9p/L8Lz03Y/9zoT2F2f4y3tFhufw33NSTHv9LK/KN09jaBvjjRneHv2KDH9JT51iv4/K8AjLlRmegvAjk2JqynnH83flu61PY84zPBX370btr8w376zbmO+O9o25ntCnLd9t7bvy3dinI99tYzTmu6N9Y64nxdSS77YxuvLd1qd1jm/qe0a+eapq6/xuad+a744+jfnuaN+a76b2bbmeMEbr/G5p35rvrria8t0xRmu+W9p3vZ5/x+h5dn9008sm5bujT9vreVv7tvnd1r5rfjf26ZjfbWN0vZ639Wl7PW+NqSnfHc/fNb/b+nTl/MEZfoTEFRm+eTtxQr6b2nfO75Y+rfO7pX3n/G7q0zXHW8boyndT+8753RZTU747xuic3y19uvJ9bJKvZHR65jSv5y19uv6GN7XvyndT+0n53qfPhHw3jdH5et7Sp+tveGNMHfluev5J+W7q05XvX8mwMLxytL9Hd+W7pf2k+d3UpyvfTe0n5XufPhPy3TRG1/xuaj9pfjf16Xp9/v8y/AfV3yc5c5q51/S1+804AAAA9MZWPs0YAACALUoxCwAAQO8oZgEAAOgdxSwAAAC9o5gFAACgdxSzAAAA9I5iFgAAgN5RzALAEimlvK2U8vFSyidLKReMHntWKeWzpZQPllJ+t5Ty30aPn1xKubiU8rHR18MXGz0AzE+ptS46BgBgpJRy91rrV0spxyT5WJJHJfmbJA9JclOSv0jy97XW55ZS/jjJa2utf11K+bYk76m1fvfCggeAOTpi0QEAAGOeV0o5d/T9vZM8Pclf1Vq/miSllD9Ncr/R9h9N8oBSyu6+J5RSdtRab5pnwACwCIpZAFgSpZQzMixQf6DWeksp5YNJPpOk7WjrYaO2X59PhACwPFwzCwDL465JvjYqZL8ryfcnOTbJI0opJ5ZSjkhy3qb2703y3N0rpZQHzzVaAFggxSwALI93JzmilHJFkl9N8pEk60n+c5K/TfL+JJ9KcsOo/fOSnF5KuaKU8qkkPzv/kAFgMdwACgCWXCnl+FrrxujI7CVJXl9rvWTRcQHAIjkyCwDL7xWllMuTXJnk80netuB4AGDhHJkFAACgdxyZBQAAoHcUswAAAPSOYhYAAIDeUcwCAADQO4pZAAAAekcxCwAAQO/8b+5p6r59tiljAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a=sns.barplot(x='age',y='income',data=EDA1,estimator=sum)\n",
    "a.figure.set_size_inches(16,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19c14ef5850>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='marital-status',y='income',data=EDA1,estimator=sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19c14f5b7f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEHCAYAAABfkmooAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAadklEQVR4nO3df7RdZX3n8feHAElAMoK5QkxCg0zUJqhBrikdbIeClWgdwVnShqnCmsUYy4IKow4S7Sh2raxl8VfLTGE1CCXxB0zqjyF1gYpRRGwg3tBAEgI1Iwg3P0iQoQbHRhI+88d5rj3cnNx9crn7nJPcz2uts/Y+37Ofvb83hHzvfp7nPFu2iYiIGMlh3U4gIiJ6X4pFRERUSrGIiIhKKRYREVEpxSIiIiqlWERERKXD676ApAnAALDF9tslHQf8L2AW8Bjwh7b/bzl2MXAxsBd4v+1vlfhpwM3AZOB24HJXzPmdOnWqZ82aVcNPFBFx6Fq7du1TtvuGx2svFsDlwCZgSnl/FbDK9iclXVXef1jSHGAhMBd4BfAdSa+yvRe4HlgE3EujWCwA7hjporNmzWJgYKCOnyci4pAl6aet4rV2Q0maAfwB8Pmm8LnAsrK/DDivKX6r7d22HwU2A/MlTQOm2F5d7iaWN7WJiIgOqHvM4i+BK4Hnm2LH294GULYvL/HpwBNNxw2W2PSyPzy+D0mLJA1IGti5c+fY/AQREVFfsZD0dmCH7bXtNmkR8wjxfYP2Utv9tvv7+vbpcouIiFGqc8ziDOAdkt4GTAKmSPoi8KSkaba3lS6mHeX4QWBmU/sZwNYSn9EiHhERHVLbnYXtxbZn2J5FY+D6u7bfDawELiqHXQTcVvZXAgslTZR0EjAbWFO6qnZJOl2SgAub2kRERAd0YjbUcJ8EVki6GHgcOB/A9kZJK4CHgD3ApWUmFMAl/OvU2TuomAkVERFjS4fqEuX9/f3O1NmIiAMjaa3t/uHxfIM7IiIqdaMbKmLcuvLKK9m+fTsnnHAC11xzTbfTiWhbikVEB23fvp0tW7Z0O42IA5ZuqIiIqJRiERERlVIsIiKiUopFRERUygB3xCj8zw/+/ajaPfPUL369Hc05LvvMfxjVdSNerNxZREREpRSLiIiolGIRERGVUiwiIqJSikVERFRKsYiIiEqZOhvRQUcfOeUF24iDRYpFRAedcfJ/7HYKEaOSbqiIiKiUYhEREZVqKxaSJklaI+kBSRslfaLEr5a0RdK68npbU5vFkjZLekTSOU3x0yStL59dK0l15R0REfuqc8xiN3CW7WclHQHcI+mO8tnnbH+6+WBJc4CFwFzgFcB3JL3K9l7gemARcC9wO7AAuIOIiOiI2u4s3PBseXtEeXmEJucCt9rebftRYDMwX9I0YIrt1bYNLAfOqyvviIjYV61jFpImSFoH7ADutH1f+egySQ9KuknSsSU2HXiiqflgiU0v+8Pjra63SNKApIGdO3eO6c8SETGe1VosbO+1PQ+YQeMu4RQaXUonA/OAbcBnyuGtxiE8QrzV9Zba7rfd39fX96Lzj4iIho7MhrL9DHAXsMD2k6WIPA/cAMwvhw0CM5uazQC2lviMFvGIiOiQOmdD9Ul6admfDLwZeLiMQQx5J7Ch7K8EFkqaKOkkYDawxvY2YJek08ssqAuB2+rKOyIi9lXnbKhpwDJJE2gUpRW2vyHpC5Lm0ehKegx4H4DtjZJWAA8Be4BLy0wogEuAm4HJNGZBZSZUREQH1VYsbD8InNoi/p4R2iwBlrSIDwCnjGmCERHRtnyDOyIiKqVYREREpRSLiIiolGIRERGVUiwiIqJSikVERFRKsYiIiEopFhERUSnFIiIiKqVYREREpRSLiIiolGIRERGVUiwiIqJSikVERFRKsYiIiEopFhERUSnFIiIiKqVYREREpdqKhaRJktZIekDSRkmfKPHjJN0p6cdle2xTm8WSNkt6RNI5TfHTJK0vn10rSXXlHRER+6rzzmI3cJbt1wPzgAWSTgeuAlbZng2sKu+RNAdYCMwFFgDXSZpQznU9sAiYXV4Lasw7IiKGqa1YuOHZ8vaI8jJwLrCsxJcB55X9c4Fbbe+2/SiwGZgvaRowxfZq2waWN7WJiIgOqHXMQtIESeuAHcCdtu8Djre9DaBsX14Onw480dR8sMSml/3h8VbXWyRpQNLAzp07x/aHiYgYx2otFrb32p4HzKBxl3DKCIe3GofwCPFW11tqu992f19f34EnHBERLXVkNpTtZ4C7aIw1PFm6lijbHeWwQWBmU7MZwNYSn9EiHhERHVLnbKg+SS8t+5OBNwMPAyuBi8phFwG3lf2VwEJJEyWdRGMge03pqtol6fQyC+rCpjYREdEBh9d47mnAsjKj6TBghe1vSFoNrJB0MfA4cD6A7Y2SVgAPAXuAS23vLee6BLgZmAzcUV4REdEhtRUL2w8Cp7aI/ww4ez9tlgBLWsQHgJHGOyIiokb5BndERFRKsYiIiEopFhERUSnFIiIiKqVYREREpRSLiIiolGIRERGVUiwiIqJSikVERFRKsYiIiEopFhERUSnFIiIiKqVYREREpRSLiIiolGIRERGVUiwiIqJSikVERFRKsYiIiEq1FQtJMyV9T9ImSRslXV7iV0vaImldeb2tqc1iSZslPSLpnKb4aZLWl8+ulaS68o6IiH3V9gxuYA/wQdv3SzoGWCvpzvLZ52x/uvlgSXOAhcBc4BXAdyS9yvZe4HpgEXAvcDuwALijxtwjIqJJbXcWtrfZvr/s7wI2AdNHaHIucKvt3bYfBTYD8yVNA6bYXm3bwHLgvLryjoiIfXVkzELSLOBU4L4SukzSg5JuknRsiU0HnmhqNlhi08v+8Hir6yySNCBpYOfOnWP4E0REjG+1FwtJLwG+Clxh++c0upROBuYB24DPDB3aorlHiO8btJfa7rfd39fX96Jzj4iIhlqLhaQjaBSKL9n+GoDtJ23vtf08cAMwvxw+CMxsaj4D2FriM1rEIyKiQ+qcDSXgRmCT7c82xac1HfZOYEPZXwkslDRR0knAbGCN7W3ALkmnl3NeCNxWV94REbGvOmdDnQG8B1gvaV2JfQS4QNI8Gl1JjwHvA7C9UdIK4CEaM6kuLTOhAC4BbgYm05gFlZlQEREdVFuxsH0Prccbbh+hzRJgSYv4AHDK2GUXEREHIt/gjoiISikWERFRKcUiIiIqpVhERESltoqFpFdJWiVpQ3n/Okl/Vm9qERHRK9q9s7gBWAw8B2D7QRqL/kVExDjQbrE4yvaaYbE9Y51MRET0pnaLxVOSTqasySTpXTTWdYqIiHGg3S/lXQosBV4jaQvwKPDu2rKKiIie0laxsP0T4M2SjgYOK8+niIiIcaKtYiHppTQW8JsFHD70VFPb768ts4iI6BntdkPdTuORpuuB5+tLJyIielG7xWKS7Q/UmklERPSsdmdDfUHSeyVNk3Tc0KvWzCIiome0e2fxK+BTwEf510eaGnhlHUlFRERvabdYfAD4t7afqjOZiIjoTe12Q20E/l+diURERO9qt1jsBdZJ+htJ1w69Rmogaaak70naJGmjpMtL/DhJd0r6cdke29RmsaTNkh6RdE5T/DRJ68tn12po7m5ERHREu8Xif9N43Ok/AGubXiPZA3zQ9m8CpwOXSpoDXAWssj0bWFXeUz5bCMwFFgDXSZpQznU9sAiYXV4L2sw7IiLGQLvf4F4m6UjgVSX0iO3nKtpso6wfZXuXpE3AdOBc4Mxy2DLgLuDDJX6r7d3Ao5I2A/MlPQZMsb0aQNJy4DzgjjZ/xoiIeJHa/Qb3mTT+YX8MEDBT0kW2726z/SzgVOA+4PhSSLC9TdLLy2HTaXzxb8hgiT1X9ofHIyKiQ9qdDfUZ4C22H4HGw5CAW4DTqhpKegnwVeAK2z8fYbih1QceId7qWotodFdx4oknVqUWERFtanfM4oihQgFg+5+AI6oaSTqCRqH4ku2vlfCTkqaVz6cBO0p8EJjZ1HwGsLXEZ7SI78P2Utv9tvv7+vra+sEiIqJau8ViQNKNks4srxuoGOAuM5ZuBDbZ/mzTRyuBi8r+RcBtTfGFkiZKOonGQPaa0mW1S9Lp5ZwXNrWJiIgOaLcb6hIaz7R4P41uobuB6yranAG8B1gvaV2JfQT4JLBC0sXA48D5ALY3SloBPERjJtWltvc2Xf9mYDKNge0MbkdEdFC7xeJw4K+G7hDKlNaJIzWwfQ+txxsAzt5PmyU0pugOjw8Ap7SZa0REjLF2u6FW0fitfshk4Dtjn05ERPSidovFJNvPDr0p+0fVk1JERPSadovFLyS9YeiNpNOAX9aTUkRE9Jp2xyyuAP5O0tCU1WnAH9WTUkRE9Jp2l/v4kaTXAK+mMWj9cNVyHxERceho984C4I3ArNLmVEnYXl5LVhER0VPaXRvqC8DJwDoay5VDY8mNFIuIiHGg3TuLfmCO7ZZrMkVExKGt3dlQG4AT6kwkIiJ6V7t3FlOBhyStAXYPBW2/o5asIiKip7RbLK6uM4mIiOht7U6d/X7diURERO8asVhIusf2myTt4oUPHBJg21NqzS4iInrCiMXC9pvK9pjOpBMREb2o3dlQERExjqVYREREpRSLiIiolGIRERGVaisWkm6StEPShqbY1ZK2SFpXXm9r+myxpM2SHpF0TlP8NEnry2fXStrfo1ojIqImdd5Z3AwsaBH/nO155XU7gKQ5wEJgbmlzXXnON8D1wCJgdnm1OmdERNSotmJh+27g6TYPPxe41fZu248Cm4H5kqYBU2yvLosYLgfOqyfjiIjYn26MWVwm6cHSTXVsiU0Hnmg6ZrDEppf94fGWJC2SNCBpYOfOnWOdd0TEuNXpYnE9jedizAO2AZ8p8VbjEB4h3pLtpbb7bff39fW92FwjIqLoaLGw/aTtvbafB24A5pePBoGZTYfOALaW+IwW8YiI6KCOFosyBjHknTSekwGwElgoaaKkk2gMZK+xvQ3YJen0MgvqQuC2TuYcEREH9gzuAyLpFuBMYKqkQeDjwJmS5tHoSnoMeB+A7Y2SVgAPAXuAS20PPb71EhozqyYDd5RXRER0UG3FwvYFLcI3jnD8EmBJi/gAcMoYphYREQco3+COiIhKKRYREVEpxSIiIiqlWERERKUUi4iIqJRiERERlVIsIiKiUopFRERUSrGIiIhKKRYREVEpxSIiIiqlWERERKUUi4iIqJRiERERlVIsIiKiUopFRERUSrGIiIhKKRYREVGptmIh6SZJOyRtaIodJ+lOST8u22ObPlssabOkRySd0xQ/TdL68tm1klRXzhER0VqddxY3AwuGxa4CVtmeDawq75E0B1gIzC1trpM0obS5HlgEzC6v4eeMiIia1VYsbN8NPD0sfC6wrOwvA85rit9qe7ftR4HNwHxJ04AptlfbNrC8qU1ERHRIp8csjre9DaBsX17i04Enmo4bLLHpZX94vCVJiyQNSBrYuXPnmCYeETGe9coAd6txCI8Qb8n2Utv9tvv7+vrGLLmIiPGu08XiydK1RNnuKPFBYGbTcTOArSU+o0U8IiI6qNPFYiVwUdm/CLitKb5Q0kRJJ9EYyF5Tuqp2STq9zIK6sKlNRER0yOF1nVjSLcCZwFRJg8DHgU8CKyRdDDwOnA9ge6OkFcBDwB7gUtt7y6kuoTGzajJwR3lFREQH1VYsbF+wn4/O3s/xS4AlLeIDwCljmFpERBygXhngjoiIHpZiERERlVIsIiKiUopFRERUSrGIiIhKKRYREVEpxSIiIiqlWERERKUUi4iIqJRiERERlVIsIiKiUopFRERUSrGIiIhKKRYREVGptiXKIyJejCuvvJLt27dzwgkncM0113Q7nXEvxSIietL27dvZsmVLt9OIIt1QERFRKXcWEVGrTUu+O6p2v3r6l7/eHug5fvOjZ43qmrF/XbmzkPSYpPWS1kkaKLHjJN0p6cdle2zT8YslbZb0iKRzupFzRMR41s1uqN+zPc92f3l/FbDK9mxgVXmPpDnAQmAusAC4TtKEbiQcETFe9VI31LnAmWV/GXAX8OESv9X2buBRSZuB+cDqLuQY+5GZKwev/LeLdnSrWBj4tiQDf2N7KXC87W0AtrdJenk5djpwb1PbwRLbh6RFwCKAE088sa7co4XMXDl49ep/u5dN+jcv2EZ3datYnGF7aykId0p6eIRj1SLmVgeWorMUoL+/v+UxEYeqJe9+16jaPb3jnxvb7dtGdY6PfvEro7pulctO/U+1nDdGpyvFwvbWst0h6es0upWelDSt3FVMA3aUwweBmU3NZwBbO5rwOHLG/zhjVO2OfOZIDuMwnnjmiVGd44d/+sNRXTciOqPjA9ySjpZ0zNA+8BZgA7ASuKgcdhFwW9lfCSyUNFHSScBsYE1ns46IGN+6cWdxPPB1SUPX/7Ltb0r6EbBC0sXA48D5ALY3SloBPATsAS61vbcLeUcckiZNOOwF24hWOl4sbP8EeH2L+M+As/fTZgmwpObU4kXwUeZ5nsdHZajoYHPqy47pdgpxEOilqbNxEHvujOe6nUJE1Cj3nRERUSnFIiIiKqUb6iCUb9xGRKelWByEevUbtxGHuvH8i1qKRUREm8bzL2opFl30+J+/dlTt9jx9HHA4e57+6QGf48SPrR/VNSMOJVdfffWo2j399NO/3o7mHKO9bi/IAHdERFTKncVBaOqk54E9ZRsRnTJx4sQXbMeTFIuD0Ide90y3U4gYl1772tF1HR8K0g0VERGVcmcxgvE8TS4iolmKxQjG8zS5iIhm46JYnPbflo+q3TFP7WIC8PhTu0Z1jrWfunBU142I6DUZs4iIiErj4s5itJ4/8ugXbCMixqsUixH8YvZbup1CRERPSDdURERUOmiKhaQFkh6RtFnSVd3OJyJiPDkoioWkCcBfA28F5gAXSJrT3awiIsaPg6JYAPOBzbZ/YvtXwK3AuV3OKSJi3JDtbudQSdK7gAW2/0t5/x7gt2xfNuy4RcCi8vbVwCNjcPmpwFNjcJ6x1ot5Jaf2JKf29WJeh3pOv2G7b3jwYJkNpRaxfaqc7aXA0jG9sDRgu38szzkWejGv5NSe5NS+XsxrvOZ0sHRDDQIzm97PALZ2KZeIiHHnYCkWPwJmSzpJ0pHAQmBll3OKiBg3DopuKNt7JF0GfAuYANxke2OHLj+m3VpjqBfzSk7tSU7t68W8xmVOB8UAd0REdNfB0g0VERFdlGIRERGVUixG0GtLjEi6SdIOSRu6ncsQSTMlfU/SJkkbJV3eAzlNkrRG0gMlp090O6chkiZI+kdJ3+h2LkMkPSZpvaR1kga6nQ+ApJdK+oqkh8vfrd/ucj6vLn8+Q6+fS7qimzmVvP5r+Tu+QdItkibVdq2MWbRWlhj5J+D3aUzd/RFwge2HupjT7wLPAsttn9KtPJpJmgZMs32/pGOAtcB5Xf5zEnC07WclHQHcA1xu+95u5TRE0geAfmCK7bd3Ox9oFAug33bPfNFM0jLgB7Y/X2ZAHmX7mW7nBb/+t2ELjS8G/7SLeUyn8Xd7ju1fSloB3G775jqulzuL/eu5JUZs3w083c0chrO9zfb9ZX8XsAmY3uWcbPvZ8vaI8ur6b0WSZgB/AHy+27n0MklTgN8FbgSw/ateKRTF2cD/6WahaHI4MFnS4cBR1Pj9sxSL/ZsOPNH0fpAu/yPY6yTNAk4F7utuJr/u7lkH7ADutN31nIC/BK4Enu92IsMY+LaktWXJnG57JbAT+NvSZfd5Sb30BLKFwC3dTsL2FuDTwOPANuCfbX+7ruulWOxfW0uMRIOklwBfBa6w/fNu52N7r+15NL7tP19SV7vtJL0d2GF7bTfz2I8zbL+BxqrOl5buzm46HHgDcL3tU4FfAF0fMwQoXWLvAP6uB3I5lkZvx0nAK4CjJb27ruulWOxflhhpUxkX+CrwJdtf63Y+zUr3xV3Agi6ncgbwjjI+cCtwlqQvdjelBttby3YH8HUaXbDdNAgMNt0NfoVG8egFbwXut/1ktxMB3gw8anun7eeArwH/rq6LpVjsX5YYaUMZTL4R2GT7s93OB0BSn6SXlv3JNP6neribOdlebHuG7Vk0/i5913ZtvwW2S9LRZWICpavnLUBXZ9vZ3g48IenVJXQ20LUJE8NcQA90QRWPA6dLOqr8f3g2jTHDWhwUy310Q5eXGGlJ0i3AmcBUSYPAx23f2M2caPzG/B5gfRkjAPiI7du7mNM0YFmZtXIYsMJ2z0xV7THHA19v/FvD4cCXbX+zuykB8KfAl8ovaj8B/nOX80HSUTRmR76v27kA2L5P0leA+4E9wD9S47IfmTobERGV0g0VERGVUiwiIqJSikVERFRKsYiIiEopFhERUSnFIqImZTXXqW0ee7WkD9WdU8RopVhE1KB8xyPikJFiETGMpCslvb/sf07Sd8v+2ZK+KOmC8vyHDZL+oqnds5L+XNJ9wG83xSdL+qak95b3F0p6sDxv4wstrv9eST8qn3+1fBkMSeeXaz4g6e4Sm1ue3bGunHN2rX84MW6lWETs627gd8p+P/CSsv7Vm4AfA38BnAXMA94o6bxy7NHABtu/ZfueEnsJ8Pc0vhl9g6S5wEeBs2y/Hmj1sKiv2X5j+XwTcHGJfww4p8TfUWJ/AvxVWTSxn8a6ShFjLsUiYl9rgdPKmkm7gdU0/iH+HeAZ4K6yeNse4Es0nr0AsJfGgorNbgP+1vby8v4s4CtDDxqy3er5JKdI+oGk9cAfA3NL/IfAzeUOZaibazXwEUkfBn7D9i9fzA8esT8pFhHDlBU8H6OxHtE/AD8Afg84mcbibfvzL7b3Dov9EHhrWegNGkvfV62xczNwme3XAp8AJpW8/gT4MxqrIa+T9DLbX6Zxl/FL4FuSzmrnZ4w4UCkWEa3dDXyobH9Ao7tnHXAv8O8lTS2D2BcA3x/hPB8DfgZcV96vAv5Q0ssAJB3Xos0xwLbS9fXHQ0FJJ9u+z/bHgKeAmZJeCfzE9rU0VkV+3Wh/4IiRpFhEtPYDGqvXri7PLvgXGs+E3gYsBr4HPEDj2Qa3VZzrCmCSpGvKysVLgO9LegBotaz7f6fxtME7eeHS6p8aGlinUcQeAP4I2FBW/H0NsHz4ySLGQladjYiISrmziIiISikWERFRKcUiIiIqpVhERESlFIuIiKiUYhEREZVSLCIiotL/BxKUSVPvJm6gAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='workclass',y='income',data=EDA1,estimator=sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data\n",
    "EDA2=pd.get_dummies(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income            1.000000\n",
       "education-num     0.333539\n",
       "age               0.230700\n",
       "hours-per-week    0.227305\n",
       "capital-gain      0.222510\n",
       "sex               0.216744\n",
       "capital-loss      0.147657\n",
       "occupation        0.076817\n",
       "race              0.073077\n",
       "education         0.071532\n",
       "workclass         0.055015\n",
       "native-country    0.016642\n",
       "demogweight      -0.008029\n",
       "marital-status   -0.198008\n",
       "relationship     -0.251006\n",
       "Name: income, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1=EDA1.corr().sort_values('income',ascending=False)\n",
    "table1['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=EDA2.corr().sort_values('income_>50K.',ascending=False)\n",
    "table['income_>50K.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Massive Correlation Matrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col0 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col1 {\n",
       "            background-color:  #5673e0;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col2 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col3 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col4 {\n",
       "            background-color:  #5e7de7;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col5 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col6 {\n",
       "            background-color:  #4c66d6;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col7 {\n",
       "            background-color:  #7da0f9;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col8 {\n",
       "            background-color:  #6282ea;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col9 {\n",
       "            background-color:  #c6d6f1;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col10 {\n",
       "            background-color:  #6180e9;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col11 {\n",
       "            background-color:  #5d7ce6;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col12 {\n",
       "            background-color:  #8fb1fe;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col13 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col14 {\n",
       "            background-color:  #bbd1f8;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col0 {\n",
       "            background-color:  #81a4fb;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col1 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col2 {\n",
       "            background-color:  #4b64d5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col3 {\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col4 {\n",
       "            background-color:  #6485ec;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col5 {\n",
       "            background-color:  #6c8ff1;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col6 {\n",
       "            background-color:  #a2c1ff;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col7 {\n",
       "            background-color:  #a2c1ff;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col8 {\n",
       "            background-color:  #688aef;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col9 {\n",
       "            background-color:  #c9d7f0;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col10 {\n",
       "            background-color:  #5470de;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col11 {\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col12 {\n",
       "            background-color:  #a3c2fe;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col13 {\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col14 {\n",
       "            background-color:  #8badfd;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col0 {\n",
       "            background-color:  #6a8bef;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col1 {\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col2 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col3 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col4 {\n",
       "            background-color:  #4961d2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col5 {\n",
       "            background-color:  #86a9fc;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col6 {\n",
       "            background-color:  #516ddb;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col7 {\n",
       "            background-color:  #b7cff9;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col8 {\n",
       "            background-color:  #5470de;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col9 {\n",
       "            background-color:  #bbd1f8;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col10 {\n",
       "            background-color:  #4c66d6;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col11 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col12 {\n",
       "            background-color:  #779af7;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col13 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col14 {\n",
       "            background-color:  #799cf8;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col0 {\n",
       "            background-color:  #7a9df8;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col1 {\n",
       "            background-color:  #5a78e4;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col2 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col3 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col4 {\n",
       "            background-color:  #c4d5f3;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col5 {\n",
       "            background-color:  #7597f6;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col6 {\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col7 {\n",
       "            background-color:  #b5cdfa;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col8 {\n",
       "            background-color:  #5e7de7;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col9 {\n",
       "            background-color:  #afcafc;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col10 {\n",
       "            background-color:  #5470de;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col11 {\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col12 {\n",
       "            background-color:  #88abfd;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col13 {\n",
       "            background-color:  #5d7ce6;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col14 {\n",
       "            background-color:  #90b2fe;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col0 {\n",
       "            background-color:  #88abfd;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col1 {\n",
       "            background-color:  #6384eb;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col2 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col3 {\n",
       "            background-color:  #b9d0f9;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col4 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col5 {\n",
       "            background-color:  #6c8ff1;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col6 {\n",
       "            background-color:  #7396f5;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col7 {\n",
       "            background-color:  #a1c0ff;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col8 {\n",
       "            background-color:  #6384eb;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col9 {\n",
       "            background-color:  #b9d0f9;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col10 {\n",
       "            background-color:  #7093f3;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col11 {\n",
       "            background-color:  #6384eb;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col12 {\n",
       "            background-color:  #a5c3fe;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col13 {\n",
       "            background-color:  #5875e1;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col14 {\n",
       "            background-color:  #d4dbe6;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col0 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col1 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col2 {\n",
       "            background-color:  #5977e3;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col3 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col4 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col5 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col6 {\n",
       "            background-color:  #4c66d6;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col7 {\n",
       "            background-color:  #d8dce2;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col8 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col9 {\n",
       "            background-color:  #9abbff;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col10 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col11 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col12 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col13 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col14 {\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col0 {\n",
       "            background-color:  #7a9df8;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col1 {\n",
       "            background-color:  #a5c3fe;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col2 {\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col3 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col4 {\n",
       "            background-color:  #779af7;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col5 {\n",
       "            background-color:  #7a9df8;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col6 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col7 {\n",
       "            background-color:  #a5c3fe;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col8 {\n",
       "            background-color:  #5d7ce6;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col9 {\n",
       "            background-color:  #c6d6f1;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col10 {\n",
       "            background-color:  #536edd;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col11 {\n",
       "            background-color:  #516ddb;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col12 {\n",
       "            background-color:  #93b5fe;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col13 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col14 {\n",
       "            background-color:  #92b4fe;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col0 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col1 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col2 {\n",
       "            background-color:  #536edd;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col3 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col4 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col5 {\n",
       "            background-color:  #b1cbfc;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col6 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col7 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col8 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col9 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col10 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col11 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col12 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col13 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col14 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col0 {\n",
       "            background-color:  #85a8fc;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col1 {\n",
       "            background-color:  #6282ea;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col2 {\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col3 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col4 {\n",
       "            background-color:  #5e7de7;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col5 {\n",
       "            background-color:  #6b8df0;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col6 {\n",
       "            background-color:  #5470de;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col7 {\n",
       "            background-color:  #9dbdff;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col8 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col9 {\n",
       "            background-color:  #c7d7f0;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col10 {\n",
       "            background-color:  #4e68d8;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col11 {\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col12 {\n",
       "            background-color:  #86a9fc;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col13 {\n",
       "            background-color:  #7396f5;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col14 {\n",
       "            background-color:  #90b2fe;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col0 {\n",
       "            background-color:  #96b7ff;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col1 {\n",
       "            background-color:  #7295f4;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col2 {\n",
       "            background-color:  #5977e3;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col3 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col4 {\n",
       "            background-color:  #5977e3;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col5 {\n",
       "            background-color:  #5b7ae5;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col6 {\n",
       "            background-color:  #6b8df0;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col7 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col8 {\n",
       "            background-color:  #7597f6;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col9 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col10 {\n",
       "            background-color:  #5977e3;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col11 {\n",
       "            background-color:  #5977e3;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col12 {\n",
       "            background-color:  #bbd1f8;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col13 {\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col14 {\n",
       "            background-color:  #b7cff9;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col0 {\n",
       "            background-color:  #93b5fe;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col1 {\n",
       "            background-color:  #5d7ce6;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col2 {\n",
       "            background-color:  #516ddb;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col3 {\n",
       "            background-color:  #4e68d8;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col4 {\n",
       "            background-color:  #7a9df8;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col5 {\n",
       "            background-color:  #7295f4;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col6 {\n",
       "            background-color:  #5977e3;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col7 {\n",
       "            background-color:  #a9c6fd;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col8 {\n",
       "            background-color:  #5e7de7;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col9 {\n",
       "            background-color:  #bfd3f6;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col10 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col11 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col12 {\n",
       "            background-color:  #92b4fe;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col13 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col14 {\n",
       "            background-color:  #b9d0f9;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col0 {\n",
       "            background-color:  #8db0fe;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col1 {\n",
       "            background-color:  #5977e3;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col2 {\n",
       "            background-color:  #4c66d6;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col3 {\n",
       "            background-color:  #4961d2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col4 {\n",
       "            background-color:  #6c8ff1;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col5 {\n",
       "            background-color:  #7597f6;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col6 {\n",
       "            background-color:  #5875e1;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col7 {\n",
       "            background-color:  #a9c6fd;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col8 {\n",
       "            background-color:  #5f7fe8;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col9 {\n",
       "            background-color:  #bfd3f6;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col10 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col11 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col12 {\n",
       "            background-color:  #8badfd;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col13 {\n",
       "            background-color:  #4961d2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col14 {\n",
       "            background-color:  #a5c3fe;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col0 {\n",
       "            background-color:  #92b4fe;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col1 {\n",
       "            background-color:  #80a3fa;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col2 {\n",
       "            background-color:  #4b64d5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col3 {\n",
       "            background-color:  #516ddb;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col4 {\n",
       "            background-color:  #82a6fb;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col5 {\n",
       "            background-color:  #4b64d5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col6 {\n",
       "            background-color:  #6b8df0;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col7 {\n",
       "            background-color:  #7ea1fa;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col8 {\n",
       "            background-color:  #6788ee;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col9 {\n",
       "            background-color:  #e0dbd8;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col10 {\n",
       "            background-color:  #6384eb;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col11 {\n",
       "            background-color:  #5b7ae5;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col12 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col13 {\n",
       "            background-color:  #4961d2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col14 {\n",
       "            background-color:  #bad0f8;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col0 {\n",
       "            background-color:  #7da0f9;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col1 {\n",
       "            background-color:  #516ddb;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col2 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col3 {\n",
       "            background-color:  #5875e1;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col4 {\n",
       "            background-color:  #6384eb;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col5 {\n",
       "            background-color:  #799cf8;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col6 {\n",
       "            background-color:  #4e68d8;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col7 {\n",
       "            background-color:  #b3cdfb;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col8 {\n",
       "            background-color:  #84a7fc;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col9 {\n",
       "            background-color:  #b5cdfa;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col10 {\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col11 {\n",
       "            background-color:  #4c66d6;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col12 {\n",
       "            background-color:  #7b9ff9;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col13 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col14 {\n",
       "            background-color:  #80a3fa;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col0 {\n",
       "            background-color:  #bed2f6;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col1 {\n",
       "            background-color:  #6485ec;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col2 {\n",
       "            background-color:  #4e68d8;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col3 {\n",
       "            background-color:  #5a78e4;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col4 {\n",
       "            background-color:  #bed2f6;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col5 {\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col6 {\n",
       "            background-color:  #688aef;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col7 {\n",
       "            background-color:  #7ea1fa;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col8 {\n",
       "            background-color:  #7093f3;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col9 {\n",
       "            background-color:  #dedcdb;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col10 {\n",
       "            background-color:  #92b4fe;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col11 {\n",
       "            background-color:  #7a9df8;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col12 {\n",
       "            background-color:  #bad0f8;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col13 {\n",
       "            background-color:  #4e68d8;\n",
       "            color:  #000000;\n",
       "        }    #T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col14 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7f\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >age</th>        <th class=\"col_heading level0 col1\" >workclass</th>        <th class=\"col_heading level0 col2\" >demogweight</th>        <th class=\"col_heading level0 col3\" >education</th>        <th class=\"col_heading level0 col4\" >education-num</th>        <th class=\"col_heading level0 col5\" >marital-status</th>        <th class=\"col_heading level0 col6\" >occupation</th>        <th class=\"col_heading level0 col7\" >relationship</th>        <th class=\"col_heading level0 col8\" >race</th>        <th class=\"col_heading level0 col9\" >sex</th>        <th class=\"col_heading level0 col10\" >capital-gain</th>        <th class=\"col_heading level0 col11\" >capital-loss</th>        <th class=\"col_heading level0 col12\" >hours-per-week</th>        <th class=\"col_heading level0 col13\" >native-country</th>        <th class=\"col_heading level0 col14\" >income</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7flevel0_row0\" class=\"row_heading level0 row0\" >age</th>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col1\" class=\"data row0 col1\" >0.008177</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col2\" class=\"data row0 col2\" >-0.075810</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col3\" class=\"data row0 col3\" >-0.015288</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col4\" class=\"data row0 col4\" >0.032765</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col5\" class=\"data row0 col5\" >-0.263989</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col6\" class=\"data row0 col6\" >-0.015555</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col7\" class=\"data row0 col7\" >-0.260526</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col8\" class=\"data row0 col8\" >0.027069</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col9\" class=\"data row0 col9\" >0.084250</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col10\" class=\"data row0 col10\" >0.073591</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col11\" class=\"data row0 col11\" >0.056408</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col12\" class=\"data row0 col12\" >0.069045</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col13\" class=\"data row0 col13\" >-0.002499</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow0_col14\" class=\"data row0 col14\" >0.230700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7flevel0_row1\" class=\"row_heading level0 row1\" >workclass</th>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col0\" class=\"data row1 col0\" >0.008177</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col2\" class=\"data row1 col2\" >-0.013327</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col3\" class=\"data row1 col3\" >0.020791</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col4\" class=\"data row1 col4\" >0.052213</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col5\" class=\"data row1 col5\" >-0.064131</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col6\" class=\"data row1 col6\" >0.254039</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col7\" class=\"data row1 col7\" >-0.091820</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col8\" class=\"data row1 col8\" >0.048674</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col9\" class=\"data row1 col9\" >0.097349</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col10\" class=\"data row1 col10\" >0.030435</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col11\" class=\"data row1 col11\" >0.016066</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col12\" class=\"data row1 col12\" >0.141320</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col13\" class=\"data row1 col13\" >-0.008880</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow1_col14\" class=\"data row1 col14\" >0.055015</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7flevel0_row2\" class=\"row_heading level0 row2\" >demogweight</th>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col0\" class=\"data row2 col0\" >-0.075810</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col1\" class=\"data row2 col1\" >-0.013327</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col3\" class=\"data row2 col3\" >-0.027546</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col4\" class=\"data row2 col4\" >-0.043853</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col5\" class=\"data row2 col5\" >0.029521</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col6\" class=\"data row2 col6\" >0.001245</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col7\" class=\"data row2 col7\" >0.010333</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col8\" class=\"data row2 col8\" >-0.020728</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col9\" class=\"data row2 col9\" >0.029492</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col10\" class=\"data row2 col10\" >0.004366</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col11\" class=\"data row2 col11\" >-0.012152</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col12\" class=\"data row2 col12\" >-0.015179</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col13\" class=\"data row2 col13\" >-0.050835</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow2_col14\" class=\"data row2 col14\" >-0.008029</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7flevel0_row3\" class=\"row_heading level0 row3\" >education</th>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col0\" class=\"data row3 col0\" >-0.015288</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col1\" class=\"data row3 col1\" >0.020791</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col2\" class=\"data row3 col2\" >-0.027546</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col4\" class=\"data row3 col4\" >0.356520</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col5\" class=\"data row3 col5\" >-0.034734</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col6\" class=\"data row3 col6\" >-0.024293</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col7\" class=\"data row3 col7\" >-0.005428</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col8\" class=\"data row3 col8\" >0.011934</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col9\" class=\"data row3 col9\" >-0.031968</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col10\" class=\"data row3 col10\" >0.031156</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col11\" class=\"data row3 col11\" >0.014886</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col12\" class=\"data row3 col12\" >0.046071</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col13\" class=\"data row3 col13\" >0.065595</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow3_col14\" class=\"data row3 col14\" >0.071532</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7flevel0_row4\" class=\"row_heading level0 row4\" >education-num</th>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col0\" class=\"data row4 col0\" >0.032765</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col1\" class=\"data row4 col1\" >0.052213</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col2\" class=\"data row4 col2\" >-0.043853</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col3\" class=\"data row4 col3\" >0.356520</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col5\" class=\"data row4 col5\" >-0.066305</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col6\" class=\"data row4 col6\" >0.110272</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col7\" class=\"data row4 col7\" >-0.095476</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col8\" class=\"data row4 col8\" >0.031503</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col9\" class=\"data row4 col9\" >0.015325</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col10\" class=\"data row4 col10\" >0.120998</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col11\" class=\"data row4 col11\" >0.078483</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col12\" class=\"data row4 col12\" >0.145903</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col13\" class=\"data row4 col13\" >0.049267</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow4_col14\" class=\"data row4 col14\" >0.333539</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7flevel0_row5\" class=\"row_heading level0 row5\" >marital-status</th>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col0\" class=\"data row5 col0\" >-0.263989</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col1\" class=\"data row5 col1\" >-0.064131</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col2\" class=\"data row5 col2\" >0.029521</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col3\" class=\"data row5 col3\" >-0.034734</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col4\" class=\"data row5 col4\" >-0.066305</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col6\" class=\"data row5 col6\" >-0.015288</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col7\" class=\"data row5 col7\" >0.180593</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col8\" class=\"data row5 col8\" >-0.068641</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col9\" class=\"data row5 col9\" >-0.127836</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col10\" class=\"data row5 col10\" >-0.046271</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col11\" class=\"data row5 col11\" >-0.034631</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col12\" class=\"data row5 col12\" >-0.194108</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col13\" class=\"data row5 col13\" >-0.021026</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow5_col14\" class=\"data row5 col14\" >-0.198008</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7flevel0_row6\" class=\"row_heading level0 row6\" >occupation</th>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col0\" class=\"data row6 col0\" >-0.015555</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col1\" class=\"data row6 col1\" >0.254039</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col2\" class=\"data row6 col2\" >0.001245</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col3\" class=\"data row6 col3\" >-0.024293</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col4\" class=\"data row6 col4\" >0.110272</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col5\" class=\"data row6 col5\" >-0.015288</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col7\" class=\"data row6 col7\" >-0.081583</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col8\" class=\"data row6 col8\" >0.009514</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col9\" class=\"data row6 col9\" >0.083463</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col10\" class=\"data row6 col10\" >0.025865</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col11\" class=\"data row6 col11\" >0.020143</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col12\" class=\"data row6 col12\" >0.084114</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col13\" class=\"data row6 col13\" >-0.013004</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow6_col14\" class=\"data row6 col14\" >0.076817</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7flevel0_row7\" class=\"row_heading level0 row7\" >relationship</th>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col0\" class=\"data row7 col0\" >-0.260526</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col1\" class=\"data row7 col1\" >-0.091820</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col2\" class=\"data row7 col2\" >0.010333</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col3\" class=\"data row7 col3\" >-0.005428</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col4\" class=\"data row7 col4\" >-0.095476</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col5\" class=\"data row7 col5\" >0.180593</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col6\" class=\"data row7 col6\" >-0.081583</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col8\" class=\"data row7 col8\" >-0.116666</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col9\" class=\"data row7 col9\" >-0.582218</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col10\" class=\"data row7 col10\" >-0.058577</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col11\" class=\"data row7 col11\" >-0.059890</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col12\" class=\"data row7 col12\" >-0.249706</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col13\" class=\"data row7 col13\" >-0.010928</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow7_col14\" class=\"data row7 col14\" >-0.251006</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7flevel0_row8\" class=\"row_heading level0 row8\" >race</th>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col0\" class=\"data row8 col0\" >0.027069</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col1\" class=\"data row8 col1\" >0.048674</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col2\" class=\"data row8 col2\" >-0.020728</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col3\" class=\"data row8 col3\" >0.011934</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col4\" class=\"data row8 col4\" >0.031503</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col5\" class=\"data row8 col5\" >-0.068641</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col6\" class=\"data row8 col6\" >0.009514</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col7\" class=\"data row8 col7\" >-0.116666</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col8\" class=\"data row8 col8\" >1.000000</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col9\" class=\"data row8 col9\" >0.086851</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col10\" class=\"data row8 col10\" >0.010893</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col11\" class=\"data row8 col11\" >0.016526</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col12\" class=\"data row8 col12\" >0.040777</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col13\" class=\"data row8 col13\" >0.135892</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow8_col14\" class=\"data row8 col14\" >0.073077</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7flevel0_row9\" class=\"row_heading level0 row9\" >sex</th>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col0\" class=\"data row9 col0\" >0.084250</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col1\" class=\"data row9 col1\" >0.097349</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col2\" class=\"data row9 col2\" >0.029492</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col3\" class=\"data row9 col3\" >-0.031968</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col4\" class=\"data row9 col4\" >0.015325</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col5\" class=\"data row9 col5\" >-0.127836</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col6\" class=\"data row9 col6\" >0.083463</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col7\" class=\"data row9 col7\" >-0.582218</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col8\" class=\"data row9 col8\" >0.086851</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col9\" class=\"data row9 col9\" >1.000000</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col10\" class=\"data row9 col10\" >0.046675</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col11\" class=\"data row9 col11\" >0.047298</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col12\" class=\"data row9 col12\" >0.231300</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col13\" class=\"data row9 col13\" >-0.006655</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow9_col14\" class=\"data row9 col14\" >0.216744</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7flevel0_row10\" class=\"row_heading level0 row10\" >capital-gain</th>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col0\" class=\"data row10 col0\" >0.073591</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col1\" class=\"data row10 col1\" >0.030435</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col2\" class=\"data row10 col2\" >0.004366</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col3\" class=\"data row10 col3\" >0.031156</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col4\" class=\"data row10 col4\" >0.120998</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col5\" class=\"data row10 col5\" >-0.046271</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col6\" class=\"data row10 col6\" >0.025865</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col7\" class=\"data row10 col7\" >-0.058577</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col8\" class=\"data row10 col8\" >0.010893</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col9\" class=\"data row10 col9\" >0.046675</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col10\" class=\"data row10 col10\" >1.000000</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col11\" class=\"data row10 col11\" >-0.031346</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col12\" class=\"data row10 col12\" >0.079760</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col13\" class=\"data row10 col13\" >-0.002765</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow10_col14\" class=\"data row10 col14\" >0.222510</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7flevel0_row11\" class=\"row_heading level0 row11\" >capital-loss</th>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col0\" class=\"data row11 col0\" >0.056408</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col1\" class=\"data row11 col1\" >0.016066</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col2\" class=\"data row11 col2\" >-0.012152</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col3\" class=\"data row11 col3\" >0.014886</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col4\" class=\"data row11 col4\" >0.078483</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col5\" class=\"data row11 col5\" >-0.034631</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col6\" class=\"data row11 col6\" >0.020143</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col7\" class=\"data row11 col7\" >-0.059890</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col8\" class=\"data row11 col8\" >0.016526</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col9\" class=\"data row11 col9\" >0.047298</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col10\" class=\"data row11 col10\" >-0.031346</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col11\" class=\"data row11 col11\" >1.000000</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col12\" class=\"data row11 col12\" >0.055278</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col13\" class=\"data row11 col13\" >0.002363</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow11_col14\" class=\"data row11 col14\" >0.147657</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7flevel0_row12\" class=\"row_heading level0 row12\" >hours-per-week</th>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col0\" class=\"data row12 col0\" >0.069045</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col1\" class=\"data row12 col1\" >0.141320</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col2\" class=\"data row12 col2\" >-0.015179</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col3\" class=\"data row12 col3\" >0.046071</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col4\" class=\"data row12 col4\" >0.145903</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col5\" class=\"data row12 col5\" >-0.194108</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col6\" class=\"data row12 col6\" >0.084114</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col7\" class=\"data row12 col7\" >-0.249706</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col8\" class=\"data row12 col8\" >0.040777</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col9\" class=\"data row12 col9\" >0.231300</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col10\" class=\"data row12 col10\" >0.079760</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col11\" class=\"data row12 col11\" >0.055278</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col12\" class=\"data row12 col12\" >1.000000</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col13\" class=\"data row12 col13\" >-0.000620</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow12_col14\" class=\"data row12 col14\" >0.227305</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7flevel0_row13\" class=\"row_heading level0 row13\" >native-country</th>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col0\" class=\"data row13 col0\" >-0.002499</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col1\" class=\"data row13 col1\" >-0.008880</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col2\" class=\"data row13 col2\" >-0.050835</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col3\" class=\"data row13 col3\" >0.065595</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col4\" class=\"data row13 col4\" >0.049267</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col5\" class=\"data row13 col5\" >-0.021026</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col6\" class=\"data row13 col6\" >-0.013004</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col7\" class=\"data row13 col7\" >-0.010928</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col8\" class=\"data row13 col8\" >0.135892</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col9\" class=\"data row13 col9\" >-0.006655</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col10\" class=\"data row13 col10\" >-0.002765</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col11\" class=\"data row13 col11\" >0.002363</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col12\" class=\"data row13 col12\" >-0.000620</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col13\" class=\"data row13 col13\" >1.000000</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow13_col14\" class=\"data row13 col14\" >0.016642</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7flevel0_row14\" class=\"row_heading level0 row14\" >income</th>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col0\" class=\"data row14 col0\" >0.230700</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col1\" class=\"data row14 col1\" >0.055015</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col2\" class=\"data row14 col2\" >-0.008029</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col3\" class=\"data row14 col3\" >0.071532</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col4\" class=\"data row14 col4\" >0.333539</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col5\" class=\"data row14 col5\" >-0.198008</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col6\" class=\"data row14 col6\" >0.076817</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col7\" class=\"data row14 col7\" >-0.251006</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col8\" class=\"data row14 col8\" >0.073077</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col9\" class=\"data row14 col9\" >0.216744</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col10\" class=\"data row14 col10\" >0.222510</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col11\" class=\"data row14 col11\" >0.147657</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col12\" class=\"data row14 col12\" >0.227305</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col13\" class=\"data row14 col13\" >0.016642</td>\n",
       "                        <td id=\"T_64ba526d_5eaa_11eb_9859_147dda4ebf7frow14_col14\" class=\"data row14 col14\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19c14fc9730>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = EDA2.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   age             25000 non-null  int64\n",
      " 1   workclass       25000 non-null  int32\n",
      " 2   demogweight     25000 non-null  int64\n",
      " 3   education       25000 non-null  int32\n",
      " 4   education-num   25000 non-null  int64\n",
      " 5   marital-status  25000 non-null  int32\n",
      " 6   occupation      25000 non-null  int32\n",
      " 7   relationship    25000 non-null  int32\n",
      " 8   race            25000 non-null  int32\n",
      " 9   sex             25000 non-null  int32\n",
      " 10  capital-gain    25000 non-null  int64\n",
      " 11  capital-loss    25000 non-null  int64\n",
      " 12  hours-per-week  25000 non-null  int64\n",
      " 13  native-country  25000 non-null  int32\n",
      " 14  income          25000 non-null  int32\n",
      "dtypes: int32(9), int64(6)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19c15b26b20>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fig, ax = plt.subplots(figsize=(20,6))\n",
    "sns.countplot(data = data, x = \"income\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"USCensusTraining.csv\")\n",
    "test_data = pd.read_csv(\"USCensusTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['native-country'] = np.where(data[\"native-country\"]==\"United-States\", \"US\", \"others\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop \"education\" as it's repetitive with \"education_num\"\n",
    "data = data.drop([\"education\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number encoding on categorical variables\n",
    "cat_cols = [\"workclass\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\"]\n",
    "data = pd.get_dummies(data=data, columns=cat_cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"workclass_?\", \"marital-status_Divorced\", \"occupation_?\", \"relationship_Husband\", \n",
    "                  \"race_Other\", \"sex_Female\", \"native-country_others\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"income\"] = np.where(data[\"income\"]==\">50K.\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"income\", axis=1)\n",
    "y = data[\"income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "#save the scaler\n",
    "import pickle as pkl\n",
    "with open(\"scaler.pkl\", \"wb\") as outfile:\n",
    "    pkl.dump(scaler, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 0.4826 - accuracy: 0.7774\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 1s 527us/step - loss: 0.3708 - accuracy: 0.8230\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 1s 530us/step - loss: 0.3632 - accuracy: 0.8294\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 1s 531us/step - loss: 0.3541 - accuracy: 0.8354\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 1s 533us/step - loss: 0.3538 - accuracy: 0.8352\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 1s 531us/step - loss: 0.3487 - accuracy: 0.8379\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 1s 543us/step - loss: 0.3559 - accuracy: 0.8350\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 1s 538us/step - loss: 0.3538 - accuracy: 0.8411\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 1s 669us/step - loss: 0.3414 - accuracy: 0.8466\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 1s 530us/step - loss: 0.3436 - accuracy: 0.8448\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 1s 534us/step - loss: 0.3425 - accuracy: 0.8444\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 1s 542us/step - loss: 0.3440 - accuracy: 0.8446\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 1s 539us/step - loss: 0.3427 - accuracy: 0.8466\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 1s 541us/step - loss: 0.3408 - accuracy: 0.8485\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 1s 529us/step - loss: 0.3448 - accuracy: 0.8414\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 1s 532us/step - loss: 0.3368 - accuracy: 0.8477\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 1s 546us/step - loss: 0.3376 - accuracy: 0.8513\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 1s 539us/step - loss: 0.3339 - accuracy: 0.8497\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 1s 551us/step - loss: 0.3365 - accuracy: 0.8501\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 1s 531us/step - loss: 0.3328 - accuracy: 0.8538\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 1s 533us/step - loss: 0.3331 - accuracy: 0.8509\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 1s 535us/step - loss: 0.3365 - accuracy: 0.8486\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 1s 537us/step - loss: 0.3346 - accuracy: 0.8511\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 1s 538us/step - loss: 0.3301 - accuracy: 0.8514\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 1s 537us/step - loss: 0.3350 - accuracy: 0.8476\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 1s 538us/step - loss: 0.3304 - accuracy: 0.8518\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 1s 537us/step - loss: 0.3376 - accuracy: 0.8486\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 1s 532us/step - loss: 0.3331 - accuracy: 0.8501\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 1s 525us/step - loss: 0.3301 - accuracy: 0.8550\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 1s 528us/step - loss: 0.3305 - accuracy: 0.8505\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 1s 532us/step - loss: 0.3235 - accuracy: 0.8571\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 1s 527us/step - loss: 0.3307 - accuracy: 0.8530\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 2s 797us/step - loss: 0.3259 - accuracy: 0.8561\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 1s 691us/step - loss: 0.3330 - accuracy: 0.8496\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 1s 546us/step - loss: 0.3263 - accuracy: 0.8535\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 1s 519us/step - loss: 0.3290 - accuracy: 0.8537\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 1s 516us/step - loss: 0.3322 - accuracy: 0.8507\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 1s 517us/step - loss: 0.3326 - accuracy: 0.8525\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 1s 517us/step - loss: 0.3284 - accuracy: 0.8552\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 1s 518us/step - loss: 0.3313 - accuracy: 0.8527\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 1s 541us/step - loss: 0.3364 - accuracy: 0.8493\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 1s 580us/step - loss: 0.3290 - accuracy: 0.8534\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 1s 521us/step - loss: 0.3280 - accuracy: 0.8529\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 1s 520us/step - loss: 0.3293 - accuracy: 0.8547\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 1s 521us/step - loss: 0.3313 - accuracy: 0.8494\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 1s 518us/step - loss: 0.3306 - accuracy: 0.8542\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 1s 517us/step - loss: 0.3300 - accuracy: 0.8536\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 1s 520us/step - loss: 0.3281 - accuracy: 0.8525\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 1s 520us/step - loss: 0.3322 - accuracy: 0.8511\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 1s 524us/step - loss: 0.3380 - accuracy: 0.8472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19c16102880>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=45, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size = 10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 473us/step - loss: 0.3425 - accuracy: 0.8476\n",
      "Accuracy: 84.76%\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_valid, y_valid)\n",
    "print('Accuracy: %.2f' % (accuracy*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter Tuning  (GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_hidden = 1, neurons = 45, activation = \"relu\"):\n",
    "    model = Sequential()\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(neurons, input_dim = 45, kernel_initializer=\"uniform\", activation=activation))\n",
    "    model.add(Dense(1, kernel_initializer=\"uniform\", activation=\"sigmoid\"))\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = \"rmsprop\", metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 908us/step - loss: 0.4894 - accuracy: 0.7701 - val_loss: 0.3813 - val_accuracy: 0.8076\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3821 - accuracy: 0.8163 - val_loss: 0.3717 - val_accuracy: 0.8202\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 752us/step - loss: 0.3691 - accuracy: 0.8228 - val_loss: 0.3729 - val_accuracy: 0.8168\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3639 - accuracy: 0.8288 - val_loss: 0.3645 - val_accuracy: 0.8248\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 887us/step - loss: 0.3696 - accuracy: 0.8256 - val_loss: 0.3624 - val_accuracy: 0.8252\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 783us/step - loss: 0.3591 - accuracy: 0.8332 - val_loss: 0.3618 - val_accuracy: 0.8242\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3618 - accuracy: 0.8311 - val_loss: 0.3605 - val_accuracy: 0.8292\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3592 - accuracy: 0.8309 - val_loss: 0.3585 - val_accuracy: 0.8318\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 891us/step - loss: 0.3590 - accuracy: 0.8324 - val_loss: 0.3597 - val_accuracy: 0.8340\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 776us/step - loss: 0.3515 - accuracy: 0.8364 - val_loss: 0.3576 - val_accuracy: 0.8324\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3519 - accuracy: 0.8350 - val_loss: 0.3584 - val_accuracy: 0.8276\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3514 - accuracy: 0.8404 - val_loss: 0.3556 - val_accuracy: 0.8338\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3454 - accuracy: 0.8427 - val_loss: 0.3534 - val_accuracy: 0.8332\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3480 - accuracy: 0.8388 - val_loss: 0.3563 - val_accuracy: 0.8296\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3388 - accuracy: 0.8455 - val_loss: 0.3553 - val_accuracy: 0.8364\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3507 - accuracy: 0.8371 - val_loss: 0.3522 - val_accuracy: 0.8334\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3464 - accuracy: 0.8425 - val_loss: 0.3558 - val_accuracy: 0.8308\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3435 - accuracy: 0.8421 - val_loss: 0.3516 - val_accuracy: 0.8340\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3452 - accuracy: 0.8409 - val_loss: 0.3526 - val_accuracy: 0.8348\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 793us/step - loss: 0.3385 - accuracy: 0.8486 - val_loss: 0.3503 - val_accuracy: 0.8370\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.3565 - accuracy: 0.8368 - val_loss: 0.3499 - val_accuracy: 0.8378\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3441 - accuracy: 0.8425 - val_loss: 0.3492 - val_accuracy: 0.8404\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3378 - accuracy: 0.8501 - val_loss: 0.3488 - val_accuracy: 0.8384\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3418 - accuracy: 0.8435 - val_loss: 0.3466 - val_accuracy: 0.8408\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3417 - accuracy: 0.8435 - val_loss: 0.3467 - val_accuracy: 0.8428\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3441 - accuracy: 0.8435 - val_loss: 0.3465 - val_accuracy: 0.8408\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3446 - accuracy: 0.8442 - val_loss: 0.3479 - val_accuracy: 0.8386\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 763us/step - loss: 0.3364 - accuracy: 0.8485 - val_loss: 0.3448 - val_accuracy: 0.8434\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3419 - accuracy: 0.8468 - val_loss: 0.3440 - val_accuracy: 0.8444\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 795us/step - loss: 0.3392 - accuracy: 0.8489 - val_loss: 0.3459 - val_accuracy: 0.8444\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3372 - accuracy: 0.8467 - val_loss: 0.3431 - val_accuracy: 0.8448\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3306 - accuracy: 0.8533 - val_loss: 0.3453 - val_accuracy: 0.8426\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 767us/step - loss: 0.3373 - accuracy: 0.8518 - val_loss: 0.3447 - val_accuracy: 0.8426\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3427 - accuracy: 0.8465 - val_loss: 0.3425 - val_accuracy: 0.8448\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 901us/step - loss: 0.3383 - accuracy: 0.8462 - val_loss: 0.3426 - val_accuracy: 0.8470\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 922us/step - loss: 0.3364 - accuracy: 0.8489 - val_loss: 0.3409 - val_accuracy: 0.8466\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3310 - accuracy: 0.8539 - val_loss: 0.3423 - val_accuracy: 0.8456\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3360 - accuracy: 0.8506 - val_loss: 0.3402 - val_accuracy: 0.8458\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3396 - accuracy: 0.8474 - val_loss: 0.3415 - val_accuracy: 0.8456\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3321 - accuracy: 0.8537 - val_loss: 0.3404 - val_accuracy: 0.8484\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 811us/step - loss: 0.3378 - accuracy: 0.8514 - val_loss: 0.3440 - val_accuracy: 0.8470\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3344 - accuracy: 0.8516 - val_loss: 0.3394 - val_accuracy: 0.8474\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 731us/step - loss: 0.3253 - accuracy: 0.8542 - val_loss: 0.3399 - val_accuracy: 0.8450\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3316 - accuracy: 0.8523 - val_loss: 0.3437 - val_accuracy: 0.8440\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3285 - accuracy: 0.8556 - val_loss: 0.3394 - val_accuracy: 0.8476\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3384 - accuracy: 0.8470 - val_loss: 0.3406 - val_accuracy: 0.8446\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 723us/step - loss: 0.3358 - accuracy: 0.8495 - val_loss: 0.3402 - val_accuracy: 0.8446\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3321 - accuracy: 0.8502 - val_loss: 0.3391 - val_accuracy: 0.8464\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3326 - accuracy: 0.8507 - val_loss: 0.3403 - val_accuracy: 0.8480\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3424 - accuracy: 0.8462 - val_loss: 0.3385 - val_accuracy: 0.8464\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3365 - accuracy: 0.8483 - val_loss: 0.3419 - val_accuracy: 0.8442\n",
      "Epoch 52/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3351 - accuracy: 0.8492 - val_loss: 0.3395 - val_accuracy: 0.8442\n",
      "Epoch 53/1000\n",
      "1600/1600 [==============================] - 1s 856us/step - loss: 0.3315 - accuracy: 0.8546 - val_loss: 0.3380 - val_accuracy: 0.8466\n",
      "Epoch 54/1000\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.3316 - accuracy: 0.8527 - val_loss: 0.3396 - val_accuracy: 0.8440\n",
      "Epoch 55/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3263 - accuracy: 0.8508 - val_loss: 0.3387 - val_accuracy: 0.8462\n",
      "Epoch 56/1000\n",
      "1600/1600 [==============================] - 1s 763us/step - loss: 0.3339 - accuracy: 0.8520 - val_loss: 0.3420 - val_accuracy: 0.8468\n",
      "Epoch 57/1000\n",
      "1600/1600 [==============================] - 1s 873us/step - loss: 0.3325 - accuracy: 0.8509 - val_loss: 0.3406 - val_accuracy: 0.8468\n",
      "Epoch 58/1000\n",
      "1600/1600 [==============================] - 2s 939us/step - loss: 0.3330 - accuracy: 0.8501 - val_loss: 0.3391 - val_accuracy: 0.8436\n",
      "Epoch 59/1000\n",
      "1600/1600 [==============================] - 1s 780us/step - loss: 0.3352 - accuracy: 0.8487 - val_loss: 0.3396 - val_accuracy: 0.8426\n",
      "Epoch 60/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3351 - accuracy: 0.8471 - val_loss: 0.3414 - val_accuracy: 0.8480\n",
      "Epoch 61/1000\n",
      "1600/1600 [==============================] - 2s 971us/step - loss: 0.3308 - accuracy: 0.8511 - val_loss: 0.3384 - val_accuracy: 0.8472\n",
      "Epoch 62/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3329 - accuracy: 0.8539 - val_loss: 0.3391 - val_accuracy: 0.8452\n",
      "Epoch 63/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3273 - accuracy: 0.8529 - val_loss: 0.3375 - val_accuracy: 0.8472\n",
      "Epoch 64/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3283 - accuracy: 0.8516 - val_loss: 0.3383 - val_accuracy: 0.8448\n",
      "Epoch 65/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3341 - accuracy: 0.8492 - val_loss: 0.3391 - val_accuracy: 0.8468\n",
      "Epoch 66/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3309 - accuracy: 0.8508 - val_loss: 0.3387 - val_accuracy: 0.8464\n",
      "Epoch 67/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3306 - accuracy: 0.8516 - val_loss: 0.3384 - val_accuracy: 0.8470\n",
      "Epoch 68/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3268 - accuracy: 0.8509 - val_loss: 0.3397 - val_accuracy: 0.8460\n",
      "Epoch 69/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3351 - accuracy: 0.8483 - val_loss: 0.3388 - val_accuracy: 0.8444\n",
      "Epoch 70/1000\n",
      "1600/1600 [==============================] - 1s 781us/step - loss: 0.3258 - accuracy: 0.8535 - val_loss: 0.3370 - val_accuracy: 0.8470\n",
      "Epoch 71/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3348 - accuracy: 0.8504 - val_loss: 0.3407 - val_accuracy: 0.8438\n",
      "Epoch 72/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3218 - accuracy: 0.8561 - val_loss: 0.3396 - val_accuracy: 0.8444\n",
      "Epoch 73/1000\n",
      "1600/1600 [==============================] - 1s 777us/step - loss: 0.3364 - accuracy: 0.8501 - val_loss: 0.3368 - val_accuracy: 0.8476\n",
      "Epoch 74/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3311 - accuracy: 0.8537 - val_loss: 0.3367 - val_accuracy: 0.8464\n",
      "Epoch 75/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3227 - accuracy: 0.8559 - val_loss: 0.3383 - val_accuracy: 0.8438\n",
      "Epoch 76/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3337 - accuracy: 0.8523 - val_loss: 0.3368 - val_accuracy: 0.8466\n",
      "Epoch 77/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3369 - accuracy: 0.8506 - val_loss: 0.3392 - val_accuracy: 0.8468\n",
      "Epoch 78/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3310 - accuracy: 0.8505 - val_loss: 0.3394 - val_accuracy: 0.8444\n",
      "Epoch 79/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3252 - accuracy: 0.8573 - val_loss: 0.3369 - val_accuracy: 0.8462\n",
      "Epoch 80/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3325 - accuracy: 0.8526 - val_loss: 0.3372 - val_accuracy: 0.8454\n",
      "Epoch 81/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3342 - accuracy: 0.8498 - val_loss: 0.3379 - val_accuracy: 0.8454\n",
      "Epoch 82/1000\n",
      "1600/1600 [==============================] - 1s 676us/step - loss: 0.3327 - accuracy: 0.8541 - val_loss: 0.3375 - val_accuracy: 0.8450\n",
      "Epoch 83/1000\n",
      "1600/1600 [==============================] - 1s 775us/step - loss: 0.3359 - accuracy: 0.8478 - val_loss: 0.3392 - val_accuracy: 0.8468\n",
      "Epoch 84/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3319 - accuracy: 0.8509 - val_loss: 0.3405 - val_accuracy: 0.8458\n",
      "400/400 [==============================] - 0s 740us/step - loss: 0.3279 - accuracy: 0.8528\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 740us/step - loss: 0.4871 - accuracy: 0.7700 - val_loss: 0.3803 - val_accuracy: 0.8120\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 673us/step - loss: 0.3742 - accuracy: 0.8203 - val_loss: 0.3698 - val_accuracy: 0.8196\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3624 - accuracy: 0.8318 - val_loss: 0.3687 - val_accuracy: 0.8176\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3646 - accuracy: 0.8246 - val_loss: 0.3631 - val_accuracy: 0.8250\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3638 - accuracy: 0.8316 - val_loss: 0.3622 - val_accuracy: 0.8258\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3516 - accuracy: 0.8346 - val_loss: 0.3607 - val_accuracy: 0.8242\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 683us/step - loss: 0.3533 - accuracy: 0.8375 - val_loss: 0.3604 - val_accuracy: 0.8256\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3599 - accuracy: 0.8358 - val_loss: 0.3587 - val_accuracy: 0.8316\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3617 - accuracy: 0.8323 - val_loss: 0.3575 - val_accuracy: 0.8278\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3501 - accuracy: 0.8396 - val_loss: 0.3552 - val_accuracy: 0.8312\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 663us/step - loss: 0.3562 - accuracy: 0.8382 - val_loss: 0.3544 - val_accuracy: 0.8324\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3458 - accuracy: 0.8415 - val_loss: 0.3548 - val_accuracy: 0.8312\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3498 - accuracy: 0.8395 - val_loss: 0.3538 - val_accuracy: 0.8324\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 663us/step - loss: 0.3472 - accuracy: 0.8424 - val_loss: 0.3526 - val_accuracy: 0.8380\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3518 - accuracy: 0.8429 - val_loss: 0.3530 - val_accuracy: 0.8350\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 776us/step - loss: 0.3462 - accuracy: 0.8409 - val_loss: 0.3499 - val_accuracy: 0.8348\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3458 - accuracy: 0.8426 - val_loss: 0.3486 - val_accuracy: 0.8388\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3395 - accuracy: 0.8465 - val_loss: 0.3469 - val_accuracy: 0.8416\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3397 - accuracy: 0.8494 - val_loss: 0.3474 - val_accuracy: 0.8418\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3422 - accuracy: 0.8456 - val_loss: 0.3459 - val_accuracy: 0.8434\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 656us/step - loss: 0.3418 - accuracy: 0.8445 - val_loss: 0.3492 - val_accuracy: 0.8450\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 655us/step - loss: 0.3380 - accuracy: 0.8456 - val_loss: 0.3469 - val_accuracy: 0.8454\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3394 - accuracy: 0.8480 - val_loss: 0.3452 - val_accuracy: 0.8450\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3371 - accuracy: 0.8460 - val_loss: 0.3437 - val_accuracy: 0.8434\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3416 - accuracy: 0.8505 - val_loss: 0.3449 - val_accuracy: 0.8418\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3348 - accuracy: 0.8502 - val_loss: 0.3423 - val_accuracy: 0.8444\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3362 - accuracy: 0.8511 - val_loss: 0.3450 - val_accuracy: 0.8472\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3337 - accuracy: 0.8502 - val_loss: 0.3420 - val_accuracy: 0.8466\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3325 - accuracy: 0.8515 - val_loss: 0.3463 - val_accuracy: 0.8464\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3465 - accuracy: 0.8460 - val_loss: 0.3436 - val_accuracy: 0.8446\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 670us/step - loss: 0.3368 - accuracy: 0.8446 - val_loss: 0.3419 - val_accuracy: 0.8468\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 876us/step - loss: 0.3290 - accuracy: 0.8528 - val_loss: 0.3438 - val_accuracy: 0.8424\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3362 - accuracy: 0.8494 - val_loss: 0.3421 - val_accuracy: 0.8450\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3398 - accuracy: 0.8502 - val_loss: 0.3444 - val_accuracy: 0.8458\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3362 - accuracy: 0.8510 - val_loss: 0.3455 - val_accuracy: 0.8424\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3313 - accuracy: 0.8498 - val_loss: 0.3423 - val_accuracy: 0.8462\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 851us/step - loss: 0.3315 - accuracy: 0.8526 - val_loss: 0.3421 - val_accuracy: 0.8478\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3317 - accuracy: 0.8531 - val_loss: 0.3431 - val_accuracy: 0.8450\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3281 - accuracy: 0.8549 - val_loss: 0.3453 - val_accuracy: 0.8426\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3331 - accuracy: 0.8541 - val_loss: 0.3443 - val_accuracy: 0.8426\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 668us/step - loss: 0.3335 - accuracy: 0.8522 - val_loss: 0.3421 - val_accuracy: 0.8472\n",
      "400/400 [==============================] - 0s 692us/step - loss: 0.3298 - accuracy: 0.8535\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 747us/step - loss: 0.4833 - accuracy: 0.7797 - val_loss: 0.3773 - val_accuracy: 0.8134\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3787 - accuracy: 0.8204 - val_loss: 0.3696 - val_accuracy: 0.8194\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3704 - accuracy: 0.8197 - val_loss: 0.3672 - val_accuracy: 0.8206\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 698us/step - loss: 0.3650 - accuracy: 0.8281 - val_loss: 0.3651 - val_accuracy: 0.8330\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3574 - accuracy: 0.8361 - val_loss: 0.3619 - val_accuracy: 0.8264\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3604 - accuracy: 0.8333 - val_loss: 0.3618 - val_accuracy: 0.8336\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3501 - accuracy: 0.8362 - val_loss: 0.3570 - val_accuracy: 0.8316\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 664us/step - loss: 0.3556 - accuracy: 0.8342 - val_loss: 0.3569 - val_accuracy: 0.8326\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3467 - accuracy: 0.8419 - val_loss: 0.3543 - val_accuracy: 0.8354\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3503 - accuracy: 0.8406 - val_loss: 0.3542 - val_accuracy: 0.8326\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3503 - accuracy: 0.8401 - val_loss: 0.3531 - val_accuracy: 0.8334\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 874us/step - loss: 0.3494 - accuracy: 0.8375 - val_loss: 0.3528 - val_accuracy: 0.8358\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 808us/step - loss: 0.3493 - accuracy: 0.8381 - val_loss: 0.3534 - val_accuracy: 0.8338\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3524 - accuracy: 0.8376 - val_loss: 0.3518 - val_accuracy: 0.8374\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 808us/step - loss: 0.3423 - accuracy: 0.8463 - val_loss: 0.3528 - val_accuracy: 0.8394\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3494 - accuracy: 0.8411 - val_loss: 0.3504 - val_accuracy: 0.8394\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3464 - accuracy: 0.8453 - val_loss: 0.3524 - val_accuracy: 0.8374\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3480 - accuracy: 0.8426 - val_loss: 0.3505 - val_accuracy: 0.8396\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 802us/step - loss: 0.3453 - accuracy: 0.8467 - val_loss: 0.3504 - val_accuracy: 0.8418\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3486 - accuracy: 0.8424 - val_loss: 0.3505 - val_accuracy: 0.8412\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3374 - accuracy: 0.8493 - val_loss: 0.3487 - val_accuracy: 0.8418\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 713us/step - loss: 0.3378 - accuracy: 0.8516 - val_loss: 0.3457 - val_accuracy: 0.8440\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 773us/step - loss: 0.3389 - accuracy: 0.8470 - val_loss: 0.3449 - val_accuracy: 0.8448\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3412 - accuracy: 0.8464 - val_loss: 0.3479 - val_accuracy: 0.8392\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 670us/step - loss: 0.3427 - accuracy: 0.8471 - val_loss: 0.3439 - val_accuracy: 0.8438\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3368 - accuracy: 0.8495 - val_loss: 0.3428 - val_accuracy: 0.8460\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3339 - accuracy: 0.8486 - val_loss: 0.3468 - val_accuracy: 0.8454\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3296 - accuracy: 0.8499 - val_loss: 0.3451 - val_accuracy: 0.8444\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 698us/step - loss: 0.3291 - accuracy: 0.8479 - val_loss: 0.3421 - val_accuracy: 0.8452\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3279 - accuracy: 0.8568 - val_loss: 0.3432 - val_accuracy: 0.8462\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3323 - accuracy: 0.8494 - val_loss: 0.3418 - val_accuracy: 0.8470\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 756us/step - loss: 0.3287 - accuracy: 0.8496 - val_loss: 0.3413 - val_accuracy: 0.8470\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3333 - accuracy: 0.8502 - val_loss: 0.3409 - val_accuracy: 0.8468\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 851us/step - loss: 0.3306 - accuracy: 0.8514 - val_loss: 0.3435 - val_accuracy: 0.8468\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3247 - accuracy: 0.8515 - val_loss: 0.3417 - val_accuracy: 0.8462\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 713us/step - loss: 0.3386 - accuracy: 0.8500 - val_loss: 0.3470 - val_accuracy: 0.8468\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3326 - accuracy: 0.8480 - val_loss: 0.3419 - val_accuracy: 0.8464\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 815us/step - loss: 0.3266 - accuracy: 0.8506 - val_loss: 0.3447 - val_accuracy: 0.8442\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 828us/step - loss: 0.3289 - accuracy: 0.8528 - val_loss: 0.3403 - val_accuracy: 0.8478\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3356 - accuracy: 0.8483 - val_loss: 0.3432 - val_accuracy: 0.8470\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3340 - accuracy: 0.8465 - val_loss: 0.3428 - val_accuracy: 0.8448\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 926us/step - loss: 0.3329 - accuracy: 0.8522 - val_loss: 0.3446 - val_accuracy: 0.8464\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3320 - accuracy: 0.8524 - val_loss: 0.3425 - val_accuracy: 0.8468\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 777us/step - loss: 0.3338 - accuracy: 0.8514 - val_loss: 0.3447 - val_accuracy: 0.8472\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3280 - accuracy: 0.8552 - val_loss: 0.3442 - val_accuracy: 0.8440\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3333 - accuracy: 0.8526 - val_loss: 0.3404 - val_accuracy: 0.8478\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3342 - accuracy: 0.8518 - val_loss: 0.3447 - val_accuracy: 0.8464\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3317 - accuracy: 0.8513 - val_loss: 0.3424 - val_accuracy: 0.8474\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3305 - accuracy: 0.8517 - val_loss: 0.3401 - val_accuracy: 0.8472\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3262 - accuracy: 0.8529 - val_loss: 0.3458 - val_accuracy: 0.8474\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3341 - accuracy: 0.8470 - val_loss: 0.3427 - val_accuracy: 0.8466\n",
      "Epoch 52/1000\n",
      "1600/1600 [==============================] - 1s 830us/step - loss: 0.3287 - accuracy: 0.8537 - val_loss: 0.3425 - val_accuracy: 0.8470\n",
      "Epoch 53/1000\n",
      "1600/1600 [==============================] - 1s 923us/step - loss: 0.3253 - accuracy: 0.8546 - val_loss: 0.3425 - val_accuracy: 0.8462\n",
      "Epoch 54/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3359 - accuracy: 0.8469 - val_loss: 0.3404 - val_accuracy: 0.8476\n",
      "Epoch 55/1000\n",
      "1600/1600 [==============================] - 1s 777us/step - loss: 0.3336 - accuracy: 0.8470 - val_loss: 0.3415 - val_accuracy: 0.8474\n",
      "Epoch 56/1000\n",
      "1600/1600 [==============================] - 1s 794us/step - loss: 0.3308 - accuracy: 0.8529 - val_loss: 0.3404 - val_accuracy: 0.8476\n",
      "Epoch 57/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3251 - accuracy: 0.8578 - val_loss: 0.3385 - val_accuracy: 0.8470\n",
      "Epoch 58/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3262 - accuracy: 0.8548 - val_loss: 0.3400 - val_accuracy: 0.8468\n",
      "Epoch 59/1000\n",
      "1600/1600 [==============================] - 1s 835us/step - loss: 0.3291 - accuracy: 0.8536 - val_loss: 0.3418 - val_accuracy: 0.8466\n",
      "Epoch 60/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3311 - accuracy: 0.8495 - val_loss: 0.3447 - val_accuracy: 0.8476\n",
      "Epoch 61/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3268 - accuracy: 0.8559 - val_loss: 0.3424 - val_accuracy: 0.8466\n",
      "Epoch 62/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3332 - accuracy: 0.8516 - val_loss: 0.3418 - val_accuracy: 0.8458\n",
      "Epoch 63/1000\n",
      "1600/1600 [==============================] - 1s 919us/step - loss: 0.3289 - accuracy: 0.8551 - val_loss: 0.3408 - val_accuracy: 0.8450\n",
      "Epoch 64/1000\n",
      "1600/1600 [==============================] - 1s 761us/step - loss: 0.3255 - accuracy: 0.8556 - val_loss: 0.3403 - val_accuracy: 0.8460\n",
      "Epoch 65/1000\n",
      "1600/1600 [==============================] - 1s 859us/step - loss: 0.3218 - accuracy: 0.8573 - val_loss: 0.3412 - val_accuracy: 0.8468\n",
      "Epoch 66/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3300 - accuracy: 0.8511 - val_loss: 0.3402 - val_accuracy: 0.8456\n",
      "Epoch 67/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3277 - accuracy: 0.8540 - val_loss: 0.3381 - val_accuracy: 0.8470\n",
      "Epoch 68/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3346 - accuracy: 0.8502 - val_loss: 0.3399 - val_accuracy: 0.8470\n",
      "Epoch 69/1000\n",
      "1600/1600 [==============================] - 1s 928us/step - loss: 0.3353 - accuracy: 0.8510 - val_loss: 0.3401 - val_accuracy: 0.8466\n",
      "Epoch 70/1000\n",
      "1600/1600 [==============================] - 2s 989us/step - loss: 0.3286 - accuracy: 0.8563 - val_loss: 0.3403 - val_accuracy: 0.8468\n",
      "Epoch 71/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3286 - accuracy: 0.8515 - val_loss: 0.3404 - val_accuracy: 0.8462\n",
      "Epoch 72/1000\n",
      "1600/1600 [==============================] - 1s 787us/step - loss: 0.3290 - accuracy: 0.8524 - val_loss: 0.3441 - val_accuracy: 0.8452\n",
      "Epoch 73/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3234 - accuracy: 0.8560 - val_loss: 0.3392 - val_accuracy: 0.8478\n",
      "Epoch 74/1000\n",
      "1600/1600 [==============================] - 1s 693us/step - loss: 0.3252 - accuracy: 0.8536 - val_loss: 0.3388 - val_accuracy: 0.8460\n",
      "Epoch 75/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3266 - accuracy: 0.8554 - val_loss: 0.3429 - val_accuracy: 0.8470\n",
      "Epoch 76/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3302 - accuracy: 0.8532 - val_loss: 0.3435 - val_accuracy: 0.8444\n",
      "Epoch 77/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3256 - accuracy: 0.8528 - val_loss: 0.3401 - val_accuracy: 0.8452\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.3400 - accuracy: 0.85 - 0s 692us/step - loss: 0.3388 - accuracy: 0.8533\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 832us/step - loss: 0.4870 - accuracy: 0.7774 - val_loss: 0.3788 - val_accuracy: 0.8184\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3771 - accuracy: 0.8185 - val_loss: 0.3711 - val_accuracy: 0.8184\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3625 - accuracy: 0.8287 - val_loss: 0.3675 - val_accuracy: 0.8202\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3610 - accuracy: 0.8332 - val_loss: 0.3637 - val_accuracy: 0.8278\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 713us/step - loss: 0.3565 - accuracy: 0.8333 - val_loss: 0.3633 - val_accuracy: 0.8242\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 806us/step - loss: 0.3648 - accuracy: 0.8288 - val_loss: 0.3613 - val_accuracy: 0.8320\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3532 - accuracy: 0.8360 - val_loss: 0.3595 - val_accuracy: 0.8244\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 812us/step - loss: 0.3534 - accuracy: 0.8370 - val_loss: 0.3577 - val_accuracy: 0.8306\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3551 - accuracy: 0.8371 - val_loss: 0.3575 - val_accuracy: 0.8268\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3528 - accuracy: 0.8355 - val_loss: 0.3561 - val_accuracy: 0.8286\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 782us/step - loss: 0.3512 - accuracy: 0.8379 - val_loss: 0.3570 - val_accuracy: 0.8356\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3542 - accuracy: 0.8366 - val_loss: 0.3552 - val_accuracy: 0.8322\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3530 - accuracy: 0.8382 - val_loss: 0.3542 - val_accuracy: 0.8312\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 832us/step - loss: 0.3574 - accuracy: 0.8373 - val_loss: 0.3550 - val_accuracy: 0.8322\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3524 - accuracy: 0.8420 - val_loss: 0.3537 - val_accuracy: 0.8326\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3487 - accuracy: 0.8408 - val_loss: 0.3539 - val_accuracy: 0.8340\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 880us/step - loss: 0.3494 - accuracy: 0.8403 - val_loss: 0.3521 - val_accuracy: 0.8356\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3416 - accuracy: 0.8446 - val_loss: 0.3504 - val_accuracy: 0.8368\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3409 - accuracy: 0.8474 - val_loss: 0.3496 - val_accuracy: 0.8378\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3472 - accuracy: 0.8397 - val_loss: 0.3487 - val_accuracy: 0.8376\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.3424 - accuracy: 0.8451 - val_loss: 0.3490 - val_accuracy: 0.8382\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 849us/step - loss: 0.3394 - accuracy: 0.8486 - val_loss: 0.3476 - val_accuracy: 0.8392\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 793us/step - loss: 0.3422 - accuracy: 0.8438 - val_loss: 0.3464 - val_accuracy: 0.8400\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3421 - accuracy: 0.8451 - val_loss: 0.3480 - val_accuracy: 0.8370\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 2s 975us/step - loss: 0.3374 - accuracy: 0.8500 - val_loss: 0.3444 - val_accuracy: 0.8418\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3418 - accuracy: 0.8490 - val_loss: 0.3466 - val_accuracy: 0.8424\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 983us/step - loss: 0.3401 - accuracy: 0.8502 - val_loss: 0.3438 - val_accuracy: 0.8432\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3376 - accuracy: 0.8492 - val_loss: 0.3443 - val_accuracy: 0.8432\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 852us/step - loss: 0.3389 - accuracy: 0.8469 - val_loss: 0.3436 - val_accuracy: 0.8436\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 800us/step - loss: 0.3325 - accuracy: 0.8540 - val_loss: 0.3434 - val_accuracy: 0.8448\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3254 - accuracy: 0.8580 - val_loss: 0.3417 - val_accuracy: 0.8444\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 2s 961us/step - loss: 0.3362 - accuracy: 0.8469 - val_loss: 0.3423 - val_accuracy: 0.8430\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3332 - accuracy: 0.8533 - val_loss: 0.3424 - val_accuracy: 0.8448\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.3318 - accuracy: 0.8507 - val_loss: 0.3416 - val_accuracy: 0.8432\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 813us/step - loss: 0.3282 - accuracy: 0.8543 - val_loss: 0.3412 - val_accuracy: 0.8476\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3336 - accuracy: 0.8527 - val_loss: 0.3399 - val_accuracy: 0.8466\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3292 - accuracy: 0.8539 - val_loss: 0.3418 - val_accuracy: 0.8426\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 830us/step - loss: 0.3291 - accuracy: 0.8494 - val_loss: 0.3419 - val_accuracy: 0.8476\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3309 - accuracy: 0.8530 - val_loss: 0.3430 - val_accuracy: 0.8470\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3270 - accuracy: 0.8537 - val_loss: 0.3458 - val_accuracy: 0.8476\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3286 - accuracy: 0.8547 - val_loss: 0.3416 - val_accuracy: 0.8468\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3328 - accuracy: 0.8504 - val_loss: 0.3417 - val_accuracy: 0.8482\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 863us/step - loss: 0.3348 - accuracy: 0.8518 - val_loss: 0.3417 - val_accuracy: 0.8422\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3319 - accuracy: 0.8504 - val_loss: 0.3424 - val_accuracy: 0.8430\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 746us/step - loss: 0.3242 - accuracy: 0.8570 - val_loss: 0.3386 - val_accuracy: 0.8486\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 798us/step - loss: 0.3370 - accuracy: 0.8482 - val_loss: 0.3394 - val_accuracy: 0.8458\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3335 - accuracy: 0.8520 - val_loss: 0.3396 - val_accuracy: 0.8494\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 756us/step - loss: 0.3332 - accuracy: 0.8484 - val_loss: 0.3405 - val_accuracy: 0.8436\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 765us/step - loss: 0.3293 - accuracy: 0.8528 - val_loss: 0.3382 - val_accuracy: 0.8486\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3390 - accuracy: 0.8510 - val_loss: 0.3389 - val_accuracy: 0.8456\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 1s 876us/step - loss: 0.3365 - accuracy: 0.8480 - val_loss: 0.3435 - val_accuracy: 0.8440\n",
      "Epoch 52/1000\n",
      "1600/1600 [==============================] - 1s 751us/step - loss: 0.3305 - accuracy: 0.8542 - val_loss: 0.3420 - val_accuracy: 0.8478\n",
      "Epoch 53/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3280 - accuracy: 0.8540 - val_loss: 0.3391 - val_accuracy: 0.8438\n",
      "Epoch 54/1000\n",
      "1600/1600 [==============================] - 1s 789us/step - loss: 0.3299 - accuracy: 0.8498 - val_loss: 0.3393 - val_accuracy: 0.8482\n",
      "Epoch 55/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3268 - accuracy: 0.8523 - val_loss: 0.3413 - val_accuracy: 0.8440\n",
      "Epoch 56/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3300 - accuracy: 0.8550 - val_loss: 0.3389 - val_accuracy: 0.8434\n",
      "Epoch 57/1000\n",
      "1600/1600 [==============================] - 1s 774us/step - loss: 0.3312 - accuracy: 0.8512 - val_loss: 0.3381 - val_accuracy: 0.8448\n",
      "Epoch 58/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3357 - accuracy: 0.8492 - val_loss: 0.3416 - val_accuracy: 0.8436\n",
      "Epoch 59/1000\n",
      "1600/1600 [==============================] - 1s 793us/step - loss: 0.3360 - accuracy: 0.8531 - val_loss: 0.3395 - val_accuracy: 0.8446\n",
      "Epoch 60/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3329 - accuracy: 0.8529 - val_loss: 0.3382 - val_accuracy: 0.8494\n",
      "Epoch 61/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3305 - accuracy: 0.8513 - val_loss: 0.3401 - val_accuracy: 0.8474\n",
      "Epoch 62/1000\n",
      "1600/1600 [==============================] - 1s 723us/step - loss: 0.3247 - accuracy: 0.8547 - val_loss: 0.3371 - val_accuracy: 0.8486\n",
      "Epoch 63/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3342 - accuracy: 0.8542 - val_loss: 0.3378 - val_accuracy: 0.8466\n",
      "Epoch 64/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3268 - accuracy: 0.8546 - val_loss: 0.3380 - val_accuracy: 0.8492\n",
      "Epoch 65/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3328 - accuracy: 0.8493 - val_loss: 0.3376 - val_accuracy: 0.8472\n",
      "Epoch 66/1000\n",
      "1600/1600 [==============================] - 1s 698us/step - loss: 0.3333 - accuracy: 0.8488 - val_loss: 0.3370 - val_accuracy: 0.8478\n",
      "Epoch 67/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3337 - accuracy: 0.8470 - val_loss: 0.3415 - val_accuracy: 0.8494\n",
      "Epoch 68/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3320 - accuracy: 0.8503 - val_loss: 0.3372 - val_accuracy: 0.8474\n",
      "Epoch 69/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3290 - accuracy: 0.8529 - val_loss: 0.3376 - val_accuracy: 0.8490\n",
      "Epoch 70/1000\n",
      "1600/1600 [==============================] - 1s 782us/step - loss: 0.3379 - accuracy: 0.8503 - val_loss: 0.3407 - val_accuracy: 0.8440\n",
      "Epoch 71/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3374 - accuracy: 0.8458 - val_loss: 0.3376 - val_accuracy: 0.8490\n",
      "Epoch 72/1000\n",
      "1600/1600 [==============================] - 1s 927us/step - loss: 0.3316 - accuracy: 0.8497 - val_loss: 0.3410 - val_accuracy: 0.8484\n",
      "Epoch 73/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3339 - accuracy: 0.8514 - val_loss: 0.3394 - val_accuracy: 0.8460\n",
      "Epoch 74/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3282 - accuracy: 0.8519 - val_loss: 0.3382 - val_accuracy: 0.8454\n",
      "Epoch 75/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3298 - accuracy: 0.8540 - val_loss: 0.3390 - val_accuracy: 0.8484\n",
      "Epoch 76/1000\n",
      "1600/1600 [==============================] - 1s 765us/step - loss: 0.3305 - accuracy: 0.8542 - val_loss: 0.3391 - val_accuracy: 0.8480\n",
      "400/400 [==============================] - 0s 727us/step - loss: 0.3327 - accuracy: 0.8487\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 745us/step - loss: 0.4857 - accuracy: 0.7778 - val_loss: 0.3764 - val_accuracy: 0.8192\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3718 - accuracy: 0.8267 - val_loss: 0.3727 - val_accuracy: 0.8234\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 796us/step - loss: 0.3730 - accuracy: 0.8245 - val_loss: 0.3641 - val_accuracy: 0.8230\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3556 - accuracy: 0.8371 - val_loss: 0.3616 - val_accuracy: 0.8314\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3610 - accuracy: 0.8320 - val_loss: 0.3581 - val_accuracy: 0.8282\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3541 - accuracy: 0.8347 - val_loss: 0.3600 - val_accuracy: 0.8260\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3579 - accuracy: 0.8338 - val_loss: 0.3547 - val_accuracy: 0.8324\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 652us/step - loss: 0.3507 - accuracy: 0.8388 - val_loss: 0.3534 - val_accuracy: 0.8370\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 662us/step - loss: 0.3463 - accuracy: 0.8420 - val_loss: 0.3521 - val_accuracy: 0.8408\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3391 - accuracy: 0.8475 - val_loss: 0.3481 - val_accuracy: 0.8374\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 657us/step - loss: 0.3404 - accuracy: 0.8453 - val_loss: 0.3483 - val_accuracy: 0.8372\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3315 - accuracy: 0.8528 - val_loss: 0.3472 - val_accuracy: 0.8432\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3326 - accuracy: 0.8516 - val_loss: 0.3442 - val_accuracy: 0.8454\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3383 - accuracy: 0.8496 - val_loss: 0.3446 - val_accuracy: 0.8414\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 752us/step - loss: 0.3354 - accuracy: 0.8536 - val_loss: 0.3441 - val_accuracy: 0.8464\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3350 - accuracy: 0.8560 - val_loss: 0.3442 - val_accuracy: 0.8430\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3331 - accuracy: 0.8517 - val_loss: 0.3437 - val_accuracy: 0.8424\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3313 - accuracy: 0.8544 - val_loss: 0.3431 - val_accuracy: 0.8428\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3273 - accuracy: 0.8545 - val_loss: 0.3433 - val_accuracy: 0.8468\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3236 - accuracy: 0.8554 - val_loss: 0.3422 - val_accuracy: 0.8468\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3387 - accuracy: 0.8490 - val_loss: 0.3417 - val_accuracy: 0.8462\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3373 - accuracy: 0.8488 - val_loss: 0.3424 - val_accuracy: 0.8466\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 660us/step - loss: 0.3342 - accuracy: 0.8527 - val_loss: 0.3417 - val_accuracy: 0.8466\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3339 - accuracy: 0.8536 - val_loss: 0.3419 - val_accuracy: 0.8462\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3314 - accuracy: 0.8523 - val_loss: 0.3422 - val_accuracy: 0.8452\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 670us/step - loss: 0.3308 - accuracy: 0.8534 - val_loss: 0.3409 - val_accuracy: 0.8468\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 670us/step - loss: 0.3312 - accuracy: 0.8559 - val_loss: 0.3426 - val_accuracy: 0.8460\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3314 - accuracy: 0.8507 - val_loss: 0.3427 - val_accuracy: 0.8436\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3361 - accuracy: 0.8509 - val_loss: 0.3429 - val_accuracy: 0.8468\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3242 - accuracy: 0.8575 - val_loss: 0.3406 - val_accuracy: 0.8450\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3312 - accuracy: 0.8536 - val_loss: 0.3414 - val_accuracy: 0.8450\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3360 - accuracy: 0.8536 - val_loss: 0.3405 - val_accuracy: 0.8464\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.3382 - accuracy: 0.8504 - val_loss: 0.3393 - val_accuracy: 0.8458\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3293 - accuracy: 0.8515 - val_loss: 0.3399 - val_accuracy: 0.8476\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 656us/step - loss: 0.3304 - accuracy: 0.8554 - val_loss: 0.3410 - val_accuracy: 0.8456\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3272 - accuracy: 0.8567 - val_loss: 0.3425 - val_accuracy: 0.8442\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3226 - accuracy: 0.8595 - val_loss: 0.3393 - val_accuracy: 0.8468\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3250 - accuracy: 0.8554 - val_loss: 0.3390 - val_accuracy: 0.8464\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3309 - accuracy: 0.8551 - val_loss: 0.3417 - val_accuracy: 0.8442\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 651us/step - loss: 0.3335 - accuracy: 0.8526 - val_loss: 0.3412 - val_accuracy: 0.8460\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 657us/step - loss: 0.3251 - accuracy: 0.8597 - val_loss: 0.3392 - val_accuracy: 0.8478\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3338 - accuracy: 0.8513 - val_loss: 0.3420 - val_accuracy: 0.8472\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3329 - accuracy: 0.8530 - val_loss: 0.3403 - val_accuracy: 0.8454\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3239 - accuracy: 0.8544 - val_loss: 0.3396 - val_accuracy: 0.8460\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3365 - accuracy: 0.8522 - val_loss: 0.3411 - val_accuracy: 0.8458\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3383 - accuracy: 0.8445 - val_loss: 0.3410 - val_accuracy: 0.8468\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3281 - accuracy: 0.8534 - val_loss: 0.3395 - val_accuracy: 0.8480\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3328 - accuracy: 0.8551 - val_loss: 0.3433 - val_accuracy: 0.8474\n",
      "400/400 [==============================] - 0s 795us/step - loss: 0.3381 - accuracy: 0.8447\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 745us/step - loss: 0.4857 - accuracy: 0.7739 - val_loss: 0.3757 - val_accuracy: 0.8164\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3797 - accuracy: 0.8137 - val_loss: 0.3691 - val_accuracy: 0.8276\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3769 - accuracy: 0.8219 - val_loss: 0.3662 - val_accuracy: 0.8236\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3561 - accuracy: 0.8333 - val_loss: 0.3618 - val_accuracy: 0.8262\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 838us/step - loss: 0.3574 - accuracy: 0.8338 - val_loss: 0.3590 - val_accuracy: 0.8314\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3522 - accuracy: 0.8387 - val_loss: 0.3580 - val_accuracy: 0.8290\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 806us/step - loss: 0.3527 - accuracy: 0.8394 - val_loss: 0.3575 - val_accuracy: 0.8330\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3453 - accuracy: 0.8438 - val_loss: 0.3550 - val_accuracy: 0.8356\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3478 - accuracy: 0.8397 - val_loss: 0.3550 - val_accuracy: 0.8318\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3564 - accuracy: 0.8349 - val_loss: 0.3525 - val_accuracy: 0.8352\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3514 - accuracy: 0.8395 - val_loss: 0.3512 - val_accuracy: 0.8372\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3457 - accuracy: 0.8435 - val_loss: 0.3494 - val_accuracy: 0.8384\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3484 - accuracy: 0.8449 - val_loss: 0.3499 - val_accuracy: 0.8384\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 676us/step - loss: 0.3339 - accuracy: 0.8485 - val_loss: 0.3467 - val_accuracy: 0.8412\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3455 - accuracy: 0.8406 - val_loss: 0.3466 - val_accuracy: 0.8430\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.3418 - accuracy: 0.8452 - val_loss: 0.3442 - val_accuracy: 0.8434\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3336 - accuracy: 0.8507 - val_loss: 0.3437 - val_accuracy: 0.8438\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 912us/step - loss: 0.3426 - accuracy: 0.8461 - val_loss: 0.3462 - val_accuracy: 0.8400\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 886us/step - loss: 0.3245 - accuracy: 0.8540 - val_loss: 0.3439 - val_accuracy: 0.8420\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3384 - accuracy: 0.8477 - val_loss: 0.3439 - val_accuracy: 0.8476\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3461 - accuracy: 0.8428 - val_loss: 0.3425 - val_accuracy: 0.8474\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3308 - accuracy: 0.8501 - val_loss: 0.3415 - val_accuracy: 0.8468\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3391 - accuracy: 0.8481 - val_loss: 0.3431 - val_accuracy: 0.8442\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3331 - accuracy: 0.8486 - val_loss: 0.3408 - val_accuracy: 0.8478\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 796us/step - loss: 0.3349 - accuracy: 0.8507 - val_loss: 0.3433 - val_accuracy: 0.8446\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3365 - accuracy: 0.8504 - val_loss: 0.3416 - val_accuracy: 0.8460\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3341 - accuracy: 0.8511 - val_loss: 0.3446 - val_accuracy: 0.8440\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3322 - accuracy: 0.8514 - val_loss: 0.3424 - val_accuracy: 0.8440\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 2s 984us/step - loss: 0.3295 - accuracy: 0.8552 - val_loss: 0.3395 - val_accuracy: 0.8462\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 792us/step - loss: 0.3308 - accuracy: 0.8561 - val_loss: 0.3443 - val_accuracy: 0.8456\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3355 - accuracy: 0.8498 - val_loss: 0.3408 - val_accuracy: 0.8454\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3330 - accuracy: 0.8510 - val_loss: 0.3406 - val_accuracy: 0.8438\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3353 - accuracy: 0.8530 - val_loss: 0.3418 - val_accuracy: 0.8458\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3300 - accuracy: 0.8509 - val_loss: 0.3383 - val_accuracy: 0.8450\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 835us/step - loss: 0.3304 - accuracy: 0.8508 - val_loss: 0.3432 - val_accuracy: 0.8426\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 780us/step - loss: 0.3342 - accuracy: 0.8484 - val_loss: 0.3409 - val_accuracy: 0.8478\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 673us/step - loss: 0.3286 - accuracy: 0.8517 - val_loss: 0.3415 - val_accuracy: 0.8468\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3280 - accuracy: 0.8554 - val_loss: 0.3414 - val_accuracy: 0.8436\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 776us/step - loss: 0.3344 - accuracy: 0.8543 - val_loss: 0.3418 - val_accuracy: 0.8458\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3384 - accuracy: 0.8493 - val_loss: 0.3404 - val_accuracy: 0.8470\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 808us/step - loss: 0.3326 - accuracy: 0.8521 - val_loss: 0.3401 - val_accuracy: 0.8460\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3312 - accuracy: 0.8527 - val_loss: 0.3373 - val_accuracy: 0.8466\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3331 - accuracy: 0.8533 - val_loss: 0.3403 - val_accuracy: 0.8452\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3389 - accuracy: 0.8497 - val_loss: 0.3381 - val_accuracy: 0.8486\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 688us/step - loss: 0.3317 - accuracy: 0.8535 - val_loss: 0.3374 - val_accuracy: 0.8474\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3300 - accuracy: 0.8530 - val_loss: 0.3403 - val_accuracy: 0.8474\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3269 - accuracy: 0.8569 - val_loss: 0.3387 - val_accuracy: 0.8466\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 650us/step - loss: 0.3400 - accuracy: 0.8512 - val_loss: 0.3425 - val_accuracy: 0.8466\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3327 - accuracy: 0.8500 - val_loss: 0.3411 - val_accuracy: 0.8436\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 659us/step - loss: 0.3341 - accuracy: 0.8521 - val_loss: 0.3374 - val_accuracy: 0.8464\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3214 - accuracy: 0.8554 - val_loss: 0.3403 - val_accuracy: 0.8474\n",
      "Epoch 52/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3354 - accuracy: 0.8489 - val_loss: 0.3411 - val_accuracy: 0.8462\n",
      "400/400 [==============================] - 0s 712us/step - loss: 0.3299 - accuracy: 0.8522\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 740us/step - loss: 0.4875 - accuracy: 0.7600 - val_loss: 0.3866 - val_accuracy: 0.8162\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 670us/step - loss: 0.3897 - accuracy: 0.8167 - val_loss: 0.3758 - val_accuracy: 0.8218\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3755 - accuracy: 0.8269 - val_loss: 0.3679 - val_accuracy: 0.8204\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 831us/step - loss: 0.3674 - accuracy: 0.8301 - val_loss: 0.3658 - val_accuracy: 0.8226\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 664us/step - loss: 0.3640 - accuracy: 0.8291 - val_loss: 0.3621 - val_accuracy: 0.8246\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3533 - accuracy: 0.8354 - val_loss: 0.3614 - val_accuracy: 0.8234\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3533 - accuracy: 0.8382 - val_loss: 0.3594 - val_accuracy: 0.8280\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3587 - accuracy: 0.8311 - val_loss: 0.3574 - val_accuracy: 0.8296\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3545 - accuracy: 0.8360 - val_loss: 0.3566 - val_accuracy: 0.8326\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3437 - accuracy: 0.8421 - val_loss: 0.3579 - val_accuracy: 0.8252\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.3549 - accuracy: 0.8349 - val_loss: 0.3565 - val_accuracy: 0.8330\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3538 - accuracy: 0.8356 - val_loss: 0.3553 - val_accuracy: 0.8280\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3513 - accuracy: 0.8375 - val_loss: 0.3559 - val_accuracy: 0.8284\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.3446 - accuracy: 0.8415 - val_loss: 0.3543 - val_accuracy: 0.8288\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3474 - accuracy: 0.8436 - val_loss: 0.3543 - val_accuracy: 0.8298\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3514 - accuracy: 0.8399 - val_loss: 0.3534 - val_accuracy: 0.8308\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 683us/step - loss: 0.3448 - accuracy: 0.8409 - val_loss: 0.3522 - val_accuracy: 0.8322\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3504 - accuracy: 0.8405 - val_loss: 0.3523 - val_accuracy: 0.8346\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 792us/step - loss: 0.3484 - accuracy: 0.8418 - val_loss: 0.3510 - val_accuracy: 0.8344\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3418 - accuracy: 0.8446 - val_loss: 0.3503 - val_accuracy: 0.8370\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3439 - accuracy: 0.8442 - val_loss: 0.3511 - val_accuracy: 0.8344\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 853us/step - loss: 0.3449 - accuracy: 0.8427 - val_loss: 0.3512 - val_accuracy: 0.8382\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3460 - accuracy: 0.8436 - val_loss: 0.3553 - val_accuracy: 0.8434\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3479 - accuracy: 0.8428 - val_loss: 0.3494 - val_accuracy: 0.8420\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3397 - accuracy: 0.8455 - val_loss: 0.3458 - val_accuracy: 0.8414\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3355 - accuracy: 0.8515 - val_loss: 0.3465 - val_accuracy: 0.8390\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 649us/step - loss: 0.3398 - accuracy: 0.8466 - val_loss: 0.3466 - val_accuracy: 0.8436\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3469 - accuracy: 0.8399 - val_loss: 0.3444 - val_accuracy: 0.8422\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3349 - accuracy: 0.8507 - val_loss: 0.3445 - val_accuracy: 0.8426\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 670us/step - loss: 0.3355 - accuracy: 0.8486 - val_loss: 0.3428 - val_accuracy: 0.8456\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3353 - accuracy: 0.8497 - val_loss: 0.3423 - val_accuracy: 0.8460\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 656us/step - loss: 0.3421 - accuracy: 0.8474 - val_loss: 0.3443 - val_accuracy: 0.8430\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 874us/step - loss: 0.3426 - accuracy: 0.8445 - val_loss: 0.3433 - val_accuracy: 0.8420\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3386 - accuracy: 0.8496 - val_loss: 0.3427 - val_accuracy: 0.8432\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 698us/step - loss: 0.3449 - accuracy: 0.8461 - val_loss: 0.3458 - val_accuracy: 0.8472\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3440 - accuracy: 0.8443 - val_loss: 0.3434 - val_accuracy: 0.8438\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3264 - accuracy: 0.8534 - val_loss: 0.3407 - val_accuracy: 0.8452\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3341 - accuracy: 0.8499 - val_loss: 0.3417 - val_accuracy: 0.8438\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 880us/step - loss: 0.3370 - accuracy: 0.8489 - val_loss: 0.3422 - val_accuracy: 0.8440\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3307 - accuracy: 0.8538 - val_loss: 0.3421 - val_accuracy: 0.8434\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3362 - accuracy: 0.8520 - val_loss: 0.3406 - val_accuracy: 0.8452\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3383 - accuracy: 0.8493 - val_loss: 0.3427 - val_accuracy: 0.8434\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3308 - accuracy: 0.8503 - val_loss: 0.3412 - val_accuracy: 0.8450\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3397 - accuracy: 0.8449 - val_loss: 0.3405 - val_accuracy: 0.8458\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3306 - accuracy: 0.8533 - val_loss: 0.3411 - val_accuracy: 0.8438\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 662us/step - loss: 0.3353 - accuracy: 0.8537 - val_loss: 0.3475 - val_accuracy: 0.8444\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 673us/step - loss: 0.3366 - accuracy: 0.8488 - val_loss: 0.3402 - val_accuracy: 0.8474\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3281 - accuracy: 0.8550 - val_loss: 0.3408 - val_accuracy: 0.8454\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3344 - accuracy: 0.8517 - val_loss: 0.3488 - val_accuracy: 0.8438\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3345 - accuracy: 0.8512 - val_loss: 0.3411 - val_accuracy: 0.8454\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 1s 665us/step - loss: 0.3329 - accuracy: 0.8522 - val_loss: 0.3394 - val_accuracy: 0.8456\n",
      "Epoch 52/1000\n",
      "1600/1600 [==============================] - 1s 735us/step - loss: 0.3383 - accuracy: 0.8470 - val_loss: 0.3441 - val_accuracy: 0.8458\n",
      "Epoch 53/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3333 - accuracy: 0.8535 - val_loss: 0.3452 - val_accuracy: 0.8466\n",
      "Epoch 54/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3399 - accuracy: 0.8505 - val_loss: 0.3430 - val_accuracy: 0.8452\n",
      "Epoch 55/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3350 - accuracy: 0.8478 - val_loss: 0.3399 - val_accuracy: 0.8464\n",
      "Epoch 56/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3314 - accuracy: 0.8518 - val_loss: 0.3406 - val_accuracy: 0.8446\n",
      "Epoch 57/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3321 - accuracy: 0.8504 - val_loss: 0.3443 - val_accuracy: 0.8466\n",
      "Epoch 58/1000\n",
      "1600/1600 [==============================] - 1s 790us/step - loss: 0.3372 - accuracy: 0.8460 - val_loss: 0.3401 - val_accuracy: 0.8450\n",
      "Epoch 59/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3373 - accuracy: 0.8503 - val_loss: 0.3418 - val_accuracy: 0.8446\n",
      "Epoch 60/1000\n",
      "1600/1600 [==============================] - 1s 663us/step - loss: 0.3289 - accuracy: 0.8548 - val_loss: 0.3427 - val_accuracy: 0.8460\n",
      "Epoch 61/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3281 - accuracy: 0.8547 - val_loss: 0.3405 - val_accuracy: 0.8438\n",
      "400/400 [==============================] - 0s 750us/step - loss: 0.3279 - accuracy: 0.8543\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 793us/step - loss: 0.4759 - accuracy: 0.7759 - val_loss: 0.3749 - val_accuracy: 0.8204\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3717 - accuracy: 0.8207 - val_loss: 0.3678 - val_accuracy: 0.8230\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3656 - accuracy: 0.8247 - val_loss: 0.3648 - val_accuracy: 0.8200\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3578 - accuracy: 0.8287 - val_loss: 0.3608 - val_accuracy: 0.8270\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3464 - accuracy: 0.8388 - val_loss: 0.3569 - val_accuracy: 0.8320\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3503 - accuracy: 0.8386 - val_loss: 0.3562 - val_accuracy: 0.8306\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3539 - accuracy: 0.8365 - val_loss: 0.3563 - val_accuracy: 0.8326\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3495 - accuracy: 0.8383 - val_loss: 0.3530 - val_accuracy: 0.8426\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3465 - accuracy: 0.8408 - val_loss: 0.3497 - val_accuracy: 0.8380\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3374 - accuracy: 0.8456 - val_loss: 0.3485 - val_accuracy: 0.8400\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3306 - accuracy: 0.8525 - val_loss: 0.3520 - val_accuracy: 0.8362\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3338 - accuracy: 0.8483 - val_loss: 0.3459 - val_accuracy: 0.8430\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 698us/step - loss: 0.3425 - accuracy: 0.8433 - val_loss: 0.3460 - val_accuracy: 0.8430\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3377 - accuracy: 0.8469 - val_loss: 0.3468 - val_accuracy: 0.8398\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3329 - accuracy: 0.8503 - val_loss: 0.3440 - val_accuracy: 0.8420\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3295 - accuracy: 0.8512 - val_loss: 0.3497 - val_accuracy: 0.8410\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 676us/step - loss: 0.3337 - accuracy: 0.8512 - val_loss: 0.3447 - val_accuracy: 0.8436\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3300 - accuracy: 0.8533 - val_loss: 0.3439 - val_accuracy: 0.8422\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3369 - accuracy: 0.8510 - val_loss: 0.3449 - val_accuracy: 0.8410\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3327 - accuracy: 0.8505 - val_loss: 0.3404 - val_accuracy: 0.8470\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3381 - accuracy: 0.8446 - val_loss: 0.3424 - val_accuracy: 0.8440\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3346 - accuracy: 0.8503 - val_loss: 0.3442 - val_accuracy: 0.8460\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3320 - accuracy: 0.8509 - val_loss: 0.3426 - val_accuracy: 0.8448\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3363 - accuracy: 0.8477 - val_loss: 0.3439 - val_accuracy: 0.8436\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3330 - accuracy: 0.8487 - val_loss: 0.3448 - val_accuracy: 0.8424\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3260 - accuracy: 0.8555 - val_loss: 0.3472 - val_accuracy: 0.8434\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3212 - accuracy: 0.8575 - val_loss: 0.3418 - val_accuracy: 0.8472\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3347 - accuracy: 0.8500 - val_loss: 0.3409 - val_accuracy: 0.8466\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3345 - accuracy: 0.8480 - val_loss: 0.3453 - val_accuracy: 0.8428\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3246 - accuracy: 0.8549 - val_loss: 0.3474 - val_accuracy: 0.8424\n",
      "400/400 [==============================] - 0s 715us/step - loss: 0.3400 - accuracy: 0.8520\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 793us/step - loss: 0.4739 - accuracy: 0.7885 - val_loss: 0.3758 - val_accuracy: 0.8190\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 665us/step - loss: 0.3759 - accuracy: 0.8215 - val_loss: 0.3690 - val_accuracy: 0.8272\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 660us/step - loss: 0.3601 - accuracy: 0.8323 - val_loss: 0.3640 - val_accuracy: 0.8224\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 673us/step - loss: 0.3632 - accuracy: 0.8294 - val_loss: 0.3607 - val_accuracy: 0.8290\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3611 - accuracy: 0.8334 - val_loss: 0.3595 - val_accuracy: 0.8252\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3616 - accuracy: 0.8307 - val_loss: 0.3577 - val_accuracy: 0.8262\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3520 - accuracy: 0.8351 - val_loss: 0.3567 - val_accuracy: 0.8284\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 683us/step - loss: 0.3539 - accuracy: 0.8370 - val_loss: 0.3594 - val_accuracy: 0.8262\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3514 - accuracy: 0.8405 - val_loss: 0.3558 - val_accuracy: 0.8296\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3526 - accuracy: 0.8376 - val_loss: 0.3538 - val_accuracy: 0.8324\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3494 - accuracy: 0.8400 - val_loss: 0.3551 - val_accuracy: 0.8382\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3439 - accuracy: 0.8421 - val_loss: 0.3511 - val_accuracy: 0.8356\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3378 - accuracy: 0.8445 - val_loss: 0.3507 - val_accuracy: 0.8358\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3410 - accuracy: 0.8458 - val_loss: 0.3493 - val_accuracy: 0.8378\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.3456 - accuracy: 0.8458 - val_loss: 0.3495 - val_accuracy: 0.8368\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3414 - accuracy: 0.8478 - val_loss: 0.3451 - val_accuracy: 0.8422\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 754us/step - loss: 0.3389 - accuracy: 0.8484 - val_loss: 0.3442 - val_accuracy: 0.8420\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3397 - accuracy: 0.8482 - val_loss: 0.3423 - val_accuracy: 0.8448\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3377 - accuracy: 0.8491 - val_loss: 0.3459 - val_accuracy: 0.8404\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 656us/step - loss: 0.3357 - accuracy: 0.8496 - val_loss: 0.3432 - val_accuracy: 0.8440\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 668us/step - loss: 0.3373 - accuracy: 0.8490 - val_loss: 0.3408 - val_accuracy: 0.8436\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3360 - accuracy: 0.8492 - val_loss: 0.3409 - val_accuracy: 0.8434\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3307 - accuracy: 0.8520 - val_loss: 0.3401 - val_accuracy: 0.8470\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.3326 - accuracy: 0.8484 - val_loss: 0.3407 - val_accuracy: 0.8452\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3298 - accuracy: 0.8514 - val_loss: 0.3408 - val_accuracy: 0.8466\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3291 - accuracy: 0.8548 - val_loss: 0.3417 - val_accuracy: 0.8450\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3310 - accuracy: 0.8520 - val_loss: 0.3444 - val_accuracy: 0.8462\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3358 - accuracy: 0.8479 - val_loss: 0.3397 - val_accuracy: 0.8462\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3315 - accuracy: 0.8490 - val_loss: 0.3400 - val_accuracy: 0.8498\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 776us/step - loss: 0.3307 - accuracy: 0.8496 - val_loss: 0.3407 - val_accuracy: 0.8448\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 693us/step - loss: 0.3299 - accuracy: 0.8522 - val_loss: 0.3408 - val_accuracy: 0.8438\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3354 - accuracy: 0.8496 - val_loss: 0.3391 - val_accuracy: 0.8434\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3370 - accuracy: 0.8509 - val_loss: 0.3394 - val_accuracy: 0.8480\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.3353 - accuracy: 0.8498 - val_loss: 0.3391 - val_accuracy: 0.8446\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3342 - accuracy: 0.8490 - val_loss: 0.3407 - val_accuracy: 0.8480\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 664us/step - loss: 0.3286 - accuracy: 0.8522 - val_loss: 0.3404 - val_accuracy: 0.8472\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.3314 - accuracy: 0.8518 - val_loss: 0.3391 - val_accuracy: 0.8490\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3359 - accuracy: 0.8517 - val_loss: 0.3401 - val_accuracy: 0.8440\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3347 - accuracy: 0.8511 - val_loss: 0.3392 - val_accuracy: 0.8484\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3346 - accuracy: 0.8524 - val_loss: 0.3406 - val_accuracy: 0.8446\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3380 - accuracy: 0.8496 - val_loss: 0.3387 - val_accuracy: 0.8478\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3311 - accuracy: 0.8509 - val_loss: 0.3414 - val_accuracy: 0.8456\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3343 - accuracy: 0.8523 - val_loss: 0.3379 - val_accuracy: 0.8486\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3284 - accuracy: 0.8516 - val_loss: 0.3378 - val_accuracy: 0.8488\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 659us/step - loss: 0.3277 - accuracy: 0.8535 - val_loss: 0.3376 - val_accuracy: 0.8482\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3321 - accuracy: 0.8486 - val_loss: 0.3413 - val_accuracy: 0.8436\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3278 - accuracy: 0.8540 - val_loss: 0.3391 - val_accuracy: 0.8450\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3347 - accuracy: 0.8474 - val_loss: 0.3377 - val_accuracy: 0.8482\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3362 - accuracy: 0.8488 - val_loss: 0.3391 - val_accuracy: 0.8490\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3296 - accuracy: 0.8558 - val_loss: 0.3378 - val_accuracy: 0.8484\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 1s 663us/step - loss: 0.3323 - accuracy: 0.8514 - val_loss: 0.3417 - val_accuracy: 0.8470\n",
      "Epoch 52/1000\n",
      "1600/1600 [==============================] - 1s 746us/step - loss: 0.3342 - accuracy: 0.8529 - val_loss: 0.3380 - val_accuracy: 0.8468\n",
      "Epoch 53/1000\n",
      "1600/1600 [==============================] - 1s 768us/step - loss: 0.3280 - accuracy: 0.8548 - val_loss: 0.3507 - val_accuracy: 0.8470\n",
      "Epoch 54/1000\n",
      "1600/1600 [==============================] - 1s 771us/step - loss: 0.3327 - accuracy: 0.8491 - val_loss: 0.3409 - val_accuracy: 0.8460\n",
      "Epoch 55/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3405 - accuracy: 0.8503 - val_loss: 0.3369 - val_accuracy: 0.8490\n",
      "Epoch 56/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3342 - accuracy: 0.8497 - val_loss: 0.3405 - val_accuracy: 0.8492\n",
      "Epoch 57/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3324 - accuracy: 0.8476 - val_loss: 0.3377 - val_accuracy: 0.8498\n",
      "Epoch 58/1000\n",
      "1600/1600 [==============================] - 1s 676us/step - loss: 0.3266 - accuracy: 0.8535 - val_loss: 0.3384 - val_accuracy: 0.8506\n",
      "Epoch 59/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3291 - accuracy: 0.8498 - val_loss: 0.3385 - val_accuracy: 0.8496\n",
      "Epoch 60/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3397 - accuracy: 0.8457 - val_loss: 0.3381 - val_accuracy: 0.8482\n",
      "Epoch 61/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3349 - accuracy: 0.8496 - val_loss: 0.3390 - val_accuracy: 0.8476\n",
      "Epoch 62/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3359 - accuracy: 0.8501 - val_loss: 0.3376 - val_accuracy: 0.8492\n",
      "Epoch 63/1000\n",
      "1600/1600 [==============================] - 1s 813us/step - loss: 0.3320 - accuracy: 0.8544 - val_loss: 0.3401 - val_accuracy: 0.8484\n",
      "Epoch 64/1000\n",
      "1600/1600 [==============================] - 1s 845us/step - loss: 0.3293 - accuracy: 0.8530 - val_loss: 0.3413 - val_accuracy: 0.8490\n",
      "Epoch 65/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3375 - accuracy: 0.8496 - val_loss: 0.3368 - val_accuracy: 0.8494\n",
      "Epoch 66/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3259 - accuracy: 0.8543 - val_loss: 0.3369 - val_accuracy: 0.8492\n",
      "Epoch 67/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3357 - accuracy: 0.8508 - val_loss: 0.3406 - val_accuracy: 0.8468\n",
      "Epoch 68/1000\n",
      "1600/1600 [==============================] - 1s 656us/step - loss: 0.3307 - accuracy: 0.8528 - val_loss: 0.3365 - val_accuracy: 0.8502\n",
      "Epoch 69/1000\n",
      "1600/1600 [==============================] - 1s 659us/step - loss: 0.3369 - accuracy: 0.8449 - val_loss: 0.3364 - val_accuracy: 0.8506\n",
      "Epoch 70/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3297 - accuracy: 0.8521 - val_loss: 0.3365 - val_accuracy: 0.8500\n",
      "Epoch 71/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3333 - accuracy: 0.8507 - val_loss: 0.3393 - val_accuracy: 0.8496\n",
      "Epoch 72/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3325 - accuracy: 0.8493 - val_loss: 0.3375 - val_accuracy: 0.8484\n",
      "Epoch 73/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3319 - accuracy: 0.8541 - val_loss: 0.3353 - val_accuracy: 0.8494\n",
      "Epoch 74/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3312 - accuracy: 0.8515 - val_loss: 0.3357 - val_accuracy: 0.8492\n",
      "Epoch 75/1000\n",
      "1600/1600 [==============================] - 1s 780us/step - loss: 0.3362 - accuracy: 0.8485 - val_loss: 0.3388 - val_accuracy: 0.8470\n",
      "Epoch 76/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3261 - accuracy: 0.8574 - val_loss: 0.3371 - val_accuracy: 0.8492\n",
      "Epoch 77/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3355 - accuracy: 0.8507 - val_loss: 0.3499 - val_accuracy: 0.8472\n",
      "Epoch 78/1000\n",
      "1600/1600 [==============================] - 1s 665us/step - loss: 0.3302 - accuracy: 0.8530 - val_loss: 0.3351 - val_accuracy: 0.8494\n",
      "Epoch 79/1000\n",
      "1600/1600 [==============================] - 1s 662us/step - loss: 0.3246 - accuracy: 0.8557 - val_loss: 0.3359 - val_accuracy: 0.8488\n",
      "Epoch 80/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3318 - accuracy: 0.8509 - val_loss: 0.3376 - val_accuracy: 0.8492\n",
      "Epoch 81/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3296 - accuracy: 0.8545 - val_loss: 0.3382 - val_accuracy: 0.8474\n",
      "Epoch 82/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3289 - accuracy: 0.8526 - val_loss: 0.3419 - val_accuracy: 0.8482\n",
      "Epoch 83/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3238 - accuracy: 0.8569 - val_loss: 0.3368 - val_accuracy: 0.8488\n",
      "Epoch 84/1000\n",
      "1600/1600 [==============================] - 1s 752us/step - loss: 0.3308 - accuracy: 0.8514 - val_loss: 0.3365 - val_accuracy: 0.8492\n",
      "Epoch 85/1000\n",
      "1600/1600 [==============================] - 1s 655us/step - loss: 0.3277 - accuracy: 0.8514 - val_loss: 0.3378 - val_accuracy: 0.8488\n",
      "Epoch 86/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3302 - accuracy: 0.8525 - val_loss: 0.3369 - val_accuracy: 0.8486\n",
      "Epoch 87/1000\n",
      "1600/1600 [==============================] - 1s 664us/step - loss: 0.3323 - accuracy: 0.8478 - val_loss: 0.3373 - val_accuracy: 0.8498\n",
      "Epoch 88/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3350 - accuracy: 0.8474 - val_loss: 0.3456 - val_accuracy: 0.8472\n",
      "400/400 [==============================] - 0s 930us/step - loss: 0.3308 - accuracy: 0.8537\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 892us/step - loss: 0.4708 - accuracy: 0.7890 - val_loss: 0.3757 - val_accuracy: 0.8196\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3697 - accuracy: 0.8262 - val_loss: 0.3684 - val_accuracy: 0.8202\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3623 - accuracy: 0.8292 - val_loss: 0.3638 - val_accuracy: 0.8262\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3552 - accuracy: 0.8358 - val_loss: 0.3596 - val_accuracy: 0.8298\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3575 - accuracy: 0.8364 - val_loss: 0.3567 - val_accuracy: 0.8316\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3492 - accuracy: 0.8402 - val_loss: 0.3554 - val_accuracy: 0.8370\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3482 - accuracy: 0.8438 - val_loss: 0.3518 - val_accuracy: 0.8380\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3503 - accuracy: 0.8415 - val_loss: 0.3505 - val_accuracy: 0.8380\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3364 - accuracy: 0.8505 - val_loss: 0.3493 - val_accuracy: 0.8424\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3376 - accuracy: 0.8493 - val_loss: 0.3476 - val_accuracy: 0.8394\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 808us/step - loss: 0.3370 - accuracy: 0.8479 - val_loss: 0.3468 - val_accuracy: 0.8426\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3445 - accuracy: 0.8456 - val_loss: 0.3456 - val_accuracy: 0.8436\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3376 - accuracy: 0.8473 - val_loss: 0.3493 - val_accuracy: 0.8460\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3361 - accuracy: 0.8508 - val_loss: 0.3435 - val_accuracy: 0.8464\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 806us/step - loss: 0.3317 - accuracy: 0.8553 - val_loss: 0.3445 - val_accuracy: 0.8436\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 754us/step - loss: 0.3372 - accuracy: 0.8476 - val_loss: 0.3418 - val_accuracy: 0.8452\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3320 - accuracy: 0.8520 - val_loss: 0.3444 - val_accuracy: 0.8424\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3317 - accuracy: 0.8529 - val_loss: 0.3421 - val_accuracy: 0.8458\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3329 - accuracy: 0.8493 - val_loss: 0.3470 - val_accuracy: 0.8458\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3361 - accuracy: 0.8536 - val_loss: 0.3421 - val_accuracy: 0.8460\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3272 - accuracy: 0.8556 - val_loss: 0.3455 - val_accuracy: 0.8436\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3402 - accuracy: 0.8503 - val_loss: 0.3444 - val_accuracy: 0.8460\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3364 - accuracy: 0.8513 - val_loss: 0.3510 - val_accuracy: 0.8480\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3294 - accuracy: 0.8572 - val_loss: 0.3460 - val_accuracy: 0.8472\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 2s 976us/step - loss: 0.3407 - accuracy: 0.8510 - val_loss: 0.3424 - val_accuracy: 0.8454\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3306 - accuracy: 0.8549 - val_loss: 0.3502 - val_accuracy: 0.8400\n",
      "400/400 [==============================] - 0s 732us/step - loss: 0.3431 - accuracy: 0.8428\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 744us/step - loss: 0.4677 - accuracy: 0.7837 - val_loss: 0.3749 - val_accuracy: 0.8154\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3674 - accuracy: 0.8285 - val_loss: 0.3675 - val_accuracy: 0.8288\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3616 - accuracy: 0.8312 - val_loss: 0.3676 - val_accuracy: 0.8318\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3595 - accuracy: 0.8311 - val_loss: 0.3608 - val_accuracy: 0.8266\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3463 - accuracy: 0.8378 - val_loss: 0.3576 - val_accuracy: 0.8310\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 656us/step - loss: 0.3458 - accuracy: 0.8403 - val_loss: 0.3556 - val_accuracy: 0.8326\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3505 - accuracy: 0.8413 - val_loss: 0.3585 - val_accuracy: 0.8262\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 670us/step - loss: 0.3538 - accuracy: 0.8347 - val_loss: 0.3537 - val_accuracy: 0.8324\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 763us/step - loss: 0.3464 - accuracy: 0.8407 - val_loss: 0.3545 - val_accuracy: 0.8350\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 937us/step - loss: 0.3529 - accuracy: 0.8375 - val_loss: 0.3503 - val_accuracy: 0.8366\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 2s 954us/step - loss: 0.3472 - accuracy: 0.8405 - val_loss: 0.3507 - val_accuracy: 0.8372\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 668us/step - loss: 0.3516 - accuracy: 0.8382 - val_loss: 0.3529 - val_accuracy: 0.8324\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 659us/step - loss: 0.3428 - accuracy: 0.8416 - val_loss: 0.3477 - val_accuracy: 0.8386\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 655us/step - loss: 0.3460 - accuracy: 0.8446 - val_loss: 0.3472 - val_accuracy: 0.8418\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 652us/step - loss: 0.3403 - accuracy: 0.8436 - val_loss: 0.3448 - val_accuracy: 0.8422\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 661us/step - loss: 0.3350 - accuracy: 0.8467 - val_loss: 0.3469 - val_accuracy: 0.8416\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3402 - accuracy: 0.8450 - val_loss: 0.3477 - val_accuracy: 0.8412\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3396 - accuracy: 0.8459 - val_loss: 0.3469 - val_accuracy: 0.8452\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 644us/step - loss: 0.3346 - accuracy: 0.8470 - val_loss: 0.3440 - val_accuracy: 0.8458\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 736us/step - loss: 0.3303 - accuracy: 0.8526 - val_loss: 0.3429 - val_accuracy: 0.8434\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3287 - accuracy: 0.8506 - val_loss: 0.3424 - val_accuracy: 0.8444\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 884us/step - loss: 0.3391 - accuracy: 0.8496 - val_loss: 0.3431 - val_accuracy: 0.8444\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 657us/step - loss: 0.3401 - accuracy: 0.8475 - val_loss: 0.3430 - val_accuracy: 0.8438\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.3342 - accuracy: 0.8514 - val_loss: 0.3459 - val_accuracy: 0.8436\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3302 - accuracy: 0.8507 - val_loss: 0.3396 - val_accuracy: 0.8472\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3342 - accuracy: 0.8489 - val_loss: 0.3385 - val_accuracy: 0.8480\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 657us/step - loss: 0.3340 - accuracy: 0.8500 - val_loss: 0.3389 - val_accuracy: 0.8458\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3349 - accuracy: 0.8465 - val_loss: 0.3407 - val_accuracy: 0.8436\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3261 - accuracy: 0.8511 - val_loss: 0.3397 - val_accuracy: 0.8446\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 661us/step - loss: 0.3224 - accuracy: 0.8588 - val_loss: 0.3388 - val_accuracy: 0.8450\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3298 - accuracy: 0.8514 - val_loss: 0.3413 - val_accuracy: 0.8436\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 649us/step - loss: 0.3333 - accuracy: 0.8504 - val_loss: 0.3397 - val_accuracy: 0.8450\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 811us/step - loss: 0.3456 - accuracy: 0.8449 - val_loss: 0.3537 - val_accuracy: 0.8474\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3314 - accuracy: 0.8520 - val_loss: 0.3384 - val_accuracy: 0.8476\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 668us/step - loss: 0.3291 - accuracy: 0.8538 - val_loss: 0.3417 - val_accuracy: 0.8432\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 660us/step - loss: 0.3313 - accuracy: 0.8530 - val_loss: 0.3374 - val_accuracy: 0.8466\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3256 - accuracy: 0.8529 - val_loss: 0.3387 - val_accuracy: 0.8468\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 665us/step - loss: 0.3329 - accuracy: 0.8493 - val_loss: 0.3374 - val_accuracy: 0.8482\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3300 - accuracy: 0.8475 - val_loss: 0.3378 - val_accuracy: 0.8458\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3348 - accuracy: 0.8485 - val_loss: 0.3410 - val_accuracy: 0.8448\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 698us/step - loss: 0.3335 - accuracy: 0.8551 - val_loss: 0.3390 - val_accuracy: 0.8454\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 815us/step - loss: 0.3396 - accuracy: 0.8482 - val_loss: 0.3434 - val_accuracy: 0.8478\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3267 - accuracy: 0.8552 - val_loss: 0.3413 - val_accuracy: 0.8470\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 853us/step - loss: 0.3310 - accuracy: 0.8561 - val_loss: 0.3374 - val_accuracy: 0.8486\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 2s 957us/step - loss: 0.3305 - accuracy: 0.8544 - val_loss: 0.3380 - val_accuracy: 0.8458\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3323 - accuracy: 0.8515 - val_loss: 0.3384 - val_accuracy: 0.8458\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3296 - accuracy: 0.8563 - val_loss: 0.3387 - val_accuracy: 0.8454\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3267 - accuracy: 0.8522 - val_loss: 0.3399 - val_accuracy: 0.8476\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3271 - accuracy: 0.8533 - val_loss: 0.3398 - val_accuracy: 0.8454\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 879us/step - loss: 0.3321 - accuracy: 0.8536 - val_loss: 0.3384 - val_accuracy: 0.8464\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3300 - accuracy: 0.8525 - val_loss: 0.3388 - val_accuracy: 0.8464\n",
      "Epoch 52/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3346 - accuracy: 0.8492 - val_loss: 0.3387 - val_accuracy: 0.8468\n",
      "Epoch 53/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3282 - accuracy: 0.8536 - val_loss: 0.3456 - val_accuracy: 0.8438\n",
      "Epoch 54/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3342 - accuracy: 0.8519 - val_loss: 0.3403 - val_accuracy: 0.8468\n",
      "400/400 [==============================] - 0s 692us/step - loss: 0.3288 - accuracy: 0.8497\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 882us/step - loss: 0.4734 - accuracy: 0.7835 - val_loss: 0.3756 - val_accuracy: 0.8206\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3609 - accuracy: 0.8318 - val_loss: 0.3662 - val_accuracy: 0.8254\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3572 - accuracy: 0.8330 - val_loss: 0.3623 - val_accuracy: 0.8240\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3564 - accuracy: 0.8365 - val_loss: 0.3584 - val_accuracy: 0.8276\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 765us/step - loss: 0.3478 - accuracy: 0.8376 - val_loss: 0.3533 - val_accuracy: 0.8306\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3475 - accuracy: 0.8413 - val_loss: 0.3511 - val_accuracy: 0.8336\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 775us/step - loss: 0.3458 - accuracy: 0.8459 - val_loss: 0.3494 - val_accuracy: 0.8362\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 918us/step - loss: 0.3387 - accuracy: 0.8468 - val_loss: 0.3467 - val_accuracy: 0.8406\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 770us/step - loss: 0.3408 - accuracy: 0.8475 - val_loss: 0.3511 - val_accuracy: 0.8368\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3470 - accuracy: 0.8455 - val_loss: 0.3437 - val_accuracy: 0.8456\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 777us/step - loss: 0.3409 - accuracy: 0.8449 - val_loss: 0.3475 - val_accuracy: 0.8402\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 857us/step - loss: 0.3402 - accuracy: 0.8454 - val_loss: 0.3433 - val_accuracy: 0.8436\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3379 - accuracy: 0.8478 - val_loss: 0.3433 - val_accuracy: 0.8434\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 869us/step - loss: 0.3409 - accuracy: 0.8488 - val_loss: 0.3447 - val_accuracy: 0.8444\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3288 - accuracy: 0.8572 - val_loss: 0.3482 - val_accuracy: 0.8406\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3344 - accuracy: 0.8523 - val_loss: 0.3440 - val_accuracy: 0.8456\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3280 - accuracy: 0.8554 - val_loss: 0.3427 - val_accuracy: 0.8460\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 683us/step - loss: 0.3398 - accuracy: 0.8503 - val_loss: 0.3448 - val_accuracy: 0.8426\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3427 - accuracy: 0.8440 - val_loss: 0.3474 - val_accuracy: 0.8428\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3299 - accuracy: 0.8524 - val_loss: 0.3456 - val_accuracy: 0.8430\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3390 - accuracy: 0.8509 - val_loss: 0.3429 - val_accuracy: 0.8462\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3354 - accuracy: 0.8480 - val_loss: 0.3424 - val_accuracy: 0.8472\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3291 - accuracy: 0.8511 - val_loss: 0.3483 - val_accuracy: 0.8418\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3370 - accuracy: 0.8463 - val_loss: 0.3430 - val_accuracy: 0.8456\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3350 - accuracy: 0.8489 - val_loss: 0.3434 - val_accuracy: 0.8476\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 823us/step - loss: 0.3357 - accuracy: 0.8477 - val_loss: 0.3443 - val_accuracy: 0.8464\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 744us/step - loss: 0.3347 - accuracy: 0.8491 - val_loss: 0.3487 - val_accuracy: 0.8446\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 827us/step - loss: 0.3299 - accuracy: 0.8545 - val_loss: 0.3454 - val_accuracy: 0.8460\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 780us/step - loss: 0.3382 - accuracy: 0.8498 - val_loss: 0.3428 - val_accuracy: 0.8488\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3324 - accuracy: 0.8520 - val_loss: 0.3433 - val_accuracy: 0.8474\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3309 - accuracy: 0.8509 - val_loss: 0.3433 - val_accuracy: 0.8470\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3317 - accuracy: 0.8518 - val_loss: 0.3489 - val_accuracy: 0.8460\n",
      "400/400 [==============================] - 0s 710us/step - loss: 0.3316 - accuracy: 0.8558\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4696 - accuracy: 0.7789 - val_loss: 0.3734 - val_accuracy: 0.8174\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3693 - accuracy: 0.8250 - val_loss: 0.3656 - val_accuracy: 0.8208\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 917us/step - loss: 0.3651 - accuracy: 0.8274 - val_loss: 0.3634 - val_accuracy: 0.8244\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 886us/step - loss: 0.3665 - accuracy: 0.8263 - val_loss: 0.3605 - val_accuracy: 0.8298\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3506 - accuracy: 0.8376 - val_loss: 0.3569 - val_accuracy: 0.8308\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3515 - accuracy: 0.8369 - val_loss: 0.3559 - val_accuracy: 0.8378\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3435 - accuracy: 0.8445 - val_loss: 0.3540 - val_accuracy: 0.8322\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3521 - accuracy: 0.8393 - val_loss: 0.3504 - val_accuracy: 0.8374\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 781us/step - loss: 0.3494 - accuracy: 0.8443 - val_loss: 0.3516 - val_accuracy: 0.8356\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 831us/step - loss: 0.3447 - accuracy: 0.8417 - val_loss: 0.3536 - val_accuracy: 0.8354\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3353 - accuracy: 0.8499 - val_loss: 0.3473 - val_accuracy: 0.8414\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3392 - accuracy: 0.8473 - val_loss: 0.3440 - val_accuracy: 0.8414\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 770us/step - loss: 0.3411 - accuracy: 0.8467 - val_loss: 0.3428 - val_accuracy: 0.8440\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 776us/step - loss: 0.3390 - accuracy: 0.8469 - val_loss: 0.3441 - val_accuracy: 0.8434\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3334 - accuracy: 0.8550 - val_loss: 0.3459 - val_accuracy: 0.8424\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3318 - accuracy: 0.8526 - val_loss: 0.3412 - val_accuracy: 0.8466\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3308 - accuracy: 0.8527 - val_loss: 0.3447 - val_accuracy: 0.8470\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3352 - accuracy: 0.8497 - val_loss: 0.3457 - val_accuracy: 0.8454\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3244 - accuracy: 0.8532 - val_loss: 0.3444 - val_accuracy: 0.8458\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3283 - accuracy: 0.8502 - val_loss: 0.3471 - val_accuracy: 0.8426\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 951us/step - loss: 0.3255 - accuracy: 0.8553 - val_loss: 0.3426 - val_accuracy: 0.8464\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3273 - accuracy: 0.8538 - val_loss: 0.3434 - val_accuracy: 0.8434\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 887us/step - loss: 0.3293 - accuracy: 0.8514 - val_loss: 0.3430 - val_accuracy: 0.8454\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3320 - accuracy: 0.8546 - val_loss: 0.3423 - val_accuracy: 0.8440\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3310 - accuracy: 0.8551 - val_loss: 0.3413 - val_accuracy: 0.8470\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 833us/step - loss: 0.3324 - accuracy: 0.8544 - val_loss: 0.3433 - val_accuracy: 0.8490\n",
      "400/400 [==============================] - 0s 702us/step - loss: 0.3407 - accuracy: 0.8487\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 807us/step - loss: 0.4657 - accuracy: 0.7884 - val_loss: 0.3749 - val_accuracy: 0.8142\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 716us/step - loss: 0.3609 - accuracy: 0.8293 - val_loss: 0.3670 - val_accuracy: 0.8196\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3635 - accuracy: 0.8291 - val_loss: 0.3613 - val_accuracy: 0.8254\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 716us/step - loss: 0.3639 - accuracy: 0.8329 - val_loss: 0.3588 - val_accuracy: 0.8288\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3550 - accuracy: 0.8336 - val_loss: 0.3555 - val_accuracy: 0.8294\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 991us/step - loss: 0.3500 - accuracy: 0.8368 - val_loss: 0.3529 - val_accuracy: 0.8332\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3462 - accuracy: 0.8421 - val_loss: 0.3508 - val_accuracy: 0.8354\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 751us/step - loss: 0.3562 - accuracy: 0.8353 - val_loss: 0.3495 - val_accuracy: 0.8424\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3473 - accuracy: 0.8427 - val_loss: 0.3475 - val_accuracy: 0.8406\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3399 - accuracy: 0.8454 - val_loss: 0.3477 - val_accuracy: 0.8422\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3376 - accuracy: 0.8510 - val_loss: 0.3453 - val_accuracy: 0.8406\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3414 - accuracy: 0.8441 - val_loss: 0.3466 - val_accuracy: 0.8416\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3366 - accuracy: 0.8503 - val_loss: 0.3422 - val_accuracy: 0.8446\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3324 - accuracy: 0.8508 - val_loss: 0.3433 - val_accuracy: 0.8430\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3355 - accuracy: 0.8513 - val_loss: 0.3438 - val_accuracy: 0.8468\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 767us/step - loss: 0.3387 - accuracy: 0.8472 - val_loss: 0.3466 - val_accuracy: 0.8384\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3294 - accuracy: 0.8551 - val_loss: 0.3422 - val_accuracy: 0.8422\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3342 - accuracy: 0.8539 - val_loss: 0.3400 - val_accuracy: 0.8478\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 782us/step - loss: 0.3301 - accuracy: 0.8561 - val_loss: 0.3413 - val_accuracy: 0.8446\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 903us/step - loss: 0.3326 - accuracy: 0.8503 - val_loss: 0.3403 - val_accuracy: 0.8454\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3254 - accuracy: 0.8556 - val_loss: 0.3411 - val_accuracy: 0.8430\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 873us/step - loss: 0.3331 - accuracy: 0.8487 - val_loss: 0.3405 - val_accuracy: 0.8456\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 698us/step - loss: 0.3335 - accuracy: 0.8516 - val_loss: 0.3398 - val_accuracy: 0.8478\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3361 - accuracy: 0.8473 - val_loss: 0.3455 - val_accuracy: 0.8466\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3289 - accuracy: 0.8503 - val_loss: 0.3389 - val_accuracy: 0.8456\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3331 - accuracy: 0.8511 - val_loss: 0.3411 - val_accuracy: 0.8440\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 934us/step - loss: 0.3399 - accuracy: 0.8480 - val_loss: 0.3397 - val_accuracy: 0.8438\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3385 - accuracy: 0.8517 - val_loss: 0.3397 - val_accuracy: 0.8456\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 916us/step - loss: 0.3305 - accuracy: 0.8534 - val_loss: 0.3398 - val_accuracy: 0.8480\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3317 - accuracy: 0.8510 - val_loss: 0.3380 - val_accuracy: 0.8482\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 693us/step - loss: 0.3292 - accuracy: 0.8492 - val_loss: 0.3413 - val_accuracy: 0.8472\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3294 - accuracy: 0.8546 - val_loss: 0.3384 - val_accuracy: 0.8486\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3327 - accuracy: 0.8524 - val_loss: 0.3426 - val_accuracy: 0.8486\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 877us/step - loss: 0.3334 - accuracy: 0.8489 - val_loss: 0.3373 - val_accuracy: 0.8480\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3360 - accuracy: 0.8487 - val_loss: 0.3389 - val_accuracy: 0.8482\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3375 - accuracy: 0.8448 - val_loss: 0.3394 - val_accuracy: 0.8456\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3315 - accuracy: 0.8509 - val_loss: 0.3409 - val_accuracy: 0.8466\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3334 - accuracy: 0.8510 - val_loss: 0.3404 - val_accuracy: 0.8494\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 693us/step - loss: 0.3295 - accuracy: 0.8533 - val_loss: 0.3383 - val_accuracy: 0.8486\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 914us/step - loss: 0.3229 - accuracy: 0.8559 - val_loss: 0.3370 - val_accuracy: 0.8468\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3301 - accuracy: 0.8526 - val_loss: 0.3411 - val_accuracy: 0.8458\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3338 - accuracy: 0.8477 - val_loss: 0.3360 - val_accuracy: 0.8474\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 782us/step - loss: 0.3325 - accuracy: 0.8507 - val_loss: 0.3373 - val_accuracy: 0.8494\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3279 - accuracy: 0.8510 - val_loss: 0.3383 - val_accuracy: 0.8472\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3340 - accuracy: 0.8508 - val_loss: 0.3420 - val_accuracy: 0.8492\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3347 - accuracy: 0.8502 - val_loss: 0.3403 - val_accuracy: 0.8484\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3277 - accuracy: 0.8542 - val_loss: 0.3373 - val_accuracy: 0.8458\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3315 - accuracy: 0.8533 - val_loss: 0.3368 - val_accuracy: 0.8482\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3257 - accuracy: 0.8567 - val_loss: 0.3378 - val_accuracy: 0.8474\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3315 - accuracy: 0.8508 - val_loss: 0.3393 - val_accuracy: 0.8454\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3231 - accuracy: 0.8557 - val_loss: 0.3372 - val_accuracy: 0.8502\n",
      "Epoch 52/1000\n",
      "1600/1600 [==============================] - 1s 818us/step - loss: 0.3320 - accuracy: 0.8544 - val_loss: 0.3389 - val_accuracy: 0.8482\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3297 - accuracy: 0.8503\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 759us/step - loss: 0.4643 - accuracy: 0.7845 - val_loss: 0.3723 - val_accuracy: 0.8186\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3704 - accuracy: 0.8236 - val_loss: 0.3670 - val_accuracy: 0.8226\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3568 - accuracy: 0.8369 - val_loss: 0.3614 - val_accuracy: 0.8254\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3603 - accuracy: 0.8333 - val_loss: 0.3618 - val_accuracy: 0.8318\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3577 - accuracy: 0.8363 - val_loss: 0.3555 - val_accuracy: 0.8328\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3449 - accuracy: 0.8428 - val_loss: 0.3523 - val_accuracy: 0.8372\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 835us/step - loss: 0.3503 - accuracy: 0.8454 - val_loss: 0.3511 - val_accuracy: 0.8384\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3425 - accuracy: 0.8481 - val_loss: 0.3475 - val_accuracy: 0.8414\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3380 - accuracy: 0.8500 - val_loss: 0.3457 - val_accuracy: 0.8452\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3414 - accuracy: 0.8474 - val_loss: 0.3481 - val_accuracy: 0.8414\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 871us/step - loss: 0.3453 - accuracy: 0.8438 - val_loss: 0.3477 - val_accuracy: 0.8436\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3298 - accuracy: 0.8529 - val_loss: 0.3487 - val_accuracy: 0.8470\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3239 - accuracy: 0.8595 - val_loss: 0.3423 - val_accuracy: 0.8446\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 781us/step - loss: 0.3397 - accuracy: 0.8464 - val_loss: 0.3418 - val_accuracy: 0.8456\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 765us/step - loss: 0.3246 - accuracy: 0.8533 - val_loss: 0.3438 - val_accuracy: 0.8454\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 765us/step - loss: 0.3230 - accuracy: 0.8604 - val_loss: 0.3438 - val_accuracy: 0.8430\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3392 - accuracy: 0.8504 - val_loss: 0.3428 - val_accuracy: 0.8444\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3363 - accuracy: 0.8485 - val_loss: 0.3452 - val_accuracy: 0.8484\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3284 - accuracy: 0.8538 - val_loss: 0.3419 - val_accuracy: 0.8460\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3329 - accuracy: 0.8536 - val_loss: 0.3455 - val_accuracy: 0.8460\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 982us/step - loss: 0.3317 - accuracy: 0.8531 - val_loss: 0.3492 - val_accuracy: 0.8450\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3284 - accuracy: 0.8526 - val_loss: 0.3421 - val_accuracy: 0.8466\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3300 - accuracy: 0.8557 - val_loss: 0.3410 - val_accuracy: 0.8468\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3296 - accuracy: 0.8533 - val_loss: 0.3441 - val_accuracy: 0.8466\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3257 - accuracy: 0.8574 - val_loss: 0.3433 - val_accuracy: 0.8474\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 693us/step - loss: 0.3328 - accuracy: 0.8508 - val_loss: 0.3430 - val_accuracy: 0.8484\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3331 - accuracy: 0.8516 - val_loss: 0.3526 - val_accuracy: 0.8486\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3355 - accuracy: 0.8515 - val_loss: 0.3419 - val_accuracy: 0.8486\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3336 - accuracy: 0.8512 - val_loss: 0.3454 - val_accuracy: 0.8466\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 864us/step - loss: 0.3400 - accuracy: 0.8500 - val_loss: 0.3449 - val_accuracy: 0.8476\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3350 - accuracy: 0.8516 - val_loss: 0.3406 - val_accuracy: 0.8470\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3324 - accuracy: 0.8524 - val_loss: 0.3412 - val_accuracy: 0.8480\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3269 - accuracy: 0.8561 - val_loss: 0.3489 - val_accuracy: 0.8486\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3367 - accuracy: 0.8525 - val_loss: 0.3427 - val_accuracy: 0.8496\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 861us/step - loss: 0.3307 - accuracy: 0.8520 - val_loss: 0.3490 - val_accuracy: 0.8486\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3272 - accuracy: 0.8560 - val_loss: 0.3418 - val_accuracy: 0.8486\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 2s 946us/step - loss: 0.3290 - accuracy: 0.8557 - val_loss: 0.3431 - val_accuracy: 0.8480\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3224 - accuracy: 0.8576 - val_loss: 0.3418 - val_accuracy: 0.8490\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3333 - accuracy: 0.8523 - val_loss: 0.3438 - val_accuracy: 0.8488\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3261 - accuracy: 0.8547 - val_loss: 0.3416 - val_accuracy: 0.8478\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 852us/step - loss: 0.3358 - accuracy: 0.8513 - val_loss: 0.3415 - val_accuracy: 0.8486\n",
      "400/400 [==============================] - 0s 965us/step - loss: 0.3424 - accuracy: 0.8395\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 764us/step - loss: 0.4555 - accuracy: 0.7846 - val_loss: 0.3722 - val_accuracy: 0.8190\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 856us/step - loss: 0.3693 - accuracy: 0.8249 - val_loss: 0.3652 - val_accuracy: 0.8260\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3515 - accuracy: 0.8358 - val_loss: 0.3602 - val_accuracy: 0.8282\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 840us/step - loss: 0.3553 - accuracy: 0.8349 - val_loss: 0.3647 - val_accuracy: 0.8192\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3526 - accuracy: 0.8359 - val_loss: 0.3570 - val_accuracy: 0.8290\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 961us/step - loss: 0.3525 - accuracy: 0.8371 - val_loss: 0.3560 - val_accuracy: 0.8320\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 786us/step - loss: 0.3492 - accuracy: 0.8393 - val_loss: 0.3514 - val_accuracy: 0.8392\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 765us/step - loss: 0.3512 - accuracy: 0.8426 - val_loss: 0.3490 - val_accuracy: 0.8370\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 698us/step - loss: 0.3384 - accuracy: 0.8430 - val_loss: 0.3466 - val_accuracy: 0.8436\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3396 - accuracy: 0.8493 - val_loss: 0.3488 - val_accuracy: 0.8438\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3404 - accuracy: 0.8451 - val_loss: 0.3434 - val_accuracy: 0.8460\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 768us/step - loss: 0.3375 - accuracy: 0.8476 - val_loss: 0.3443 - val_accuracy: 0.8450\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3396 - accuracy: 0.8455 - val_loss: 0.3453 - val_accuracy: 0.8420\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3408 - accuracy: 0.8504 - val_loss: 0.3497 - val_accuracy: 0.8452\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 914us/step - loss: 0.3304 - accuracy: 0.8505 - val_loss: 0.3449 - val_accuracy: 0.8450\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3290 - accuracy: 0.8535 - val_loss: 0.3413 - val_accuracy: 0.8456\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3385 - accuracy: 0.8477 - val_loss: 0.3431 - val_accuracy: 0.8450\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 863us/step - loss: 0.3354 - accuracy: 0.8474 - val_loss: 0.3399 - val_accuracy: 0.8478\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 991us/step - loss: 0.3337 - accuracy: 0.8500 - val_loss: 0.3462 - val_accuracy: 0.8430\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3347 - accuracy: 0.8513 - val_loss: 0.3430 - val_accuracy: 0.8440\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3339 - accuracy: 0.8534 - val_loss: 0.3410 - val_accuracy: 0.8468\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 868us/step - loss: 0.3393 - accuracy: 0.8482 - val_loss: 0.3408 - val_accuracy: 0.8466\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 752us/step - loss: 0.3328 - accuracy: 0.8536 - val_loss: 0.3483 - val_accuracy: 0.8412\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3333 - accuracy: 0.8521 - val_loss: 0.3433 - val_accuracy: 0.8476\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3367 - accuracy: 0.8460 - val_loss: 0.3438 - val_accuracy: 0.8440\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3291 - accuracy: 0.8531 - val_loss: 0.3388 - val_accuracy: 0.8470\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3238 - accuracy: 0.8552 - val_loss: 0.3382 - val_accuracy: 0.8484\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3324 - accuracy: 0.8514 - val_loss: 0.3407 - val_accuracy: 0.8466\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 874us/step - loss: 0.3270 - accuracy: 0.8581 - val_loss: 0.3387 - val_accuracy: 0.8460\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3390 - accuracy: 0.8491 - val_loss: 0.3397 - val_accuracy: 0.8472\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 848us/step - loss: 0.3312 - accuracy: 0.8519 - val_loss: 0.3413 - val_accuracy: 0.8466\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3338 - accuracy: 0.8495 - val_loss: 0.3403 - val_accuracy: 0.8470\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 763us/step - loss: 0.3334 - accuracy: 0.8497 - val_loss: 0.3391 - val_accuracy: 0.8464\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3322 - accuracy: 0.8506 - val_loss: 0.3406 - val_accuracy: 0.8482\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3309 - accuracy: 0.8508 - val_loss: 0.3446 - val_accuracy: 0.8428\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3408 - accuracy: 0.8518 - val_loss: 0.3414 - val_accuracy: 0.8474\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 869us/step - loss: 0.3363 - accuracy: 0.8518 - val_loss: 0.3402 - val_accuracy: 0.8498\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3290 - accuracy: 0.8512\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4550 - accuracy: 0.7855 - val_loss: 0.3719 - val_accuracy: 0.8238\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 698us/step - loss: 0.3658 - accuracy: 0.8287 - val_loss: 0.3644 - val_accuracy: 0.8216\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3631 - accuracy: 0.8292 - val_loss: 0.3612 - val_accuracy: 0.8334\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3562 - accuracy: 0.8345 - val_loss: 0.3543 - val_accuracy: 0.8326\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3577 - accuracy: 0.8351 - val_loss: 0.3531 - val_accuracy: 0.8370\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3528 - accuracy: 0.8389 - val_loss: 0.3535 - val_accuracy: 0.8426\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 847us/step - loss: 0.3476 - accuracy: 0.8425 - val_loss: 0.3497 - val_accuracy: 0.8458\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3450 - accuracy: 0.8434 - val_loss: 0.3492 - val_accuracy: 0.8364\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3437 - accuracy: 0.8467 - val_loss: 0.3459 - val_accuracy: 0.8440\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 826us/step - loss: 0.3367 - accuracy: 0.8493 - val_loss: 0.3457 - val_accuracy: 0.8460\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3338 - accuracy: 0.8555 - val_loss: 0.3429 - val_accuracy: 0.8462\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 913us/step - loss: 0.3340 - accuracy: 0.8525 - val_loss: 0.3425 - val_accuracy: 0.8444\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3303 - accuracy: 0.8501 - val_loss: 0.3436 - val_accuracy: 0.8428\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 853us/step - loss: 0.3328 - accuracy: 0.8494 - val_loss: 0.3435 - val_accuracy: 0.8458\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3358 - accuracy: 0.8491 - val_loss: 0.3433 - val_accuracy: 0.8470\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3396 - accuracy: 0.8473 - val_loss: 0.3427 - val_accuracy: 0.8446\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3330 - accuracy: 0.8508 - val_loss: 0.3406 - val_accuracy: 0.8482\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3266 - accuracy: 0.8543 - val_loss: 0.3420 - val_accuracy: 0.8446\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3334 - accuracy: 0.8496 - val_loss: 0.3431 - val_accuracy: 0.8454\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 910us/step - loss: 0.3362 - accuracy: 0.8493 - val_loss: 0.3425 - val_accuracy: 0.8476\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3338 - accuracy: 0.8509 - val_loss: 0.3432 - val_accuracy: 0.8498\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3351 - accuracy: 0.8506 - val_loss: 0.3416 - val_accuracy: 0.8502\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.3292 - accuracy: 0.8501 - val_loss: 0.3452 - val_accuracy: 0.8440\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3263 - accuracy: 0.8555 - val_loss: 0.3478 - val_accuracy: 0.8462\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3385 - accuracy: 0.8481 - val_loss: 0.3420 - val_accuracy: 0.8468\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3366 - accuracy: 0.8496 - val_loss: 0.3574 - val_accuracy: 0.8454\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3367 - accuracy: 0.8486 - val_loss: 0.3457 - val_accuracy: 0.8466\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3302 - accuracy: 0.8550\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 3s 1ms/step - loss: 0.4486 - accuracy: 0.7896 - val_loss: 0.3703 - val_accuracy: 0.8286\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3670 - accuracy: 0.8220 - val_loss: 0.3624 - val_accuracy: 0.8244\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3553 - accuracy: 0.8312 - val_loss: 0.3616 - val_accuracy: 0.8270\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3515 - accuracy: 0.8370 - val_loss: 0.3551 - val_accuracy: 0.8328\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3507 - accuracy: 0.8412 - val_loss: 0.3510 - val_accuracy: 0.8376\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 797us/step - loss: 0.3502 - accuracy: 0.8416 - val_loss: 0.3508 - val_accuracy: 0.8402\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3408 - accuracy: 0.8445 - val_loss: 0.3470 - val_accuracy: 0.8434\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3372 - accuracy: 0.8474 - val_loss: 0.3467 - val_accuracy: 0.8420\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3375 - accuracy: 0.8491 - val_loss: 0.3471 - val_accuracy: 0.8406\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 665us/step - loss: 0.3365 - accuracy: 0.8488 - val_loss: 0.3435 - val_accuracy: 0.8474\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3346 - accuracy: 0.8509 - val_loss: 0.3438 - val_accuracy: 0.8464\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3360 - accuracy: 0.8449 - val_loss: 0.3431 - val_accuracy: 0.8486\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3300 - accuracy: 0.8520 - val_loss: 0.3415 - val_accuracy: 0.8486\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3341 - accuracy: 0.8504 - val_loss: 0.3418 - val_accuracy: 0.8464\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3238 - accuracy: 0.8555 - val_loss: 0.3469 - val_accuracy: 0.8406\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3315 - accuracy: 0.8510 - val_loss: 0.3407 - val_accuracy: 0.8484\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3327 - accuracy: 0.8513 - val_loss: 0.3444 - val_accuracy: 0.8480\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3296 - accuracy: 0.8524 - val_loss: 0.3412 - val_accuracy: 0.8462\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3238 - accuracy: 0.8552 - val_loss: 0.3401 - val_accuracy: 0.8464\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3327 - accuracy: 0.8525 - val_loss: 0.3407 - val_accuracy: 0.8478\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3241 - accuracy: 0.8557 - val_loss: 0.3466 - val_accuracy: 0.8442\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 688us/step - loss: 0.3314 - accuracy: 0.8515 - val_loss: 0.3404 - val_accuracy: 0.8478\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3257 - accuracy: 0.8561 - val_loss: 0.3405 - val_accuracy: 0.8474\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3329 - accuracy: 0.8479 - val_loss: 0.3395 - val_accuracy: 0.8488\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3260 - accuracy: 0.8534 - val_loss: 0.3412 - val_accuracy: 0.8482\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3300 - accuracy: 0.8527 - val_loss: 0.3454 - val_accuracy: 0.8482\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3293 - accuracy: 0.8495 - val_loss: 0.3449 - val_accuracy: 0.8478\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3315 - accuracy: 0.8487 - val_loss: 0.3418 - val_accuracy: 0.8466\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3282 - accuracy: 0.8507 - val_loss: 0.3506 - val_accuracy: 0.8420\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3307 - accuracy: 0.8553 - val_loss: 0.3467 - val_accuracy: 0.8474\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3288 - accuracy: 0.8529 - val_loss: 0.3424 - val_accuracy: 0.8462\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 735us/step - loss: 0.3355 - accuracy: 0.8477 - val_loss: 0.3420 - val_accuracy: 0.8480\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 662us/step - loss: 0.3231 - accuracy: 0.8581 - val_loss: 0.3436 - val_accuracy: 0.8468\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3264 - accuracy: 0.8513 - val_loss: 0.3447 - val_accuracy: 0.8440\n",
      "400/400 [==============================] - 0s 920us/step - loss: 0.3393 - accuracy: 0.8522\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 775us/step - loss: 0.4469 - accuracy: 0.7971 - val_loss: 0.3724 - val_accuracy: 0.8148\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3659 - accuracy: 0.8297 - val_loss: 0.3623 - val_accuracy: 0.8244\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3636 - accuracy: 0.8298 - val_loss: 0.3565 - val_accuracy: 0.8300\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3578 - accuracy: 0.8370 - val_loss: 0.3546 - val_accuracy: 0.8362\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3571 - accuracy: 0.8372 - val_loss: 0.3566 - val_accuracy: 0.8318\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3495 - accuracy: 0.8400 - val_loss: 0.3475 - val_accuracy: 0.8384\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 830us/step - loss: 0.3425 - accuracy: 0.8444 - val_loss: 0.3457 - val_accuracy: 0.8418\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3520 - accuracy: 0.8405 - val_loss: 0.3503 - val_accuracy: 0.8428\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3422 - accuracy: 0.8481 - val_loss: 0.3444 - val_accuracy: 0.8474\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3409 - accuracy: 0.8444 - val_loss: 0.3412 - val_accuracy: 0.8466\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3321 - accuracy: 0.8522 - val_loss: 0.3410 - val_accuracy: 0.8466\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3360 - accuracy: 0.8500 - val_loss: 0.3417 - val_accuracy: 0.8452\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3379 - accuracy: 0.8483 - val_loss: 0.3419 - val_accuracy: 0.8468\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3331 - accuracy: 0.8496 - val_loss: 0.3444 - val_accuracy: 0.8416\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3277 - accuracy: 0.8515 - val_loss: 0.3399 - val_accuracy: 0.8478\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3323 - accuracy: 0.8502 - val_loss: 0.3405 - val_accuracy: 0.8454\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3314 - accuracy: 0.8488 - val_loss: 0.3398 - val_accuracy: 0.8482\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3352 - accuracy: 0.8500 - val_loss: 0.3390 - val_accuracy: 0.8480\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 673us/step - loss: 0.3205 - accuracy: 0.8602 - val_loss: 0.3494 - val_accuracy: 0.8458\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3363 - accuracy: 0.8489 - val_loss: 0.3411 - val_accuracy: 0.8480\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3379 - accuracy: 0.8481 - val_loss: 0.3400 - val_accuracy: 0.8484\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 841us/step - loss: 0.3428 - accuracy: 0.8457 - val_loss: 0.3477 - val_accuracy: 0.8454\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3394 - accuracy: 0.8482 - val_loss: 0.3414 - val_accuracy: 0.8478\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3324 - accuracy: 0.8488 - val_loss: 0.3454 - val_accuracy: 0.8426\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3347 - accuracy: 0.8495 - val_loss: 0.3449 - val_accuracy: 0.8468\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3289 - accuracy: 0.8549 - val_loss: 0.3399 - val_accuracy: 0.8482\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3296 - accuracy: 0.8541 - val_loss: 0.3475 - val_accuracy: 0.8416\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3362 - accuracy: 0.8484 - val_loss: 0.3399 - val_accuracy: 0.8448\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3317 - accuracy: 0.8493\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4499 - accuracy: 0.7981 - val_loss: 0.3734 - val_accuracy: 0.8218\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3703 - accuracy: 0.8249 - val_loss: 0.3645 - val_accuracy: 0.8218\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 874us/step - loss: 0.3584 - accuracy: 0.8322 - val_loss: 0.3614 - val_accuracy: 0.8230\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 668us/step - loss: 0.3544 - accuracy: 0.8316 - val_loss: 0.3606 - val_accuracy: 0.8362\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3538 - accuracy: 0.8376 - val_loss: 0.3588 - val_accuracy: 0.8286\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3561 - accuracy: 0.8361 - val_loss: 0.3540 - val_accuracy: 0.8396\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3441 - accuracy: 0.8451 - val_loss: 0.3502 - val_accuracy: 0.8394\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3466 - accuracy: 0.8467 - val_loss: 0.3501 - val_accuracy: 0.8422\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3362 - accuracy: 0.8487 - val_loss: 0.3558 - val_accuracy: 0.8346\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3386 - accuracy: 0.8483 - val_loss: 0.3454 - val_accuracy: 0.8426\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3407 - accuracy: 0.8468 - val_loss: 0.3477 - val_accuracy: 0.8428\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 821us/step - loss: 0.3422 - accuracy: 0.8479 - val_loss: 0.3517 - val_accuracy: 0.8468\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 880us/step - loss: 0.3318 - accuracy: 0.8555 - val_loss: 0.3474 - val_accuracy: 0.8420\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 766us/step - loss: 0.3331 - accuracy: 0.8491 - val_loss: 0.3425 - val_accuracy: 0.8444\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3376 - accuracy: 0.8496 - val_loss: 0.3433 - val_accuracy: 0.8470\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3411 - accuracy: 0.8500 - val_loss: 0.3410 - val_accuracy: 0.8472\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 767us/step - loss: 0.3420 - accuracy: 0.8492 - val_loss: 0.3419 - val_accuracy: 0.8442\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3329 - accuracy: 0.8517 - val_loss: 0.3418 - val_accuracy: 0.8476\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 972us/step - loss: 0.3412 - accuracy: 0.8474 - val_loss: 0.3409 - val_accuracy: 0.8466\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3250 - accuracy: 0.8573 - val_loss: 0.3403 - val_accuracy: 0.8474\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 872us/step - loss: 0.3322 - accuracy: 0.8518 - val_loss: 0.3415 - val_accuracy: 0.8468\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3405 - accuracy: 0.8477 - val_loss: 0.3443 - val_accuracy: 0.8468\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3318 - accuracy: 0.8524 - val_loss: 0.3402 - val_accuracy: 0.8468\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3293 - accuracy: 0.8560 - val_loss: 0.3422 - val_accuracy: 0.8468\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3209 - accuracy: 0.8589 - val_loss: 0.3474 - val_accuracy: 0.8462\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 698us/step - loss: 0.3324 - accuracy: 0.8523 - val_loss: 0.3398 - val_accuracy: 0.8472\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3305 - accuracy: 0.8546 - val_loss: 0.3457 - val_accuracy: 0.8474\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3312 - accuracy: 0.8525 - val_loss: 0.3458 - val_accuracy: 0.8492\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3280 - accuracy: 0.8562 - val_loss: 0.3403 - val_accuracy: 0.8486\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3251 - accuracy: 0.8575 - val_loss: 0.3409 - val_accuracy: 0.8472\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3304 - accuracy: 0.8560 - val_loss: 0.3425 - val_accuracy: 0.8474\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3298 - accuracy: 0.8544 - val_loss: 0.3409 - val_accuracy: 0.8478\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3265 - accuracy: 0.8562 - val_loss: 0.3497 - val_accuracy: 0.8472\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3285 - accuracy: 0.8581 - val_loss: 0.3401 - val_accuracy: 0.8480\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 770us/step - loss: 0.3269 - accuracy: 0.8564 - val_loss: 0.3442 - val_accuracy: 0.8478\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 773us/step - loss: 0.3290 - accuracy: 0.8562 - val_loss: 0.3424 - val_accuracy: 0.8458\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3418 - accuracy: 0.8382\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 3s 1ms/step - loss: 0.4784 - accuracy: 0.7793 - val_loss: 0.3732 - val_accuracy: 0.8200\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 772us/step - loss: 0.3701 - accuracy: 0.8236 - val_loss: 0.3692 - val_accuracy: 0.8160\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3610 - accuracy: 0.8303 - val_loss: 0.3613 - val_accuracy: 0.8240\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3618 - accuracy: 0.8278 - val_loss: 0.3570 - val_accuracy: 0.8300\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 958us/step - loss: 0.3558 - accuracy: 0.8345 - val_loss: 0.3564 - val_accuracy: 0.8306\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3557 - accuracy: 0.8371 - val_loss: 0.3517 - val_accuracy: 0.8338\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3526 - accuracy: 0.8403 - val_loss: 0.3507 - val_accuracy: 0.8360\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3436 - accuracy: 0.8438 - val_loss: 0.3456 - val_accuracy: 0.8432\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3511 - accuracy: 0.8416 - val_loss: 0.3443 - val_accuracy: 0.8402\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 716us/step - loss: 0.3363 - accuracy: 0.8460 - val_loss: 0.3416 - val_accuracy: 0.8442\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3356 - accuracy: 0.8492 - val_loss: 0.3424 - val_accuracy: 0.8428\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 889us/step - loss: 0.3365 - accuracy: 0.8490 - val_loss: 0.3403 - val_accuracy: 0.8462\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3333 - accuracy: 0.8511 - val_loss: 0.3383 - val_accuracy: 0.8480\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 977us/step - loss: 0.3342 - accuracy: 0.8499 - val_loss: 0.3383 - val_accuracy: 0.8470\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3322 - accuracy: 0.8498 - val_loss: 0.3398 - val_accuracy: 0.8448\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3310 - accuracy: 0.8529 - val_loss: 0.3387 - val_accuracy: 0.8466\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 831us/step - loss: 0.3306 - accuracy: 0.8502 - val_loss: 0.3374 - val_accuracy: 0.8466\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3320 - accuracy: 0.8513 - val_loss: 0.3361 - val_accuracy: 0.8450\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 911us/step - loss: 0.3291 - accuracy: 0.8499 - val_loss: 0.3341 - val_accuracy: 0.8482\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3382 - accuracy: 0.8491 - val_loss: 0.3373 - val_accuracy: 0.8478\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3361 - accuracy: 0.8494 - val_loss: 0.3429 - val_accuracy: 0.8456\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3292 - accuracy: 0.8532 - val_loss: 0.3339 - val_accuracy: 0.8496\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3386 - accuracy: 0.8467 - val_loss: 0.3424 - val_accuracy: 0.8506\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3234 - accuracy: 0.8557 - val_loss: 0.3359 - val_accuracy: 0.8480\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3342 - accuracy: 0.8479 - val_loss: 0.3489 - val_accuracy: 0.8486\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 796us/step - loss: 0.3314 - accuracy: 0.8500 - val_loss: 0.3371 - val_accuracy: 0.8482\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3324 - accuracy: 0.8502 - val_loss: 0.3420 - val_accuracy: 0.8440\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3376 - accuracy: 0.8500 - val_loss: 0.3383 - val_accuracy: 0.8518\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 789us/step - loss: 0.3297 - accuracy: 0.8571 - val_loss: 0.3389 - val_accuracy: 0.8520\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3302 - accuracy: 0.8538 - val_loss: 0.3476 - val_accuracy: 0.8436\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3245 - accuracy: 0.8583 - val_loss: 0.3424 - val_accuracy: 0.8500\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 2s 995us/step - loss: 0.3455 - accuracy: 0.8445 - val_loss: 0.3414 - val_accuracy: 0.8480\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3284 - accuracy: 0.8525\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4914 - accuracy: 0.7691 - val_loss: 0.3810 - val_accuracy: 0.8130\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3806 - accuracy: 0.8190 - val_loss: 0.3727 - val_accuracy: 0.8182\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3672 - accuracy: 0.8256 - val_loss: 0.3670 - val_accuracy: 0.8220\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3703 - accuracy: 0.8246 - val_loss: 0.3637 - val_accuracy: 0.8226\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3589 - accuracy: 0.8333 - val_loss: 0.3619 - val_accuracy: 0.8264\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3635 - accuracy: 0.8315 - val_loss: 0.3695 - val_accuracy: 0.8212\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 785us/step - loss: 0.3584 - accuracy: 0.8361 - val_loss: 0.3566 - val_accuracy: 0.8312\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 804us/step - loss: 0.3446 - accuracy: 0.8435 - val_loss: 0.3564 - val_accuracy: 0.8268\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3516 - accuracy: 0.8421 - val_loss: 0.3564 - val_accuracy: 0.8384\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3466 - accuracy: 0.8419 - val_loss: 0.3543 - val_accuracy: 0.8382\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 2s 994us/step - loss: 0.3476 - accuracy: 0.8411 - val_loss: 0.3523 - val_accuracy: 0.8392\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3483 - accuracy: 0.8431 - val_loss: 0.3497 - val_accuracy: 0.8344\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3472 - accuracy: 0.8430 - val_loss: 0.3483 - val_accuracy: 0.8378\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3490 - accuracy: 0.8397 - val_loss: 0.3502 - val_accuracy: 0.8380\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3388 - accuracy: 0.8478 - val_loss: 0.3474 - val_accuracy: 0.8406\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3458 - accuracy: 0.8442 - val_loss: 0.3461 - val_accuracy: 0.8392\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3347 - accuracy: 0.8485 - val_loss: 0.3448 - val_accuracy: 0.8432\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 844us/step - loss: 0.3426 - accuracy: 0.8477 - val_loss: 0.3437 - val_accuracy: 0.8452\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3358 - accuracy: 0.8486 - val_loss: 0.3453 - val_accuracy: 0.8434\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 811us/step - loss: 0.3452 - accuracy: 0.8472 - val_loss: 0.3459 - val_accuracy: 0.8440\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 793us/step - loss: 0.3348 - accuracy: 0.8484 - val_loss: 0.3439 - val_accuracy: 0.8472\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3338 - accuracy: 0.8494 - val_loss: 0.3563 - val_accuracy: 0.8362\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 818us/step - loss: 0.3370 - accuracy: 0.8472 - val_loss: 0.3491 - val_accuracy: 0.8432\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3393 - accuracy: 0.8478 - val_loss: 0.3429 - val_accuracy: 0.8440\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3371 - accuracy: 0.8510 - val_loss: 0.3444 - val_accuracy: 0.8470\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 723us/step - loss: 0.3270 - accuracy: 0.8564 - val_loss: 0.3407 - val_accuracy: 0.8476\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3283 - accuracy: 0.8492 - val_loss: 0.3453 - val_accuracy: 0.8460\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3362 - accuracy: 0.8471 - val_loss: 0.3407 - val_accuracy: 0.8440\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3356 - accuracy: 0.8490 - val_loss: 0.3448 - val_accuracy: 0.8460\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3318 - accuracy: 0.8485 - val_loss: 0.3424 - val_accuracy: 0.8430\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 2s 982us/step - loss: 0.3312 - accuracy: 0.8531 - val_loss: 0.3394 - val_accuracy: 0.8472\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3463 - accuracy: 0.8458 - val_loss: 0.3445 - val_accuracy: 0.8476\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3271 - accuracy: 0.8536 - val_loss: 0.3401 - val_accuracy: 0.8468\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3355 - accuracy: 0.8488 - val_loss: 0.3412 - val_accuracy: 0.8456\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 2s 940us/step - loss: 0.3334 - accuracy: 0.8488 - val_loss: 0.3405 - val_accuracy: 0.8434\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3353 - accuracy: 0.8502 - val_loss: 0.3435 - val_accuracy: 0.8444\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3278 - accuracy: 0.8527 - val_loss: 0.3375 - val_accuracy: 0.8476\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 746us/step - loss: 0.3289 - accuracy: 0.8528 - val_loss: 0.3396 - val_accuracy: 0.8458\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 746us/step - loss: 0.3313 - accuracy: 0.8519 - val_loss: 0.3429 - val_accuracy: 0.8402\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3362 - accuracy: 0.8486 - val_loss: 0.3398 - val_accuracy: 0.8450\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 2s 944us/step - loss: 0.3343 - accuracy: 0.8508 - val_loss: 0.3400 - val_accuracy: 0.8448\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3269 - accuracy: 0.8506 - val_loss: 0.3397 - val_accuracy: 0.8476\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 795us/step - loss: 0.3299 - accuracy: 0.8536 - val_loss: 0.3379 - val_accuracy: 0.8452\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 899us/step - loss: 0.3263 - accuracy: 0.8556 - val_loss: 0.3412 - val_accuracy: 0.8430\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3325 - accuracy: 0.8514 - val_loss: 0.3414 - val_accuracy: 0.8418\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3353 - accuracy: 0.8489 - val_loss: 0.3395 - val_accuracy: 0.8448\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3353 - accuracy: 0.8472 - val_loss: 0.3413 - val_accuracy: 0.8444\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3277 - accuracy: 0.8535\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 770us/step - loss: 0.4765 - accuracy: 0.7777 - val_loss: 0.3844 - val_accuracy: 0.8176\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3883 - accuracy: 0.8152 - val_loss: 0.3771 - val_accuracy: 0.8206\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 749us/step - loss: 0.3730 - accuracy: 0.8263 - val_loss: 0.3702 - val_accuracy: 0.8264\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3684 - accuracy: 0.8286 - val_loss: 0.3670 - val_accuracy: 0.8298\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3733 - accuracy: 0.8239 - val_loss: 0.3678 - val_accuracy: 0.8346\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3636 - accuracy: 0.8330 - val_loss: 0.3648 - val_accuracy: 0.8296\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3644 - accuracy: 0.8317 - val_loss: 0.3630 - val_accuracy: 0.8350\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 998us/step - loss: 0.3577 - accuracy: 0.8367 - val_loss: 0.3630 - val_accuracy: 0.8362\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3556 - accuracy: 0.8416 - val_loss: 0.3616 - val_accuracy: 0.8384\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3643 - accuracy: 0.8352 - val_loss: 0.3626 - val_accuracy: 0.8376\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3562 - accuracy: 0.8413 - val_loss: 0.3582 - val_accuracy: 0.8410\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3556 - accuracy: 0.8436 - val_loss: 0.3627 - val_accuracy: 0.8392\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 768us/step - loss: 0.3503 - accuracy: 0.8462 - val_loss: 0.3597 - val_accuracy: 0.8406\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3567 - accuracy: 0.8470 - val_loss: 0.3563 - val_accuracy: 0.8434\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3495 - accuracy: 0.8469 - val_loss: 0.3571 - val_accuracy: 0.8450\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 752us/step - loss: 0.3436 - accuracy: 0.8460 - val_loss: 0.3542 - val_accuracy: 0.8422\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3395 - accuracy: 0.8530 - val_loss: 0.3563 - val_accuracy: 0.8422\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3503 - accuracy: 0.8436 - val_loss: 0.3540 - val_accuracy: 0.8462\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3390 - accuracy: 0.8540 - val_loss: 0.3670 - val_accuracy: 0.8384\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 857us/step - loss: 0.3514 - accuracy: 0.8420 - val_loss: 0.3508 - val_accuracy: 0.8460\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3422 - accuracy: 0.8481 - val_loss: 0.3508 - val_accuracy: 0.8458\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3447 - accuracy: 0.8464 - val_loss: 0.3572 - val_accuracy: 0.8428\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3493 - accuracy: 0.8481 - val_loss: 0.3580 - val_accuracy: 0.8418\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 878us/step - loss: 0.3375 - accuracy: 0.8496 - val_loss: 0.3541 - val_accuracy: 0.8462\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3399 - accuracy: 0.8507 - val_loss: 0.3607 - val_accuracy: 0.8414\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 2s 949us/step - loss: 0.3370 - accuracy: 0.8535 - val_loss: 0.3509 - val_accuracy: 0.8462\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3429 - accuracy: 0.8542 - val_loss: 0.3545 - val_accuracy: 0.8428\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3352 - accuracy: 0.8543 - val_loss: 0.3574 - val_accuracy: 0.8454\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3381 - accuracy: 0.8539 - val_loss: 0.3543 - val_accuracy: 0.8452\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3440 - accuracy: 0.8484 - val_loss: 0.3615 - val_accuracy: 0.8406\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3356 - accuracy: 0.8551 - val_loss: 0.3536 - val_accuracy: 0.8466\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3490 - accuracy: 0.8478\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 785us/step - loss: 0.4794 - accuracy: 0.7780 - val_loss: 0.3799 - val_accuracy: 0.8102\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3674 - accuracy: 0.8268 - val_loss: 0.3649 - val_accuracy: 0.8228\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3637 - accuracy: 0.8323 - val_loss: 0.3613 - val_accuracy: 0.8250\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3589 - accuracy: 0.8327 - val_loss: 0.3592 - val_accuracy: 0.8308\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3684 - accuracy: 0.8266 - val_loss: 0.3650 - val_accuracy: 0.8352\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3506 - accuracy: 0.8354 - val_loss: 0.3534 - val_accuracy: 0.8318\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 798us/step - loss: 0.3537 - accuracy: 0.8383 - val_loss: 0.3505 - val_accuracy: 0.8364\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3439 - accuracy: 0.8448 - val_loss: 0.3510 - val_accuracy: 0.8352\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3388 - accuracy: 0.8486 - val_loss: 0.3451 - val_accuracy: 0.8436\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3424 - accuracy: 0.8444 - val_loss: 0.3450 - val_accuracy: 0.8406\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 793us/step - loss: 0.3347 - accuracy: 0.8505 - val_loss: 0.3423 - val_accuracy: 0.8434\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 825us/step - loss: 0.3357 - accuracy: 0.8498 - val_loss: 0.3437 - val_accuracy: 0.8420\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3434 - accuracy: 0.8443 - val_loss: 0.3429 - val_accuracy: 0.8438\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3412 - accuracy: 0.8468 - val_loss: 0.3406 - val_accuracy: 0.8464\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3349 - accuracy: 0.8514 - val_loss: 0.3405 - val_accuracy: 0.8482\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 831us/step - loss: 0.3346 - accuracy: 0.8486 - val_loss: 0.3446 - val_accuracy: 0.8464\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3352 - accuracy: 0.8495 - val_loss: 0.3394 - val_accuracy: 0.8434\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 2s 954us/step - loss: 0.3332 - accuracy: 0.8499 - val_loss: 0.3383 - val_accuracy: 0.8446\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 731us/step - loss: 0.3253 - accuracy: 0.8504 - val_loss: 0.3390 - val_accuracy: 0.8462\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3297 - accuracy: 0.8531 - val_loss: 0.3387 - val_accuracy: 0.8450\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3313 - accuracy: 0.8479 - val_loss: 0.3363 - val_accuracy: 0.8466\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3304 - accuracy: 0.8495 - val_loss: 0.3362 - val_accuracy: 0.8480\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 779us/step - loss: 0.3278 - accuracy: 0.8569 - val_loss: 0.3378 - val_accuracy: 0.8444\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 808us/step - loss: 0.3380 - accuracy: 0.8471 - val_loss: 0.3404 - val_accuracy: 0.8428\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3360 - accuracy: 0.8476 - val_loss: 0.3370 - val_accuracy: 0.8470\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3284 - accuracy: 0.8484 - val_loss: 0.3372 - val_accuracy: 0.8470\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3320 - accuracy: 0.8504 - val_loss: 0.3378 - val_accuracy: 0.8474\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3317 - accuracy: 0.8490 - val_loss: 0.3382 - val_accuracy: 0.8456\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 810us/step - loss: 0.3377 - accuracy: 0.8492 - val_loss: 0.3411 - val_accuracy: 0.8456\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3370 - accuracy: 0.8490 - val_loss: 0.3371 - val_accuracy: 0.8466\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3362 - accuracy: 0.8477 - val_loss: 0.3381 - val_accuracy: 0.8476\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3298 - accuracy: 0.8545 - val_loss: 0.3356 - val_accuracy: 0.8486\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 854us/step - loss: 0.3324 - accuracy: 0.8503 - val_loss: 0.3369 - val_accuracy: 0.8482\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3418 - accuracy: 0.8451 - val_loss: 0.3421 - val_accuracy: 0.8472\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3349 - accuracy: 0.8496 - val_loss: 0.3359 - val_accuracy: 0.8480\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3281 - accuracy: 0.8556 - val_loss: 0.3363 - val_accuracy: 0.8480\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3241 - accuracy: 0.8569 - val_loss: 0.3392 - val_accuracy: 0.8482\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3316 - accuracy: 0.8529 - val_loss: 0.3359 - val_accuracy: 0.8478\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3238 - accuracy: 0.8527 - val_loss: 0.3343 - val_accuracy: 0.8488\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 723us/step - loss: 0.3329 - accuracy: 0.8505 - val_loss: 0.3346 - val_accuracy: 0.8490\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3215 - accuracy: 0.8563 - val_loss: 0.3423 - val_accuracy: 0.8484\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3211 - accuracy: 0.8583 - val_loss: 0.3372 - val_accuracy: 0.8494\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3270 - accuracy: 0.8536 - val_loss: 0.3366 - val_accuracy: 0.8488\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 2s 941us/step - loss: 0.3313 - accuracy: 0.8488 - val_loss: 0.3356 - val_accuracy: 0.8472\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3230 - accuracy: 0.8574 - val_loss: 0.3398 - val_accuracy: 0.8450\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3314 - accuracy: 0.8523 - val_loss: 0.3381 - val_accuracy: 0.8442\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 698us/step - loss: 0.3278 - accuracy: 0.8542 - val_loss: 0.3358 - val_accuracy: 0.8434\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3287 - accuracy: 0.8544 - val_loss: 0.3380 - val_accuracy: 0.8458\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 749us/step - loss: 0.3275 - accuracy: 0.8554 - val_loss: 0.3362 - val_accuracy: 0.8482\n",
      "400/400 [==============================] - 0s 807us/step - loss: 0.3330 - accuracy: 0.8505\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 804us/step - loss: 0.4931 - accuracy: 0.7705 - val_loss: 0.3849 - val_accuracy: 0.8164\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 840us/step - loss: 0.3877 - accuracy: 0.8160 - val_loss: 0.3787 - val_accuracy: 0.8184\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3778 - accuracy: 0.8224 - val_loss: 0.3712 - val_accuracy: 0.8282\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 2s 980us/step - loss: 0.3610 - accuracy: 0.8373 - val_loss: 0.3638 - val_accuracy: 0.8332\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3640 - accuracy: 0.8366 - val_loss: 0.3659 - val_accuracy: 0.8372\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3607 - accuracy: 0.8413 - val_loss: 0.3623 - val_accuracy: 0.8382\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3515 - accuracy: 0.8455 - val_loss: 0.3633 - val_accuracy: 0.8378\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3523 - accuracy: 0.8423 - val_loss: 0.3621 - val_accuracy: 0.8390\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 828us/step - loss: 0.3556 - accuracy: 0.8415 - val_loss: 0.3610 - val_accuracy: 0.8390\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3600 - accuracy: 0.8370 - val_loss: 0.3627 - val_accuracy: 0.8388\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 2s 964us/step - loss: 0.3598 - accuracy: 0.8431 - val_loss: 0.3612 - val_accuracy: 0.8388\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.3527 - accuracy: 0.8468 - val_loss: 0.3601 - val_accuracy: 0.8416\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3562 - accuracy: 0.8439 - val_loss: 0.3608 - val_accuracy: 0.8402\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 809us/step - loss: 0.3566 - accuracy: 0.8422 - val_loss: 0.3611 - val_accuracy: 0.8404\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 880us/step - loss: 0.3625 - accuracy: 0.8406 - val_loss: 0.3587 - val_accuracy: 0.8428\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3469 - accuracy: 0.8517 - val_loss: 0.3633 - val_accuracy: 0.8374\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3578 - accuracy: 0.8446 - val_loss: 0.3612 - val_accuracy: 0.8404\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3505 - accuracy: 0.8445 - val_loss: 0.3605 - val_accuracy: 0.8426\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3502 - accuracy: 0.8455 - val_loss: 0.3600 - val_accuracy: 0.8404\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3538 - accuracy: 0.8479 - val_loss: 0.3597 - val_accuracy: 0.8400\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3600 - accuracy: 0.8448 - val_loss: 0.3592 - val_accuracy: 0.8390\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3531 - accuracy: 0.8462 - val_loss: 0.3629 - val_accuracy: 0.8400\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3548 - accuracy: 0.8442 - val_loss: 0.3591 - val_accuracy: 0.8400\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3542 - accuracy: 0.8477 - val_loss: 0.3606 - val_accuracy: 0.8394\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3465 - accuracy: 0.8532 - val_loss: 0.3608 - val_accuracy: 0.8388\n",
      "400/400 [==============================] - 0s 715us/step - loss: 0.3686 - accuracy: 0.8298\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 807us/step - loss: 0.4751 - accuracy: 0.7732 - val_loss: 0.3843 - val_accuracy: 0.8160\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 792us/step - loss: 0.3921 - accuracy: 0.8210 - val_loss: 0.3762 - val_accuracy: 0.8240\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3758 - accuracy: 0.8264 - val_loss: 0.3693 - val_accuracy: 0.8292\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 857us/step - loss: 0.3658 - accuracy: 0.8352 - val_loss: 0.3652 - val_accuracy: 0.8342\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3624 - accuracy: 0.8379 - val_loss: 0.3617 - val_accuracy: 0.8372\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3570 - accuracy: 0.8399 - val_loss: 0.3605 - val_accuracy: 0.8376\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3587 - accuracy: 0.8387 - val_loss: 0.3601 - val_accuracy: 0.8384\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3671 - accuracy: 0.8367 - val_loss: 0.3589 - val_accuracy: 0.8396\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3542 - accuracy: 0.8397 - val_loss: 0.3581 - val_accuracy: 0.8386\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3597 - accuracy: 0.8392 - val_loss: 0.3660 - val_accuracy: 0.8390\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3643 - accuracy: 0.8317 - val_loss: 0.3569 - val_accuracy: 0.8424\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 863us/step - loss: 0.3539 - accuracy: 0.8415 - val_loss: 0.3548 - val_accuracy: 0.8430\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3517 - accuracy: 0.8453 - val_loss: 0.3552 - val_accuracy: 0.8446\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3495 - accuracy: 0.8447 - val_loss: 0.3659 - val_accuracy: 0.8422\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.3521 - accuracy: 0.8405 - val_loss: 0.3485 - val_accuracy: 0.8454\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 735us/step - loss: 0.3508 - accuracy: 0.8452 - val_loss: 0.3464 - val_accuracy: 0.8464\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3484 - accuracy: 0.8487 - val_loss: 0.3481 - val_accuracy: 0.8478\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 728us/step - loss: 0.3450 - accuracy: 0.8483 - val_loss: 0.3493 - val_accuracy: 0.8482\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 764us/step - loss: 0.3480 - accuracy: 0.8441 - val_loss: 0.3567 - val_accuracy: 0.8410\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3454 - accuracy: 0.8492 - val_loss: 0.3481 - val_accuracy: 0.8468\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3378 - accuracy: 0.8515 - val_loss: 0.3510 - val_accuracy: 0.8464\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 905us/step - loss: 0.3424 - accuracy: 0.8478 - val_loss: 0.3503 - val_accuracy: 0.8440\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3409 - accuracy: 0.8491 - val_loss: 0.3456 - val_accuracy: 0.8456\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 891us/step - loss: 0.3432 - accuracy: 0.8484 - val_loss: 0.3485 - val_accuracy: 0.8448\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 728us/step - loss: 0.3372 - accuracy: 0.8478 - val_loss: 0.3433 - val_accuracy: 0.8488\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3443 - accuracy: 0.8514 - val_loss: 0.3503 - val_accuracy: 0.8470\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3410 - accuracy: 0.8496 - val_loss: 0.3433 - val_accuracy: 0.8460\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3320 - accuracy: 0.8518 - val_loss: 0.3535 - val_accuracy: 0.8434\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3306 - accuracy: 0.8537 - val_loss: 0.3504 - val_accuracy: 0.8436\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3455 - accuracy: 0.8451 - val_loss: 0.3494 - val_accuracy: 0.8492\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 818us/step - loss: 0.3333 - accuracy: 0.8563 - val_loss: 0.3443 - val_accuracy: 0.8486\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3330 - accuracy: 0.8545 - val_loss: 0.3572 - val_accuracy: 0.8458\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 2s 966us/step - loss: 0.3472 - accuracy: 0.8465 - val_loss: 0.3562 - val_accuracy: 0.8502\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3328 - accuracy: 0.8546 - val_loss: 0.3507 - val_accuracy: 0.8498\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 794us/step - loss: 0.3378 - accuracy: 0.8509 - val_loss: 0.3506 - val_accuracy: 0.8476\n",
      "400/400 [==============================] - 0s 755us/step - loss: 0.3338 - accuracy: 0.8475\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 786us/step - loss: 0.4783 - accuracy: 0.7786 - val_loss: 0.3754 - val_accuracy: 0.8184\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3709 - accuracy: 0.8239 - val_loss: 0.3662 - val_accuracy: 0.8220\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3692 - accuracy: 0.8268 - val_loss: 0.3631 - val_accuracy: 0.8224\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3625 - accuracy: 0.8325 - val_loss: 0.3660 - val_accuracy: 0.8242\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 782us/step - loss: 0.3490 - accuracy: 0.8431 - val_loss: 0.3553 - val_accuracy: 0.8282\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3574 - accuracy: 0.8344 - val_loss: 0.3608 - val_accuracy: 0.8368\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 999us/step - loss: 0.3486 - accuracy: 0.8412 - val_loss: 0.3620 - val_accuracy: 0.8288\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3519 - accuracy: 0.8393 - val_loss: 0.3487 - val_accuracy: 0.8388\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 889us/step - loss: 0.3380 - accuracy: 0.8495 - val_loss: 0.3560 - val_accuracy: 0.8458\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 716us/step - loss: 0.3451 - accuracy: 0.8456 - val_loss: 0.3445 - val_accuracy: 0.8432\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 856us/step - loss: 0.3373 - accuracy: 0.8457 - val_loss: 0.3403 - val_accuracy: 0.8466\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3312 - accuracy: 0.8520 - val_loss: 0.3433 - val_accuracy: 0.8428\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3352 - accuracy: 0.8527 - val_loss: 0.3472 - val_accuracy: 0.8430\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3318 - accuracy: 0.8515 - val_loss: 0.3382 - val_accuracy: 0.8456\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3434 - accuracy: 0.8434 - val_loss: 0.3416 - val_accuracy: 0.8470\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3336 - accuracy: 0.8515 - val_loss: 0.3416 - val_accuracy: 0.8434\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3352 - accuracy: 0.8492 - val_loss: 0.3405 - val_accuracy: 0.8444\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3355 - accuracy: 0.8511 - val_loss: 0.3462 - val_accuracy: 0.8394\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3338 - accuracy: 0.8526 - val_loss: 0.3447 - val_accuracy: 0.8416\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3328 - accuracy: 0.8498 - val_loss: 0.3381 - val_accuracy: 0.8456\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3328 - accuracy: 0.8544 - val_loss: 0.3385 - val_accuracy: 0.8460\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3366 - accuracy: 0.8511 - val_loss: 0.3406 - val_accuracy: 0.8446\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3292 - accuracy: 0.8537 - val_loss: 0.3367 - val_accuracy: 0.8462\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.3351 - accuracy: 0.8494 - val_loss: 0.3367 - val_accuracy: 0.8468\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3364 - accuracy: 0.8471 - val_loss: 0.3396 - val_accuracy: 0.8482\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3324 - accuracy: 0.8505 - val_loss: 0.3383 - val_accuracy: 0.8482\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 826us/step - loss: 0.3322 - accuracy: 0.8500 - val_loss: 0.3364 - val_accuracy: 0.8494\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 826us/step - loss: 0.3312 - accuracy: 0.8532 - val_loss: 0.3379 - val_accuracy: 0.8446\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 803us/step - loss: 0.3316 - accuracy: 0.8501 - val_loss: 0.3371 - val_accuracy: 0.8490\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3287 - accuracy: 0.8538 - val_loss: 0.3360 - val_accuracy: 0.8480\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 824us/step - loss: 0.3212 - accuracy: 0.8579 - val_loss: 0.3403 - val_accuracy: 0.8448\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3303 - accuracy: 0.8519 - val_loss: 0.3386 - val_accuracy: 0.8488\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3248 - accuracy: 0.8541 - val_loss: 0.3385 - val_accuracy: 0.8482\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3275 - accuracy: 0.8556 - val_loss: 0.3385 - val_accuracy: 0.8470\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3326 - accuracy: 0.8503 - val_loss: 0.3374 - val_accuracy: 0.8480\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3371 - accuracy: 0.8506 - val_loss: 0.3387 - val_accuracy: 0.8466\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3218 - accuracy: 0.8576 - val_loss: 0.3384 - val_accuracy: 0.8478\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3313 - accuracy: 0.8503 - val_loss: 0.3585 - val_accuracy: 0.8460\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3297 - accuracy: 0.8512 - val_loss: 0.3468 - val_accuracy: 0.8458\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3264 - accuracy: 0.8537 - val_loss: 0.3426 - val_accuracy: 0.8476\n",
      "400/400 [==============================] - 0s 722us/step - loss: 0.3269 - accuracy: 0.8562\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4741 - accuracy: 0.7753 - val_loss: 0.3770 - val_accuracy: 0.8136\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3749 - accuracy: 0.8223 - val_loss: 0.3644 - val_accuracy: 0.8222\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3615 - accuracy: 0.8307 - val_loss: 0.3621 - val_accuracy: 0.8254\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3608 - accuracy: 0.8311 - val_loss: 0.3669 - val_accuracy: 0.8354\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3522 - accuracy: 0.8346 - val_loss: 0.3547 - val_accuracy: 0.8340\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3609 - accuracy: 0.8308 - val_loss: 0.3503 - val_accuracy: 0.8366\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3395 - accuracy: 0.8494 - val_loss: 0.3571 - val_accuracy: 0.8442\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3361 - accuracy: 0.8484 - val_loss: 0.3493 - val_accuracy: 0.8394\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3345 - accuracy: 0.8481 - val_loss: 0.3429 - val_accuracy: 0.8452\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3297 - accuracy: 0.8523 - val_loss: 0.3425 - val_accuracy: 0.8456\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.8527 - val_loss: 0.3403 - val_accuracy: 0.8468\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 822us/step - loss: 0.3182 - accuracy: 0.8605 - val_loss: 0.3436 - val_accuracy: 0.8424\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3265 - accuracy: 0.8561 - val_loss: 0.3409 - val_accuracy: 0.8464\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 736us/step - loss: 0.3281 - accuracy: 0.8541 - val_loss: 0.3384 - val_accuracy: 0.8472\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 735us/step - loss: 0.3272 - accuracy: 0.8550 - val_loss: 0.3442 - val_accuracy: 0.8430\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3345 - accuracy: 0.8496 - val_loss: 0.3373 - val_accuracy: 0.8502\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 768us/step - loss: 0.3273 - accuracy: 0.8568 - val_loss: 0.3384 - val_accuracy: 0.8478\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3309 - accuracy: 0.8502 - val_loss: 0.3412 - val_accuracy: 0.8460\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3272 - accuracy: 0.8512 - val_loss: 0.3421 - val_accuracy: 0.8468\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 947us/step - loss: 0.3290 - accuracy: 0.8536 - val_loss: 0.3409 - val_accuracy: 0.8486\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3278 - accuracy: 0.8577 - val_loss: 0.3375 - val_accuracy: 0.8476\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 845us/step - loss: 0.3291 - accuracy: 0.8558 - val_loss: 0.3368 - val_accuracy: 0.8476\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3284 - accuracy: 0.8526 - val_loss: 0.3387 - val_accuracy: 0.8482\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 785us/step - loss: 0.3298 - accuracy: 0.8506 - val_loss: 0.3421 - val_accuracy: 0.8472\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3260 - accuracy: 0.8557 - val_loss: 0.3404 - val_accuracy: 0.8514\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 900us/step - loss: 0.3300 - accuracy: 0.8528 - val_loss: 0.3379 - val_accuracy: 0.8468\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3275 - accuracy: 0.8551 - val_loss: 0.3441 - val_accuracy: 0.8496\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 991us/step - loss: 0.3276 - accuracy: 0.8561 - val_loss: 0.3415 - val_accuracy: 0.8450\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3316 - accuracy: 0.8548 - val_loss: 0.3394 - val_accuracy: 0.8498\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3303 - accuracy: 0.8506 - val_loss: 0.3470 - val_accuracy: 0.8450\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3343 - accuracy: 0.8500 - val_loss: 0.3380 - val_accuracy: 0.8510\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3245 - accuracy: 0.8552 - val_loss: 0.3441 - val_accuracy: 0.8456\n",
      "400/400 [==============================] - 0s 802us/step - loss: 0.3366 - accuracy: 0.8540\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 3s 1ms/step - loss: 0.4638 - accuracy: 0.7838 - val_loss: 0.3815 - val_accuracy: 0.8166\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3753 - accuracy: 0.8268 - val_loss: 0.3676 - val_accuracy: 0.8306\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3667 - accuracy: 0.8301 - val_loss: 0.3633 - val_accuracy: 0.8342\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3640 - accuracy: 0.8375 - val_loss: 0.3629 - val_accuracy: 0.8352\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 783us/step - loss: 0.3566 - accuracy: 0.8455 - val_loss: 0.3618 - val_accuracy: 0.8348\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3676 - accuracy: 0.8362 - val_loss: 0.3595 - val_accuracy: 0.8400\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3557 - accuracy: 0.8411 - val_loss: 0.3606 - val_accuracy: 0.8386\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3566 - accuracy: 0.8417 - val_loss: 0.3612 - val_accuracy: 0.8412\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3498 - accuracy: 0.8463 - val_loss: 0.3568 - val_accuracy: 0.8414\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 777us/step - loss: 0.3562 - accuracy: 0.8423 - val_loss: 0.3626 - val_accuracy: 0.8404\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 780us/step - loss: 0.3629 - accuracy: 0.8387 - val_loss: 0.3574 - val_accuracy: 0.8420\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3516 - accuracy: 0.8481 - val_loss: 0.3657 - val_accuracy: 0.8388\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 765us/step - loss: 0.3631 - accuracy: 0.8396 - val_loss: 0.3593 - val_accuracy: 0.8406\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 756us/step - loss: 0.3498 - accuracy: 0.8457 - val_loss: 0.3576 - val_accuracy: 0.8416\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 728us/step - loss: 0.3541 - accuracy: 0.8423 - val_loss: 0.3597 - val_accuracy: 0.8416\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3530 - accuracy: 0.8485 - val_loss: 0.3581 - val_accuracy: 0.8418\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3553 - accuracy: 0.8453 - val_loss: 0.3569 - val_accuracy: 0.8432\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 716us/step - loss: 0.3549 - accuracy: 0.8425 - val_loss: 0.3635 - val_accuracy: 0.8400\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 773us/step - loss: 0.3580 - accuracy: 0.8449 - val_loss: 0.3575 - val_accuracy: 0.8416\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3588 - accuracy: 0.8382\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4691 - accuracy: 0.7746 - val_loss: 0.3840 - val_accuracy: 0.8138\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 744us/step - loss: 0.3685 - accuracy: 0.8293 - val_loss: 0.3692 - val_accuracy: 0.8262\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 744us/step - loss: 0.3727 - accuracy: 0.8304 - val_loss: 0.3652 - val_accuracy: 0.8382\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 809us/step - loss: 0.3596 - accuracy: 0.8422 - val_loss: 0.3619 - val_accuracy: 0.8372\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3523 - accuracy: 0.8447 - val_loss: 0.3608 - val_accuracy: 0.8382\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3554 - accuracy: 0.8442 - val_loss: 0.3612 - val_accuracy: 0.8410\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 803us/step - loss: 0.3574 - accuracy: 0.8426 - val_loss: 0.3595 - val_accuracy: 0.8368\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3559 - accuracy: 0.8433 - val_loss: 0.3588 - val_accuracy: 0.8422\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 749us/step - loss: 0.3611 - accuracy: 0.8406 - val_loss: 0.3584 - val_accuracy: 0.8422\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3576 - accuracy: 0.8444 - val_loss: 0.3592 - val_accuracy: 0.8412\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3543 - accuracy: 0.8435 - val_loss: 0.3592 - val_accuracy: 0.8400\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3582 - accuracy: 0.8444 - val_loss: 0.3582 - val_accuracy: 0.8418\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3488 - accuracy: 0.8483 - val_loss: 0.3584 - val_accuracy: 0.8408\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 848us/step - loss: 0.3498 - accuracy: 0.8481 - val_loss: 0.3636 - val_accuracy: 0.8392\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 814us/step - loss: 0.3511 - accuracy: 0.8466 - val_loss: 0.3629 - val_accuracy: 0.8392\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 827us/step - loss: 0.3548 - accuracy: 0.8459 - val_loss: 0.3584 - val_accuracy: 0.8414\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 752us/step - loss: 0.3484 - accuracy: 0.8479 - val_loss: 0.3585 - val_accuracy: 0.8396\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3488 - accuracy: 0.8494 - val_loss: 0.3638 - val_accuracy: 0.8406\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3477 - accuracy: 0.8456 - val_loss: 0.3696 - val_accuracy: 0.8404\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3478 - accuracy: 0.8502 - val_loss: 0.3570 - val_accuracy: 0.8386\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 957us/step - loss: 0.3498 - accuracy: 0.8455 - val_loss: 0.3633 - val_accuracy: 0.8380\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 749us/step - loss: 0.3450 - accuracy: 0.8503 - val_loss: 0.3665 - val_accuracy: 0.8404\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3495 - accuracy: 0.8518 - val_loss: 0.3583 - val_accuracy: 0.8386\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3473 - accuracy: 0.8514 - val_loss: 0.3597 - val_accuracy: 0.8380\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.3501 - accuracy: 0.8520 - val_loss: 0.3691 - val_accuracy: 0.8388\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 798us/step - loss: 0.3506 - accuracy: 0.8494 - val_loss: 0.3616 - val_accuracy: 0.8438\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3511 - accuracy: 0.8471 - val_loss: 0.3702 - val_accuracy: 0.8402\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3453 - accuracy: 0.8517 - val_loss: 0.3611 - val_accuracy: 0.8422\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 728us/step - loss: 0.3434 - accuracy: 0.8553 - val_loss: 0.3617 - val_accuracy: 0.8400\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3515 - accuracy: 0.8501 - val_loss: 0.3669 - val_accuracy: 0.8404\n",
      "400/400 [==============================] - 0s 795us/step - loss: 0.3677 - accuracy: 0.8250\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 812us/step - loss: 0.4565 - accuracy: 0.7849 - val_loss: 0.3710 - val_accuracy: 0.8202\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3686 - accuracy: 0.8270 - val_loss: 0.3658 - val_accuracy: 0.8274\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 819us/step - loss: 0.3566 - accuracy: 0.8345 - val_loss: 0.3589 - val_accuracy: 0.8346\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3509 - accuracy: 0.8371 - val_loss: 0.3567 - val_accuracy: 0.8376\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 916us/step - loss: 0.3555 - accuracy: 0.8382 - val_loss: 0.3539 - val_accuracy: 0.8384\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3484 - accuracy: 0.8430 - val_loss: 0.3508 - val_accuracy: 0.8406\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3501 - accuracy: 0.8407 - val_loss: 0.3557 - val_accuracy: 0.8434\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3521 - accuracy: 0.8455 - val_loss: 0.3508 - val_accuracy: 0.8452\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 810us/step - loss: 0.3457 - accuracy: 0.8439 - val_loss: 0.3459 - val_accuracy: 0.8464\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 904us/step - loss: 0.3427 - accuracy: 0.8498 - val_loss: 0.3493 - val_accuracy: 0.8456\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3400 - accuracy: 0.8500 - val_loss: 0.3406 - val_accuracy: 0.8468\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3419 - accuracy: 0.8473 - val_loss: 0.3395 - val_accuracy: 0.8470\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3339 - accuracy: 0.8515 - val_loss: 0.3468 - val_accuracy: 0.8452\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3330 - accuracy: 0.8547 - val_loss: 0.3411 - val_accuracy: 0.8474\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 789us/step - loss: 0.3301 - accuracy: 0.8517 - val_loss: 0.3381 - val_accuracy: 0.8468\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3382 - accuracy: 0.8480 - val_loss: 0.3427 - val_accuracy: 0.8482\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.3299 - accuracy: 0.8524 - val_loss: 0.3391 - val_accuracy: 0.8494\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3378 - accuracy: 0.8514 - val_loss: 0.3393 - val_accuracy: 0.8486\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 787us/step - loss: 0.3315 - accuracy: 0.8503 - val_loss: 0.3384 - val_accuracy: 0.8482\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 769us/step - loss: 0.3308 - accuracy: 0.8540 - val_loss: 0.3506 - val_accuracy: 0.8494\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3356 - accuracy: 0.8522 - val_loss: 0.3448 - val_accuracy: 0.8468\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 967us/step - loss: 0.3411 - accuracy: 0.8457 - val_loss: 0.3494 - val_accuracy: 0.8496\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3341 - accuracy: 0.8545 - val_loss: 0.3445 - val_accuracy: 0.8474\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 777us/step - loss: 0.3381 - accuracy: 0.8511 - val_loss: 0.3436 - val_accuracy: 0.8484\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3321 - accuracy: 0.8582 - val_loss: 0.3494 - val_accuracy: 0.8390\n",
      "400/400 [==============================] - 0s 717us/step - loss: 0.3284 - accuracy: 0.8525\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 801us/step - loss: 0.4583 - accuracy: 0.7890 - val_loss: 0.3826 - val_accuracy: 0.8236\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3693 - accuracy: 0.8266 - val_loss: 0.3662 - val_accuracy: 0.8292\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 821us/step - loss: 0.3652 - accuracy: 0.8309 - val_loss: 0.3578 - val_accuracy: 0.8380\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3609 - accuracy: 0.8355 - val_loss: 0.3544 - val_accuracy: 0.8334\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 960us/step - loss: 0.3524 - accuracy: 0.8388 - val_loss: 0.3518 - val_accuracy: 0.8378\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3485 - accuracy: 0.8420 - val_loss: 0.3485 - val_accuracy: 0.8432\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 865us/step - loss: 0.3482 - accuracy: 0.8429 - val_loss: 0.3464 - val_accuracy: 0.8440\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3464 - accuracy: 0.8466 - val_loss: 0.3437 - val_accuracy: 0.8444\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 842us/step - loss: 0.3431 - accuracy: 0.8462 - val_loss: 0.3437 - val_accuracy: 0.8446\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 751us/step - loss: 0.3323 - accuracy: 0.8537 - val_loss: 0.3505 - val_accuracy: 0.8484\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3360 - accuracy: 0.8541 - val_loss: 0.3443 - val_accuracy: 0.8482\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 749us/step - loss: 0.3394 - accuracy: 0.8490 - val_loss: 0.3403 - val_accuracy: 0.8482\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3362 - accuracy: 0.8507 - val_loss: 0.3401 - val_accuracy: 0.8480\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 776us/step - loss: 0.3380 - accuracy: 0.8491 - val_loss: 0.3441 - val_accuracy: 0.8518\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 823us/step - loss: 0.3436 - accuracy: 0.8454 - val_loss: 0.3381 - val_accuracy: 0.8494\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3426 - accuracy: 0.8457 - val_loss: 0.3423 - val_accuracy: 0.8512\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3314 - accuracy: 0.8521 - val_loss: 0.3383 - val_accuracy: 0.8516\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 2s 992us/step - loss: 0.3339 - accuracy: 0.8519 - val_loss: 0.3376 - val_accuracy: 0.8502\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.8544 - val_loss: 0.3534 - val_accuracy: 0.8414\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 769us/step - loss: 0.3288 - accuracy: 0.8531 - val_loss: 0.3435 - val_accuracy: 0.8466\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3427 - accuracy: 0.8464 - val_loss: 0.3409 - val_accuracy: 0.8490\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3433 - accuracy: 0.8447 - val_loss: 0.3412 - val_accuracy: 0.8484\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3336 - accuracy: 0.8516 - val_loss: 0.3435 - val_accuracy: 0.8490\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 735us/step - loss: 0.3340 - accuracy: 0.8499 - val_loss: 0.3560 - val_accuracy: 0.8474\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 759us/step - loss: 0.3439 - accuracy: 0.8483 - val_loss: 0.3472 - val_accuracy: 0.8500\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3338 - accuracy: 0.8507 - val_loss: 0.3413 - val_accuracy: 0.8514\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3375 - accuracy: 0.8492 - val_loss: 0.3418 - val_accuracy: 0.8498\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3367 - accuracy: 0.8529 - val_loss: 0.3438 - val_accuracy: 0.8488\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3306 - accuracy: 0.8533\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 854us/step - loss: 0.4562 - accuracy: 0.7879 - val_loss: 0.3711 - val_accuracy: 0.8158\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3705 - accuracy: 0.8238 - val_loss: 0.3643 - val_accuracy: 0.8280\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3607 - accuracy: 0.8368 - val_loss: 0.3562 - val_accuracy: 0.8398\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3471 - accuracy: 0.8450 - val_loss: 0.3565 - val_accuracy: 0.8430\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3520 - accuracy: 0.8477 - val_loss: 0.3516 - val_accuracy: 0.8430\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 744us/step - loss: 0.3411 - accuracy: 0.8486 - val_loss: 0.3458 - val_accuracy: 0.8438\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3354 - accuracy: 0.8472 - val_loss: 0.3472 - val_accuracy: 0.8444\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3457 - accuracy: 0.8429 - val_loss: 0.3466 - val_accuracy: 0.8468\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3460 - accuracy: 0.8462 - val_loss: 0.3504 - val_accuracy: 0.8462\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3451 - accuracy: 0.8467 - val_loss: 0.3525 - val_accuracy: 0.8460\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 851us/step - loss: 0.3347 - accuracy: 0.8505 - val_loss: 0.3486 - val_accuracy: 0.8446\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3354 - accuracy: 0.8511 - val_loss: 0.3503 - val_accuracy: 0.8450\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 870us/step - loss: 0.3320 - accuracy: 0.8483 - val_loss: 0.3449 - val_accuracy: 0.8462\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3403 - accuracy: 0.8485 - val_loss: 0.3483 - val_accuracy: 0.8466\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3351 - accuracy: 0.8569 - val_loss: 0.3495 - val_accuracy: 0.8480\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 772us/step - loss: 0.3379 - accuracy: 0.8495 - val_loss: 0.3485 - val_accuracy: 0.8446\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3365 - accuracy: 0.8515 - val_loss: 0.3633 - val_accuracy: 0.8394\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 763us/step - loss: 0.3360 - accuracy: 0.8522 - val_loss: 0.3598 - val_accuracy: 0.8502\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3392 - accuracy: 0.8513 - val_loss: 0.3459 - val_accuracy: 0.8460\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3331 - accuracy: 0.8526 - val_loss: 0.3470 - val_accuracy: 0.8478\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 777us/step - loss: 0.3365 - accuracy: 0.8521 - val_loss: 0.3477 - val_accuracy: 0.8438\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3308 - accuracy: 0.8568 - val_loss: 0.3490 - val_accuracy: 0.8482\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 787us/step - loss: 0.3227 - accuracy: 0.8584 - val_loss: 0.3518 - val_accuracy: 0.8448\n",
      "400/400 [==============================] - 0s 790us/step - loss: 0.3456 - accuracy: 0.8475\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 803us/step - loss: 0.4522 - accuracy: 0.7845 - val_loss: 0.3828 - val_accuracy: 0.8116\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 929us/step - loss: 0.3691 - accuracy: 0.8277 - val_loss: 0.3662 - val_accuracy: 0.8348\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3649 - accuracy: 0.8284 - val_loss: 0.3608 - val_accuracy: 0.8356\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 815us/step - loss: 0.3596 - accuracy: 0.8363 - val_loss: 0.3575 - val_accuracy: 0.8390\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3572 - accuracy: 0.8392 - val_loss: 0.3580 - val_accuracy: 0.8386\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3564 - accuracy: 0.8441 - val_loss: 0.3598 - val_accuracy: 0.8386\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3519 - accuracy: 0.8452 - val_loss: 0.3547 - val_accuracy: 0.8426\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3524 - accuracy: 0.8441 - val_loss: 0.3496 - val_accuracy: 0.8460\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3427 - accuracy: 0.8500 - val_loss: 0.3551 - val_accuracy: 0.8422\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3448 - accuracy: 0.8483 - val_loss: 0.3511 - val_accuracy: 0.8424\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 780us/step - loss: 0.3352 - accuracy: 0.8503 - val_loss: 0.3515 - val_accuracy: 0.8442\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3410 - accuracy: 0.8470 - val_loss: 0.3488 - val_accuracy: 0.8448\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3309 - accuracy: 0.8577 - val_loss: 0.3448 - val_accuracy: 0.8458\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3453 - accuracy: 0.8473 - val_loss: 0.3442 - val_accuracy: 0.8432\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3370 - accuracy: 0.8470 - val_loss: 0.3444 - val_accuracy: 0.8450\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3382 - accuracy: 0.8523 - val_loss: 0.3534 - val_accuracy: 0.8444\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3406 - accuracy: 0.8487 - val_loss: 0.3455 - val_accuracy: 0.8480\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3441 - accuracy: 0.8516 - val_loss: 0.3462 - val_accuracy: 0.8470\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3379 - accuracy: 0.8537 - val_loss: 0.3472 - val_accuracy: 0.8488\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3425 - accuracy: 0.8492 - val_loss: 0.3457 - val_accuracy: 0.8466\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3442 - accuracy: 0.8474 - val_loss: 0.3494 - val_accuracy: 0.8468\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3323 - accuracy: 0.8530 - val_loss: 0.3450 - val_accuracy: 0.8454\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 788us/step - loss: 0.3388 - accuracy: 0.8532 - val_loss: 0.3443 - val_accuracy: 0.8460\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 826us/step - loss: 0.3359 - accuracy: 0.8514 - val_loss: 0.3490 - val_accuracy: 0.8462\n",
      "400/400 [==============================] - 0s 978us/step - loss: 0.3433 - accuracy: 0.8455\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 774us/step - loss: 0.4540 - accuracy: 0.7906 - val_loss: 0.3772 - val_accuracy: 0.8274\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3720 - accuracy: 0.8278 - val_loss: 0.3663 - val_accuracy: 0.8322\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3680 - accuracy: 0.8339 - val_loss: 0.3600 - val_accuracy: 0.8384\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3563 - accuracy: 0.8403 - val_loss: 0.3557 - val_accuracy: 0.8406\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3561 - accuracy: 0.8406 - val_loss: 0.3556 - val_accuracy: 0.8414\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3481 - accuracy: 0.8467 - val_loss: 0.3526 - val_accuracy: 0.8400\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 797us/step - loss: 0.3497 - accuracy: 0.8442 - val_loss: 0.3481 - val_accuracy: 0.8456\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3463 - accuracy: 0.8482 - val_loss: 0.3478 - val_accuracy: 0.8432\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 2s 986us/step - loss: 0.3359 - accuracy: 0.8531 - val_loss: 0.3464 - val_accuracy: 0.8462\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3365 - accuracy: 0.8501 - val_loss: 0.3445 - val_accuracy: 0.8470\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3393 - accuracy: 0.8522 - val_loss: 0.3531 - val_accuracy: 0.8388\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3385 - accuracy: 0.8497 - val_loss: 0.3453 - val_accuracy: 0.8480\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 716us/step - loss: 0.3304 - accuracy: 0.8575 - val_loss: 0.3400 - val_accuracy: 0.8486\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3297 - accuracy: 0.8540 - val_loss: 0.3420 - val_accuracy: 0.8428\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 877us/step - loss: 0.3243 - accuracy: 0.8580 - val_loss: 0.3505 - val_accuracy: 0.8382\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3337 - accuracy: 0.8551 - val_loss: 0.3429 - val_accuracy: 0.8476\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 896us/step - loss: 0.3365 - accuracy: 0.8553 - val_loss: 0.3429 - val_accuracy: 0.8448\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 767us/step - loss: 0.3335 - accuracy: 0.8555 - val_loss: 0.3470 - val_accuracy: 0.8458\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3318 - accuracy: 0.8557 - val_loss: 0.3456 - val_accuracy: 0.8492\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 752us/step - loss: 0.3330 - accuracy: 0.8552 - val_loss: 0.3435 - val_accuracy: 0.8470\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3247 - accuracy: 0.8609 - val_loss: 0.3441 - val_accuracy: 0.8454\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3296 - accuracy: 0.8552 - val_loss: 0.3406 - val_accuracy: 0.8462\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3342 - accuracy: 0.8533 - val_loss: 0.3384 - val_accuracy: 0.8464\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 792us/step - loss: 0.3330 - accuracy: 0.8543 - val_loss: 0.3437 - val_accuracy: 0.8434\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3233 - accuracy: 0.8639 - val_loss: 0.3666 - val_accuracy: 0.8392\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3261 - accuracy: 0.8585 - val_loss: 0.3466 - val_accuracy: 0.8428\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3250 - accuracy: 0.8575 - val_loss: 0.3598 - val_accuracy: 0.8468\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3333 - accuracy: 0.8560 - val_loss: 0.3462 - val_accuracy: 0.8428\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 803us/step - loss: 0.3256 - accuracy: 0.8655 - val_loss: 0.3614 - val_accuracy: 0.8382\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 785us/step - loss: 0.3214 - accuracy: 0.8620 - val_loss: 0.3448 - val_accuracy: 0.8452\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 766us/step - loss: 0.3271 - accuracy: 0.8588 - val_loss: 0.3447 - val_accuracy: 0.8468\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3268 - accuracy: 0.8609 - val_loss: 0.3418 - val_accuracy: 0.8468\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3184 - accuracy: 0.8623 - val_loss: 0.3434 - val_accuracy: 0.8482\n",
      "400/400 [==============================] - 0s 700us/step - loss: 0.3396 - accuracy: 0.8470\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 845us/step - loss: 0.4417 - accuracy: 0.7918 - val_loss: 0.3702 - val_accuracy: 0.8236\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 761us/step - loss: 0.3640 - accuracy: 0.8310 - val_loss: 0.3607 - val_accuracy: 0.8322\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3605 - accuracy: 0.8337 - val_loss: 0.3581 - val_accuracy: 0.8390\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3561 - accuracy: 0.8399 - val_loss: 0.3566 - val_accuracy: 0.8356\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3549 - accuracy: 0.8412 - val_loss: 0.3513 - val_accuracy: 0.8416\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 833us/step - loss: 0.3540 - accuracy: 0.8371 - val_loss: 0.3495 - val_accuracy: 0.8440\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3507 - accuracy: 0.8415 - val_loss: 0.3484 - val_accuracy: 0.8458\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 752us/step - loss: 0.3443 - accuracy: 0.8454 - val_loss: 0.3480 - val_accuracy: 0.8422\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 756us/step - loss: 0.3424 - accuracy: 0.8490 - val_loss: 0.3421 - val_accuracy: 0.8454\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 768us/step - loss: 0.3397 - accuracy: 0.8529 - val_loss: 0.3375 - val_accuracy: 0.8448\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3340 - accuracy: 0.8479 - val_loss: 0.3381 - val_accuracy: 0.8476\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 773us/step - loss: 0.3296 - accuracy: 0.8554 - val_loss: 0.3476 - val_accuracy: 0.8480\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 765us/step - loss: 0.3396 - accuracy: 0.8501 - val_loss: 0.3375 - val_accuracy: 0.8490\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 968us/step - loss: 0.3349 - accuracy: 0.8551 - val_loss: 0.3421 - val_accuracy: 0.8492\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3362 - accuracy: 0.8533 - val_loss: 0.3493 - val_accuracy: 0.8480\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 805us/step - loss: 0.3320 - accuracy: 0.8561 - val_loss: 0.3425 - val_accuracy: 0.8478\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 932us/step - loss: 0.3379 - accuracy: 0.8490 - val_loss: 0.3620 - val_accuracy: 0.8506\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 876us/step - loss: 0.3280 - accuracy: 0.8598 - val_loss: 0.3466 - val_accuracy: 0.8498\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.3171 - accuracy: 0.8622 - val_loss: 0.3378 - val_accuracy: 0.8506\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3334 - accuracy: 0.8569 - val_loss: 0.3364 - val_accuracy: 0.8490\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3230 - accuracy: 0.8598 - val_loss: 0.3491 - val_accuracy: 0.8466\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3235 - accuracy: 0.8588 - val_loss: 0.3421 - val_accuracy: 0.8474\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 759us/step - loss: 0.3284 - accuracy: 0.8552 - val_loss: 0.3581 - val_accuracy: 0.8404\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 903us/step - loss: 0.3331 - accuracy: 0.8575 - val_loss: 0.3446 - val_accuracy: 0.8466\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3337 - accuracy: 0.8564 - val_loss: 0.3435 - val_accuracy: 0.8494\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 723us/step - loss: 0.3316 - accuracy: 0.8569 - val_loss: 0.3505 - val_accuracy: 0.8504\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3304 - accuracy: 0.8582 - val_loss: 0.3482 - val_accuracy: 0.8504\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3236 - accuracy: 0.8605 - val_loss: 0.3591 - val_accuracy: 0.8478\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 802us/step - loss: 0.3397 - accuracy: 0.8538 - val_loss: 0.3467 - val_accuracy: 0.8516\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3267 - accuracy: 0.8597 - val_loss: 0.3411 - val_accuracy: 0.8470\n",
      "400/400 [==============================] - 0s 692us/step - loss: 0.3268 - accuracy: 0.8533\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4402 - accuracy: 0.7940 - val_loss: 0.3752 - val_accuracy: 0.8182\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3721 - accuracy: 0.8247 - val_loss: 0.3667 - val_accuracy: 0.8332\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 904us/step - loss: 0.3658 - accuracy: 0.8342 - val_loss: 0.3555 - val_accuracy: 0.8380\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3611 - accuracy: 0.8345 - val_loss: 0.3589 - val_accuracy: 0.8390\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3532 - accuracy: 0.8411 - val_loss: 0.3637 - val_accuracy: 0.8340\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 713us/step - loss: 0.3519 - accuracy: 0.8404 - val_loss: 0.3516 - val_accuracy: 0.8450\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 891us/step - loss: 0.3477 - accuracy: 0.8483 - val_loss: 0.3488 - val_accuracy: 0.8462\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3509 - accuracy: 0.8441 - val_loss: 0.3485 - val_accuracy: 0.8458\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 923us/step - loss: 0.3461 - accuracy: 0.8414 - val_loss: 0.3510 - val_accuracy: 0.8446\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3386 - accuracy: 0.8493 - val_loss: 0.3429 - val_accuracy: 0.8476\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3525 - accuracy: 0.8434 - val_loss: 0.3468 - val_accuracy: 0.8452\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3426 - accuracy: 0.8525 - val_loss: 0.3426 - val_accuracy: 0.8486\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 771us/step - loss: 0.3360 - accuracy: 0.8500 - val_loss: 0.3422 - val_accuracy: 0.8478\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3419 - accuracy: 0.8492 - val_loss: 0.3536 - val_accuracy: 0.8434\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3437 - accuracy: 0.8474 - val_loss: 0.3428 - val_accuracy: 0.8492\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3324 - accuracy: 0.8539 - val_loss: 0.3417 - val_accuracy: 0.8494\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 781us/step - loss: 0.3414 - accuracy: 0.8481 - val_loss: 0.3470 - val_accuracy: 0.8488\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3383 - accuracy: 0.8506 - val_loss: 0.3444 - val_accuracy: 0.8488\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3299 - accuracy: 0.8552 - val_loss: 0.3410 - val_accuracy: 0.8500\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3256 - accuracy: 0.8590 - val_loss: 0.3452 - val_accuracy: 0.8456\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3300 - accuracy: 0.8545 - val_loss: 0.3470 - val_accuracy: 0.8474\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3388 - accuracy: 0.8510 - val_loss: 0.3404 - val_accuracy: 0.8510\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3267 - accuracy: 0.8565 - val_loss: 0.3436 - val_accuracy: 0.8484\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3338 - accuracy: 0.8575 - val_loss: 0.3400 - val_accuracy: 0.8490\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 827us/step - loss: 0.3289 - accuracy: 0.8609 - val_loss: 0.3530 - val_accuracy: 0.8448\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3261 - accuracy: 0.8547 - val_loss: 0.3486 - val_accuracy: 0.8480\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 795us/step - loss: 0.3382 - accuracy: 0.8531 - val_loss: 0.3500 - val_accuracy: 0.8516\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3276 - accuracy: 0.8578 - val_loss: 0.3554 - val_accuracy: 0.8472\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 932us/step - loss: 0.3299 - accuracy: 0.8568 - val_loss: 0.3651 - val_accuracy: 0.8374\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 775us/step - loss: 0.3253 - accuracy: 0.8576 - val_loss: 0.3540 - val_accuracy: 0.8432\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3322 - accuracy: 0.8563 - val_loss: 0.3386 - val_accuracy: 0.8498\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 817us/step - loss: 0.3282 - accuracy: 0.8583 - val_loss: 0.3441 - val_accuracy: 0.8492\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3203 - accuracy: 0.8644 - val_loss: 0.3447 - val_accuracy: 0.8524\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3342 - accuracy: 0.8522 - val_loss: 0.3476 - val_accuracy: 0.8488\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3301 - accuracy: 0.8593 - val_loss: 0.3418 - val_accuracy: 0.8504\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 2s 991us/step - loss: 0.3398 - accuracy: 0.8549 - val_loss: 0.3661 - val_accuracy: 0.8494\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3301 - accuracy: 0.8572 - val_loss: 0.3619 - val_accuracy: 0.8486\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 853us/step - loss: 0.3260 - accuracy: 0.8615 - val_loss: 0.3401 - val_accuracy: 0.8494\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3322 - accuracy: 0.8543 - val_loss: 0.3548 - val_accuracy: 0.8478\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3293 - accuracy: 0.8553 - val_loss: 0.3450 - val_accuracy: 0.8510\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3353 - accuracy: 0.8577 - val_loss: 0.3438 - val_accuracy: 0.8492\n",
      "400/400 [==============================] - 0s 775us/step - loss: 0.3334 - accuracy: 0.8593\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 919us/step - loss: 0.4391 - accuracy: 0.7981 - val_loss: 0.3711 - val_accuracy: 0.8248\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3601 - accuracy: 0.8306 - val_loss: 0.3592 - val_accuracy: 0.8290\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3647 - accuracy: 0.8324 - val_loss: 0.3529 - val_accuracy: 0.8366\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3487 - accuracy: 0.8453 - val_loss: 0.3479 - val_accuracy: 0.8444\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3453 - accuracy: 0.8491 - val_loss: 0.3477 - val_accuracy: 0.8442\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3351 - accuracy: 0.8521 - val_loss: 0.3446 - val_accuracy: 0.8442\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3395 - accuracy: 0.8472 - val_loss: 0.3462 - val_accuracy: 0.8438\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3373 - accuracy: 0.8542 - val_loss: 0.3531 - val_accuracy: 0.8440\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 2s 954us/step - loss: 0.3297 - accuracy: 0.8562 - val_loss: 0.3437 - val_accuracy: 0.8484\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3367 - accuracy: 0.8484 - val_loss: 0.3476 - val_accuracy: 0.8456\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3372 - accuracy: 0.8513 - val_loss: 0.3542 - val_accuracy: 0.8432\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 777us/step - loss: 0.3384 - accuracy: 0.8472 - val_loss: 0.3425 - val_accuracy: 0.8480\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 772us/step - loss: 0.3299 - accuracy: 0.8561 - val_loss: 0.3407 - val_accuracy: 0.8492\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3408 - accuracy: 0.8507 - val_loss: 0.3484 - val_accuracy: 0.8396\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 790us/step - loss: 0.3377 - accuracy: 0.8518 - val_loss: 0.3403 - val_accuracy: 0.8492\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3361 - accuracy: 0.8505 - val_loss: 0.3440 - val_accuracy: 0.8490\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3295 - accuracy: 0.8531 - val_loss: 0.3518 - val_accuracy: 0.8416\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3265 - accuracy: 0.8552 - val_loss: 0.3434 - val_accuracy: 0.8474\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3341 - accuracy: 0.8531 - val_loss: 0.3404 - val_accuracy: 0.8472\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3348 - accuracy: 0.8507 - val_loss: 0.3419 - val_accuracy: 0.8498\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 786us/step - loss: 0.3250 - accuracy: 0.8564 - val_loss: 0.3479 - val_accuracy: 0.8490\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3223 - accuracy: 0.8568 - val_loss: 0.3406 - val_accuracy: 0.8516\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3269 - accuracy: 0.8567 - val_loss: 0.3420 - val_accuracy: 0.8456\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 899us/step - loss: 0.3228 - accuracy: 0.8572 - val_loss: 0.3391 - val_accuracy: 0.8488\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3273 - accuracy: 0.8552 - val_loss: 0.3601 - val_accuracy: 0.8472\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 843us/step - loss: 0.3290 - accuracy: 0.8570 - val_loss: 0.3409 - val_accuracy: 0.8490\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3304 - accuracy: 0.8539 - val_loss: 0.3511 - val_accuracy: 0.8456\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 782us/step - loss: 0.3260 - accuracy: 0.8602 - val_loss: 0.3432 - val_accuracy: 0.8490\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3300 - accuracy: 0.8520 - val_loss: 0.3419 - val_accuracy: 0.8490\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3262 - accuracy: 0.8557 - val_loss: 0.3411 - val_accuracy: 0.8494\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3357 - accuracy: 0.8528 - val_loss: 0.3423 - val_accuracy: 0.8450\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3286 - accuracy: 0.8556 - val_loss: 0.3385 - val_accuracy: 0.8480\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3252 - accuracy: 0.8611 - val_loss: 0.3426 - val_accuracy: 0.8464\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3218 - accuracy: 0.8599 - val_loss: 0.3440 - val_accuracy: 0.8468\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3294 - accuracy: 0.8552 - val_loss: 0.3464 - val_accuracy: 0.8468\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3245 - accuracy: 0.8593 - val_loss: 0.3451 - val_accuracy: 0.8460\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3234 - accuracy: 0.8606 - val_loss: 0.3581 - val_accuracy: 0.8428\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3255 - accuracy: 0.8614 - val_loss: 0.3446 - val_accuracy: 0.8458\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3270 - accuracy: 0.8595 - val_loss: 0.3506 - val_accuracy: 0.8458\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3225 - accuracy: 0.8605 - val_loss: 0.3430 - val_accuracy: 0.8454\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3203 - accuracy: 0.8594 - val_loss: 0.3397 - val_accuracy: 0.8484\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3293 - accuracy: 0.8598 - val_loss: 0.3415 - val_accuracy: 0.8446\n",
      "400/400 [==============================] - 0s 730us/step - loss: 0.3381 - accuracy: 0.8547\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 806us/step - loss: 0.4393 - accuracy: 0.7929 - val_loss: 0.3704 - val_accuracy: 0.8228\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3653 - accuracy: 0.8269 - val_loss: 0.3636 - val_accuracy: 0.8330\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3606 - accuracy: 0.8310 - val_loss: 0.3604 - val_accuracy: 0.8268\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3489 - accuracy: 0.8456 - val_loss: 0.3509 - val_accuracy: 0.8420\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3502 - accuracy: 0.8413 - val_loss: 0.3513 - val_accuracy: 0.8430\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3434 - accuracy: 0.8445 - val_loss: 0.3425 - val_accuracy: 0.8488\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 848us/step - loss: 0.3471 - accuracy: 0.8452 - val_loss: 0.3540 - val_accuracy: 0.8426\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3263 - accuracy: 0.8544 - val_loss: 0.3394 - val_accuracy: 0.8482\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 2s 983us/step - loss: 0.3391 - accuracy: 0.8495 - val_loss: 0.3423 - val_accuracy: 0.8492\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3313 - accuracy: 0.8478 - val_loss: 0.3479 - val_accuracy: 0.8400\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3345 - accuracy: 0.8490 - val_loss: 0.3395 - val_accuracy: 0.8442\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3313 - accuracy: 0.8555 - val_loss: 0.3383 - val_accuracy: 0.8498\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 820us/step - loss: 0.3294 - accuracy: 0.8516 - val_loss: 0.3562 - val_accuracy: 0.8500\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 771us/step - loss: 0.3310 - accuracy: 0.8567 - val_loss: 0.3475 - val_accuracy: 0.8474\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3266 - accuracy: 0.8560 - val_loss: 0.3413 - val_accuracy: 0.8500\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 735us/step - loss: 0.3282 - accuracy: 0.8565 - val_loss: 0.3385 - val_accuracy: 0.8508\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 808us/step - loss: 0.3258 - accuracy: 0.8565 - val_loss: 0.3417 - val_accuracy: 0.8464\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3317 - accuracy: 0.8520 - val_loss: 0.3380 - val_accuracy: 0.8506\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 931us/step - loss: 0.3327 - accuracy: 0.8556 - val_loss: 0.3464 - val_accuracy: 0.8494\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3261 - accuracy: 0.8534 - val_loss: 0.3436 - val_accuracy: 0.8494\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 716us/step - loss: 0.3371 - accuracy: 0.8514 - val_loss: 0.3486 - val_accuracy: 0.8476\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3220 - accuracy: 0.8631 - val_loss: 0.3425 - val_accuracy: 0.8468\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3300 - accuracy: 0.8551 - val_loss: 0.3400 - val_accuracy: 0.8486\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 889us/step - loss: 0.3288 - accuracy: 0.8552 - val_loss: 0.3671 - val_accuracy: 0.8376\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3194 - accuracy: 0.8567 - val_loss: 0.3383 - val_accuracy: 0.8466\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3260 - accuracy: 0.8571 - val_loss: 0.3431 - val_accuracy: 0.8514\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.3246 - accuracy: 0.8572 - val_loss: 0.3551 - val_accuracy: 0.8448\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 774us/step - loss: 0.3230 - accuracy: 0.8596 - val_loss: 0.3445 - val_accuracy: 0.8496\n",
      "400/400 [==============================] - 0s 702us/step - loss: 0.3332 - accuracy: 0.8512\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 916us/step - loss: 0.4490 - accuracy: 0.7862 - val_loss: 0.3743 - val_accuracy: 0.8232\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3654 - accuracy: 0.8351 - val_loss: 0.3629 - val_accuracy: 0.8342\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3662 - accuracy: 0.8386 - val_loss: 0.3634 - val_accuracy: 0.8362\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3556 - accuracy: 0.8441 - val_loss: 0.3606 - val_accuracy: 0.8382\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3530 - accuracy: 0.8414 - val_loss: 0.3592 - val_accuracy: 0.8378\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 937us/step - loss: 0.3538 - accuracy: 0.8437 - val_loss: 0.3564 - val_accuracy: 0.8414\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3532 - accuracy: 0.8427 - val_loss: 0.3592 - val_accuracy: 0.8420\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 826us/step - loss: 0.3496 - accuracy: 0.8490 - val_loss: 0.3549 - val_accuracy: 0.8400\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3448 - accuracy: 0.8513 - val_loss: 0.3495 - val_accuracy: 0.8424\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3402 - accuracy: 0.8537 - val_loss: 0.3498 - val_accuracy: 0.8430\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3437 - accuracy: 0.8529 - val_loss: 0.3474 - val_accuracy: 0.8446\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3394 - accuracy: 0.8548 - val_loss: 0.3500 - val_accuracy: 0.8454\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3303 - accuracy: 0.8604 - val_loss: 0.3500 - val_accuracy: 0.8428\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3356 - accuracy: 0.8558 - val_loss: 0.3517 - val_accuracy: 0.8456\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3319 - accuracy: 0.8552 - val_loss: 0.3524 - val_accuracy: 0.8488\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3323 - accuracy: 0.8570 - val_loss: 0.3497 - val_accuracy: 0.8454\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3370 - accuracy: 0.8551 - val_loss: 0.3451 - val_accuracy: 0.8470\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3287 - accuracy: 0.8584 - val_loss: 0.3453 - val_accuracy: 0.8464\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3306 - accuracy: 0.8592 - val_loss: 0.3411 - val_accuracy: 0.8486\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 735us/step - loss: 0.3340 - accuracy: 0.8536 - val_loss: 0.3500 - val_accuracy: 0.8440\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 746us/step - loss: 0.3286 - accuracy: 0.8599 - val_loss: 0.3435 - val_accuracy: 0.8482\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3340 - accuracy: 0.8564 - val_loss: 0.3545 - val_accuracy: 0.8478\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 769us/step - loss: 0.3402 - accuracy: 0.8573 - val_loss: 0.3557 - val_accuracy: 0.8416\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 866us/step - loss: 0.3336 - accuracy: 0.8588 - val_loss: 0.3477 - val_accuracy: 0.8454\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3315 - accuracy: 0.8622 - val_loss: 0.3455 - val_accuracy: 0.8462\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 873us/step - loss: 0.3354 - accuracy: 0.8582 - val_loss: 0.3610 - val_accuracy: 0.8420\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3272 - accuracy: 0.8617 - val_loss: 0.3520 - val_accuracy: 0.8422\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3306 - accuracy: 0.8594 - val_loss: 0.3475 - val_accuracy: 0.8428\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3330 - accuracy: 0.8596 - val_loss: 0.3541 - val_accuracy: 0.8460\n",
      "400/400 [==============================] - 0s 707us/step - loss: 0.3521 - accuracy: 0.8380\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 846us/step - loss: 0.4838 - accuracy: 0.7668 - val_loss: 0.3840 - val_accuracy: 0.8126\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3811 - accuracy: 0.8236 - val_loss: 0.3716 - val_accuracy: 0.8262\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3665 - accuracy: 0.8326 - val_loss: 0.3703 - val_accuracy: 0.8310\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3586 - accuracy: 0.8394 - val_loss: 0.3627 - val_accuracy: 0.8364\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 746us/step - loss: 0.3711 - accuracy: 0.8344 - val_loss: 0.3663 - val_accuracy: 0.8374\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 850us/step - loss: 0.3621 - accuracy: 0.8379 - val_loss: 0.3642 - val_accuracy: 0.8368\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3659 - accuracy: 0.8356 - val_loss: 0.3678 - val_accuracy: 0.8404\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 937us/step - loss: 0.3679 - accuracy: 0.8382 - val_loss: 0.3619 - val_accuracy: 0.8408\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 853us/step - loss: 0.3639 - accuracy: 0.8373 - val_loss: 0.3629 - val_accuracy: 0.8394\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 840us/step - loss: 0.3608 - accuracy: 0.8370 - val_loss: 0.3607 - val_accuracy: 0.8418\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3548 - accuracy: 0.8417 - val_loss: 0.3611 - val_accuracy: 0.8420\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3674 - accuracy: 0.8363 - val_loss: 0.3657 - val_accuracy: 0.8348\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 752us/step - loss: 0.3698 - accuracy: 0.8372 - val_loss: 0.3610 - val_accuracy: 0.8424\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3560 - accuracy: 0.8414 - val_loss: 0.3599 - val_accuracy: 0.8414\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3581 - accuracy: 0.8418 - val_loss: 0.3589 - val_accuracy: 0.8392\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3496 - accuracy: 0.8437 - val_loss: 0.3584 - val_accuracy: 0.8416\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 772us/step - loss: 0.3614 - accuracy: 0.8407 - val_loss: 0.3619 - val_accuracy: 0.8400\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3519 - accuracy: 0.8434 - val_loss: 0.3636 - val_accuracy: 0.8394\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3548 - accuracy: 0.8442 - val_loss: 0.3593 - val_accuracy: 0.8418\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3497 - accuracy: 0.8451 - val_loss: 0.3534 - val_accuracy: 0.8434\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3475 - accuracy: 0.8484 - val_loss: 0.3529 - val_accuracy: 0.8424\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3521 - accuracy: 0.8453 - val_loss: 0.3559 - val_accuracy: 0.8448\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3515 - accuracy: 0.8480 - val_loss: 0.3591 - val_accuracy: 0.8428\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3511 - accuracy: 0.8440 - val_loss: 0.3527 - val_accuracy: 0.8418\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 765us/step - loss: 0.3464 - accuracy: 0.8470 - val_loss: 0.3547 - val_accuracy: 0.8438\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3517 - accuracy: 0.8439 - val_loss: 0.3534 - val_accuracy: 0.8434\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3479 - accuracy: 0.8483 - val_loss: 0.3730 - val_accuracy: 0.8410\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3410 - accuracy: 0.8537 - val_loss: 0.3534 - val_accuracy: 0.8432\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3448 - accuracy: 0.8509 - val_loss: 0.3608 - val_accuracy: 0.8406\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3465 - accuracy: 0.8516 - val_loss: 0.3547 - val_accuracy: 0.8432\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 2s 983us/step - loss: 0.3437 - accuracy: 0.8522 - val_loss: 0.3595 - val_accuracy: 0.8452\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3508 - accuracy: 0.8461 - val_loss: 0.3562 - val_accuracy: 0.8434\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 927us/step - loss: 0.3447 - accuracy: 0.8502 - val_loss: 0.3622 - val_accuracy: 0.8420\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3445 - accuracy: 0.8504 - val_loss: 0.3554 - val_accuracy: 0.8464\n",
      "400/400 [==============================] - 0s 705us/step - loss: 0.3472 - accuracy: 0.8432\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 814us/step - loss: 0.4764 - accuracy: 0.7785 - val_loss: 0.3765 - val_accuracy: 0.8182\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3720 - accuracy: 0.8238 - val_loss: 0.3642 - val_accuracy: 0.8280\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3636 - accuracy: 0.8337 - val_loss: 0.3611 - val_accuracy: 0.8372\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 754us/step - loss: 0.3594 - accuracy: 0.8359 - val_loss: 0.3623 - val_accuracy: 0.8360\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 987us/step - loss: 0.3634 - accuracy: 0.8388 - val_loss: 0.3592 - val_accuracy: 0.8356\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3610 - accuracy: 0.8382 - val_loss: 0.3551 - val_accuracy: 0.8364\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 887us/step - loss: 0.3539 - accuracy: 0.8396 - val_loss: 0.3563 - val_accuracy: 0.8404\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 881us/step - loss: 0.3521 - accuracy: 0.8387 - val_loss: 0.3576 - val_accuracy: 0.8388\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3514 - accuracy: 0.8401 - val_loss: 0.3500 - val_accuracy: 0.8408\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3503 - accuracy: 0.8439 - val_loss: 0.3500 - val_accuracy: 0.8410\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3455 - accuracy: 0.8426 - val_loss: 0.3432 - val_accuracy: 0.8442\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 892us/step - loss: 0.3451 - accuracy: 0.8440 - val_loss: 0.3439 - val_accuracy: 0.8442\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 764us/step - loss: 0.3378 - accuracy: 0.8501 - val_loss: 0.3409 - val_accuracy: 0.8450\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 746us/step - loss: 0.3325 - accuracy: 0.8489 - val_loss: 0.3436 - val_accuracy: 0.8408\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 977us/step - loss: 0.3354 - accuracy: 0.8472 - val_loss: 0.3375 - val_accuracy: 0.8482\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3465 - accuracy: 0.8422 - val_loss: 0.3482 - val_accuracy: 0.8426\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 863us/step - loss: 0.3331 - accuracy: 0.8485 - val_loss: 0.3449 - val_accuracy: 0.8394\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 774us/step - loss: 0.3384 - accuracy: 0.8480 - val_loss: 0.3409 - val_accuracy: 0.8426\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 749us/step - loss: 0.3373 - accuracy: 0.8478 - val_loss: 0.3469 - val_accuracy: 0.8434\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3396 - accuracy: 0.8498 - val_loss: 0.3416 - val_accuracy: 0.8462\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 765us/step - loss: 0.3379 - accuracy: 0.8503 - val_loss: 0.3387 - val_accuracy: 0.8442\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 778us/step - loss: 0.3360 - accuracy: 0.8475 - val_loss: 0.3498 - val_accuracy: 0.8480\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 932us/step - loss: 0.3308 - accuracy: 0.8509 - val_loss: 0.3425 - val_accuracy: 0.8486\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3320 - accuracy: 0.8532 - val_loss: 0.3488 - val_accuracy: 0.8380\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3369 - accuracy: 0.8481 - val_loss: 0.3461 - val_accuracy: 0.8474\n",
      "400/400 [==============================] - 0s 735us/step - loss: 0.3304 - accuracy: 0.8520\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 817us/step - loss: 0.4794 - accuracy: 0.7762 - val_loss: 0.3859 - val_accuracy: 0.8176\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3842 - accuracy: 0.8164 - val_loss: 0.3768 - val_accuracy: 0.8210\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 864us/step - loss: 0.3821 - accuracy: 0.8167 - val_loss: 0.3738 - val_accuracy: 0.8230\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 769us/step - loss: 0.3707 - accuracy: 0.8254 - val_loss: 0.3691 - val_accuracy: 0.8204\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3618 - accuracy: 0.8309 - val_loss: 0.3642 - val_accuracy: 0.8268\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3645 - accuracy: 0.8301 - val_loss: 0.3628 - val_accuracy: 0.8354\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3614 - accuracy: 0.8371 - val_loss: 0.3706 - val_accuracy: 0.8372\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 806us/step - loss: 0.3584 - accuracy: 0.8343 - val_loss: 0.3608 - val_accuracy: 0.8380\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3553 - accuracy: 0.8414 - val_loss: 0.3636 - val_accuracy: 0.8366\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3620 - accuracy: 0.8368 - val_loss: 0.3727 - val_accuracy: 0.8334\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3565 - accuracy: 0.8412 - val_loss: 0.3609 - val_accuracy: 0.8408\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3503 - accuracy: 0.8447 - val_loss: 0.3609 - val_accuracy: 0.8350\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 956us/step - loss: 0.3570 - accuracy: 0.8425 - val_loss: 0.3551 - val_accuracy: 0.8412\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3459 - accuracy: 0.8492 - val_loss: 0.3585 - val_accuracy: 0.8400\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3532 - accuracy: 0.8462 - val_loss: 0.3536 - val_accuracy: 0.8424\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3488 - accuracy: 0.8473 - val_loss: 0.3540 - val_accuracy: 0.8426\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3408 - accuracy: 0.8506 - val_loss: 0.3549 - val_accuracy: 0.8442\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3463 - accuracy: 0.8458 - val_loss: 0.3584 - val_accuracy: 0.8434\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3481 - accuracy: 0.8461 - val_loss: 0.3551 - val_accuracy: 0.8426\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3401 - accuracy: 0.8482 - val_loss: 0.3579 - val_accuracy: 0.8394\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 852us/step - loss: 0.3468 - accuracy: 0.8501 - val_loss: 0.3546 - val_accuracy: 0.8444\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3377 - accuracy: 0.8513 - val_loss: 0.3561 - val_accuracy: 0.8418\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3391 - accuracy: 0.8500 - val_loss: 0.3550 - val_accuracy: 0.8434\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3421 - accuracy: 0.8537 - val_loss: 0.3543 - val_accuracy: 0.8456\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3416 - accuracy: 0.8496 - val_loss: 0.3615 - val_accuracy: 0.8442\n",
      "400/400 [==============================] - 0s 747us/step - loss: 0.3551 - accuracy: 0.8445\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4691 - accuracy: 0.7829 - val_loss: 0.3859 - val_accuracy: 0.8190\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3861 - accuracy: 0.8211 - val_loss: 0.3800 - val_accuracy: 0.8208\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 894us/step - loss: 0.3708 - accuracy: 0.8292 - val_loss: 0.3759 - val_accuracy: 0.8220\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 825us/step - loss: 0.3776 - accuracy: 0.8253 - val_loss: 0.3769 - val_accuracy: 0.8178\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3719 - accuracy: 0.8246 - val_loss: 0.3696 - val_accuracy: 0.8240\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3686 - accuracy: 0.8272 - val_loss: 0.3689 - val_accuracy: 0.8224\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3601 - accuracy: 0.8363 - val_loss: 0.3678 - val_accuracy: 0.8222\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 883us/step - loss: 0.3678 - accuracy: 0.8285 - val_loss: 0.3650 - val_accuracy: 0.8250\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3633 - accuracy: 0.8367 - val_loss: 0.3649 - val_accuracy: 0.8296\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 974us/step - loss: 0.3585 - accuracy: 0.8387 - val_loss: 0.3604 - val_accuracy: 0.8334\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3576 - accuracy: 0.8381 - val_loss: 0.3594 - val_accuracy: 0.8344\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3562 - accuracy: 0.8404 - val_loss: 0.3609 - val_accuracy: 0.8324\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 746us/step - loss: 0.3647 - accuracy: 0.8346 - val_loss: 0.3597 - val_accuracy: 0.8384\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 835us/step - loss: 0.3572 - accuracy: 0.8407 - val_loss: 0.3578 - val_accuracy: 0.8394\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3501 - accuracy: 0.8493 - val_loss: 0.3557 - val_accuracy: 0.8444\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3507 - accuracy: 0.8491 - val_loss: 0.3553 - val_accuracy: 0.8434\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3530 - accuracy: 0.8385 - val_loss: 0.3718 - val_accuracy: 0.8446\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 850us/step - loss: 0.3466 - accuracy: 0.8465 - val_loss: 0.3521 - val_accuracy: 0.8430\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 979us/step - loss: 0.3443 - accuracy: 0.8496 - val_loss: 0.3525 - val_accuracy: 0.8432\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3476 - accuracy: 0.8484 - val_loss: 0.3534 - val_accuracy: 0.8416\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 994us/step - loss: 0.3374 - accuracy: 0.8519 - val_loss: 0.3518 - val_accuracy: 0.8448\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 756us/step - loss: 0.3349 - accuracy: 0.8574 - val_loss: 0.3511 - val_accuracy: 0.8452\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3443 - accuracy: 0.8503 - val_loss: 0.3581 - val_accuracy: 0.8322\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 875us/step - loss: 0.3435 - accuracy: 0.8512 - val_loss: 0.3531 - val_accuracy: 0.8464\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3443 - accuracy: 0.8481 - val_loss: 0.3466 - val_accuracy: 0.8454\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3467 - accuracy: 0.8469 - val_loss: 0.3606 - val_accuracy: 0.8466\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3447 - accuracy: 0.8499 - val_loss: 0.3473 - val_accuracy: 0.8446\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3349 - accuracy: 0.8538 - val_loss: 0.3464 - val_accuracy: 0.8470\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3389 - accuracy: 0.8483 - val_loss: 0.3452 - val_accuracy: 0.8474\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3403 - accuracy: 0.8526 - val_loss: 0.3405 - val_accuracy: 0.8500\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3404 - accuracy: 0.8522 - val_loss: 0.3409 - val_accuracy: 0.8472\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 744us/step - loss: 0.3427 - accuracy: 0.8492 - val_loss: 0.3447 - val_accuracy: 0.8512\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3382 - accuracy: 0.8543 - val_loss: 0.3439 - val_accuracy: 0.8472\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3358 - accuracy: 0.8539 - val_loss: 0.3442 - val_accuracy: 0.8510\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 2s 977us/step - loss: 0.3464 - accuracy: 0.8502 - val_loss: 0.3392 - val_accuracy: 0.8510\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3402 - accuracy: 0.8553 - val_loss: 0.3417 - val_accuracy: 0.8492\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 804us/step - loss: 0.3368 - accuracy: 0.8534 - val_loss: 0.3423 - val_accuracy: 0.8480\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3319 - accuracy: 0.8572 - val_loss: 0.3420 - val_accuracy: 0.8510\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3407 - accuracy: 0.8501 - val_loss: 0.3436 - val_accuracy: 0.8500\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3310 - accuracy: 0.8563 - val_loss: 0.3488 - val_accuracy: 0.8506\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 921us/step - loss: 0.3318 - accuracy: 0.8553 - val_loss: 0.3398 - val_accuracy: 0.8474\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.8563 - val_loss: 0.3397 - val_accuracy: 0.8512\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3374 - accuracy: 0.8497 - val_loss: 0.3378 - val_accuracy: 0.8502\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3331 - accuracy: 0.8554 - val_loss: 0.3484 - val_accuracy: 0.8442\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 774us/step - loss: 0.3306 - accuracy: 0.8564 - val_loss: 0.3412 - val_accuracy: 0.8500\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 2s 942us/step - loss: 0.3369 - accuracy: 0.8548 - val_loss: 0.3413 - val_accuracy: 0.8500\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3371 - accuracy: 0.8480 - val_loss: 0.3399 - val_accuracy: 0.8496\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3406 - accuracy: 0.8469 - val_loss: 0.3417 - val_accuracy: 0.8492\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3370 - accuracy: 0.8504 - val_loss: 0.3549 - val_accuracy: 0.8490\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 735us/step - loss: 0.3357 - accuracy: 0.8542 - val_loss: 0.3518 - val_accuracy: 0.8420\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 1s 911us/step - loss: 0.3299 - accuracy: 0.8567 - val_loss: 0.3392 - val_accuracy: 0.8498\n",
      "Epoch 52/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3319 - accuracy: 0.8541 - val_loss: 0.3411 - val_accuracy: 0.8470\n",
      "Epoch 53/1000\n",
      "1600/1600 [==============================] - 1s 909us/step - loss: 0.3312 - accuracy: 0.8520 - val_loss: 0.3374 - val_accuracy: 0.8510\n",
      "Epoch 54/1000\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.3316 - accuracy: 0.8547 - val_loss: 0.3438 - val_accuracy: 0.8492\n",
      "Epoch 55/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3260 - accuracy: 0.8551 - val_loss: 0.3385 - val_accuracy: 0.8506\n",
      "Epoch 56/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3312 - accuracy: 0.8575 - val_loss: 0.3414 - val_accuracy: 0.8486\n",
      "Epoch 57/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3322 - accuracy: 0.8523 - val_loss: 0.3445 - val_accuracy: 0.8510\n",
      "Epoch 58/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3256 - accuracy: 0.8638 - val_loss: 0.3492 - val_accuracy: 0.8512\n",
      "Epoch 59/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3387 - accuracy: 0.8511 - val_loss: 0.3398 - val_accuracy: 0.8502\n",
      "Epoch 60/1000\n",
      "1600/1600 [==============================] - 1s 809us/step - loss: 0.3300 - accuracy: 0.8578 - val_loss: 0.3422 - val_accuracy: 0.8482\n",
      "Epoch 61/1000\n",
      "1600/1600 [==============================] - 1s 800us/step - loss: 0.3316 - accuracy: 0.8539 - val_loss: 0.3383 - val_accuracy: 0.8496\n",
      "Epoch 62/1000\n",
      "1600/1600 [==============================] - 1s 895us/step - loss: 0.3381 - accuracy: 0.8518 - val_loss: 0.3413 - val_accuracy: 0.8504\n",
      "Epoch 63/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3345 - accuracy: 0.8527 - val_loss: 0.3434 - val_accuracy: 0.8476\n",
      "400/400 [==============================] - 0s 705us/step - loss: 0.3351 - accuracy: 0.8470\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 814us/step - loss: 0.4807 - accuracy: 0.7783 - val_loss: 0.3816 - val_accuracy: 0.8164\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3775 - accuracy: 0.8290 - val_loss: 0.3693 - val_accuracy: 0.8312\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 913us/step - loss: 0.3577 - accuracy: 0.8399 - val_loss: 0.3594 - val_accuracy: 0.8362\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 780us/step - loss: 0.3498 - accuracy: 0.8446 - val_loss: 0.3633 - val_accuracy: 0.8360\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 767us/step - loss: 0.3606 - accuracy: 0.8420 - val_loss: 0.3579 - val_accuracy: 0.8390\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 780us/step - loss: 0.3450 - accuracy: 0.8509 - val_loss: 0.3578 - val_accuracy: 0.8386\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 842us/step - loss: 0.3551 - accuracy: 0.8436 - val_loss: 0.3583 - val_accuracy: 0.8386\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3514 - accuracy: 0.8445 - val_loss: 0.3551 - val_accuracy: 0.8412\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3503 - accuracy: 0.8458 - val_loss: 0.3572 - val_accuracy: 0.8404\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3493 - accuracy: 0.8472 - val_loss: 0.3561 - val_accuracy: 0.8406\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3464 - accuracy: 0.8485 - val_loss: 0.3517 - val_accuracy: 0.8426\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 932us/step - loss: 0.3383 - accuracy: 0.8517 - val_loss: 0.3542 - val_accuracy: 0.8414\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 775us/step - loss: 0.3453 - accuracy: 0.8474 - val_loss: 0.3478 - val_accuracy: 0.8432\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3376 - accuracy: 0.8519 - val_loss: 0.3479 - val_accuracy: 0.8422\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 888us/step - loss: 0.3389 - accuracy: 0.8497 - val_loss: 0.3512 - val_accuracy: 0.8418\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3409 - accuracy: 0.8493 - val_loss: 0.3462 - val_accuracy: 0.8442\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 767us/step - loss: 0.3377 - accuracy: 0.8541 - val_loss: 0.3454 - val_accuracy: 0.8434\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 818us/step - loss: 0.3320 - accuracy: 0.8548 - val_loss: 0.3451 - val_accuracy: 0.8454\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3347 - accuracy: 0.8569 - val_loss: 0.3480 - val_accuracy: 0.8434\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3436 - accuracy: 0.8493 - val_loss: 0.3451 - val_accuracy: 0.8438\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 782us/step - loss: 0.3354 - accuracy: 0.8553 - val_loss: 0.3480 - val_accuracy: 0.8446\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 883us/step - loss: 0.3401 - accuracy: 0.8521 - val_loss: 0.3434 - val_accuracy: 0.8462\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 779us/step - loss: 0.3332 - accuracy: 0.8554 - val_loss: 0.3452 - val_accuracy: 0.8444\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3311 - accuracy: 0.8598 - val_loss: 0.3459 - val_accuracy: 0.8458\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3328 - accuracy: 0.8542 - val_loss: 0.3429 - val_accuracy: 0.8460\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 763us/step - loss: 0.3288 - accuracy: 0.8575 - val_loss: 0.3430 - val_accuracy: 0.8444\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3249 - accuracy: 0.8587 - val_loss: 0.3512 - val_accuracy: 0.8458\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3299 - accuracy: 0.8551 - val_loss: 0.3425 - val_accuracy: 0.8432\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 884us/step - loss: 0.3260 - accuracy: 0.8547 - val_loss: 0.3436 - val_accuracy: 0.8444\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3297 - accuracy: 0.8557 - val_loss: 0.3392 - val_accuracy: 0.8450\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 2s 970us/step - loss: 0.3297 - accuracy: 0.8569 - val_loss: 0.3370 - val_accuracy: 0.8436\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 756us/step - loss: 0.3348 - accuracy: 0.8513 - val_loss: 0.3368 - val_accuracy: 0.8446\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 754us/step - loss: 0.3220 - accuracy: 0.8579 - val_loss: 0.3387 - val_accuracy: 0.8454\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3323 - accuracy: 0.8526 - val_loss: 0.3378 - val_accuracy: 0.8436\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3271 - accuracy: 0.8546 - val_loss: 0.3360 - val_accuracy: 0.8452\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3241 - accuracy: 0.8598 - val_loss: 0.3421 - val_accuracy: 0.8450\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3284 - accuracy: 0.8570 - val_loss: 0.3449 - val_accuracy: 0.8440\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3338 - accuracy: 0.8544 - val_loss: 0.3468 - val_accuracy: 0.8424\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 844us/step - loss: 0.3245 - accuracy: 0.8591 - val_loss: 0.3425 - val_accuracy: 0.8430\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3291 - accuracy: 0.8558 - val_loss: 0.3613 - val_accuracy: 0.8432\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 901us/step - loss: 0.3252 - accuracy: 0.8589 - val_loss: 0.3392 - val_accuracy: 0.8408\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 808us/step - loss: 0.3322 - accuracy: 0.8521 - val_loss: 0.3375 - val_accuracy: 0.8442\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 786us/step - loss: 0.3310 - accuracy: 0.8556 - val_loss: 0.3544 - val_accuracy: 0.8440\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 798us/step - loss: 0.3337 - accuracy: 0.8549 - val_loss: 0.3412 - val_accuracy: 0.8450\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3400 - accuracy: 0.8528 - val_loss: 0.3530 - val_accuracy: 0.8452\n",
      "400/400 [==============================] - 0s 695us/step - loss: 0.3385 - accuracy: 0.8460\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 868us/step - loss: 0.4681 - accuracy: 0.7800 - val_loss: 0.3770 - val_accuracy: 0.8180\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 771us/step - loss: 0.3777 - accuracy: 0.8238 - val_loss: 0.3643 - val_accuracy: 0.8280\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 806us/step - loss: 0.3624 - accuracy: 0.8355 - val_loss: 0.3588 - val_accuracy: 0.8370\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 756us/step - loss: 0.3648 - accuracy: 0.8313 - val_loss: 0.3571 - val_accuracy: 0.8448\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 768us/step - loss: 0.3460 - accuracy: 0.8458 - val_loss: 0.3547 - val_accuracy: 0.8444\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 782us/step - loss: 0.3526 - accuracy: 0.8432 - val_loss: 0.3580 - val_accuracy: 0.8402\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 847us/step - loss: 0.3497 - accuracy: 0.8461 - val_loss: 0.3698 - val_accuracy: 0.8330\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3433 - accuracy: 0.8484 - val_loss: 0.3577 - val_accuracy: 0.8416\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3483 - accuracy: 0.8464 - val_loss: 0.3529 - val_accuracy: 0.8450\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 770us/step - loss: 0.3492 - accuracy: 0.8432 - val_loss: 0.3474 - val_accuracy: 0.8450\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 778us/step - loss: 0.3506 - accuracy: 0.8415 - val_loss: 0.3454 - val_accuracy: 0.8442\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 763us/step - loss: 0.3369 - accuracy: 0.8484 - val_loss: 0.3561 - val_accuracy: 0.8436\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3348 - accuracy: 0.8502 - val_loss: 0.3597 - val_accuracy: 0.8434\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3407 - accuracy: 0.8509 - val_loss: 0.3457 - val_accuracy: 0.8436\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3410 - accuracy: 0.8467 - val_loss: 0.3465 - val_accuracy: 0.8430\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 894us/step - loss: 0.3422 - accuracy: 0.8448 - val_loss: 0.3443 - val_accuracy: 0.8440\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3401 - accuracy: 0.8510 - val_loss: 0.3417 - val_accuracy: 0.8448\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 782us/step - loss: 0.3383 - accuracy: 0.8505 - val_loss: 0.3549 - val_accuracy: 0.8428\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3420 - accuracy: 0.8505 - val_loss: 0.3444 - val_accuracy: 0.8482\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 965us/step - loss: 0.3323 - accuracy: 0.8532 - val_loss: 0.3396 - val_accuracy: 0.8480\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3332 - accuracy: 0.8560 - val_loss: 0.3514 - val_accuracy: 0.8496\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3340 - accuracy: 0.8512 - val_loss: 0.3430 - val_accuracy: 0.8454\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 817us/step - loss: 0.3384 - accuracy: 0.8510 - val_loss: 0.3417 - val_accuracy: 0.8498\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3375 - accuracy: 0.8498 - val_loss: 0.3418 - val_accuracy: 0.8498\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3267 - accuracy: 0.8578 - val_loss: 0.3363 - val_accuracy: 0.8486\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 775us/step - loss: 0.3277 - accuracy: 0.8566 - val_loss: 0.3432 - val_accuracy: 0.8488\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 788us/step - loss: 0.3298 - accuracy: 0.8585 - val_loss: 0.3433 - val_accuracy: 0.8508\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 884us/step - loss: 0.3347 - accuracy: 0.8497 - val_loss: 0.3380 - val_accuracy: 0.8488\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.8526 - val_loss: 0.3425 - val_accuracy: 0.8490\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3284 - accuracy: 0.8539 - val_loss: 0.3428 - val_accuracy: 0.8506\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 931us/step - loss: 0.3255 - accuracy: 0.8576 - val_loss: 0.3513 - val_accuracy: 0.8500\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 772us/step - loss: 0.3323 - accuracy: 0.8559 - val_loss: 0.3398 - val_accuracy: 0.8484\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 763us/step - loss: 0.3353 - accuracy: 0.8521 - val_loss: 0.3421 - val_accuracy: 0.8490\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 768us/step - loss: 0.3343 - accuracy: 0.8504 - val_loss: 0.3412 - val_accuracy: 0.8476\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 784us/step - loss: 0.3438 - accuracy: 0.8503 - val_loss: 0.3388 - val_accuracy: 0.8484\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3260 - accuracy: 0.8528\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 3s 1ms/step - loss: 0.4621 - accuracy: 0.7727 - val_loss: 0.3836 - val_accuracy: 0.8154\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 799us/step - loss: 0.3868 - accuracy: 0.8261 - val_loss: 0.3782 - val_accuracy: 0.8220\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3736 - accuracy: 0.8288 - val_loss: 0.3756 - val_accuracy: 0.8242\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3777 - accuracy: 0.8256 - val_loss: 0.3730 - val_accuracy: 0.8268\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 782us/step - loss: 0.3699 - accuracy: 0.8284 - val_loss: 0.3639 - val_accuracy: 0.8280\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 776us/step - loss: 0.3603 - accuracy: 0.8363 - val_loss: 0.3612 - val_accuracy: 0.8340\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3576 - accuracy: 0.8426 - val_loss: 0.3603 - val_accuracy: 0.8270\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 883us/step - loss: 0.3475 - accuracy: 0.8434 - val_loss: 0.3523 - val_accuracy: 0.8378\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3451 - accuracy: 0.8458 - val_loss: 0.3507 - val_accuracy: 0.8346\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 891us/step - loss: 0.3403 - accuracy: 0.8486 - val_loss: 0.3449 - val_accuracy: 0.8400\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3482 - accuracy: 0.8434 - val_loss: 0.3492 - val_accuracy: 0.8364\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 736us/step - loss: 0.3446 - accuracy: 0.8444 - val_loss: 0.3396 - val_accuracy: 0.8476\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3377 - accuracy: 0.8515 - val_loss: 0.3397 - val_accuracy: 0.8482\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3330 - accuracy: 0.8503 - val_loss: 0.3379 - val_accuracy: 0.8464\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 790us/step - loss: 0.3360 - accuracy: 0.8504 - val_loss: 0.3452 - val_accuracy: 0.8448\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3393 - accuracy: 0.8469 - val_loss: 0.3411 - val_accuracy: 0.8432\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3375 - accuracy: 0.8486 - val_loss: 0.3399 - val_accuracy: 0.8470\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3397 - accuracy: 0.8483 - val_loss: 0.3413 - val_accuracy: 0.8416\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 946us/step - loss: 0.3366 - accuracy: 0.8524 - val_loss: 0.3373 - val_accuracy: 0.8466\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3260 - accuracy: 0.8544 - val_loss: 0.3507 - val_accuracy: 0.8430\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 780us/step - loss: 0.3319 - accuracy: 0.8541 - val_loss: 0.3431 - val_accuracy: 0.8490\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.3415 - accuracy: 0.8467 - val_loss: 0.3354 - val_accuracy: 0.8484\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3297 - accuracy: 0.8548 - val_loss: 0.3390 - val_accuracy: 0.8492\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 767us/step - loss: 0.3416 - accuracy: 0.8509 - val_loss: 0.3518 - val_accuracy: 0.8472\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 746us/step - loss: 0.3337 - accuracy: 0.8513 - val_loss: 0.3459 - val_accuracy: 0.8422\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 825us/step - loss: 0.3374 - accuracy: 0.8505 - val_loss: 0.3403 - val_accuracy: 0.8494\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3389 - accuracy: 0.8479 - val_loss: 0.3464 - val_accuracy: 0.8436\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3294 - accuracy: 0.8521 - val_loss: 0.3374 - val_accuracy: 0.8458\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3386 - accuracy: 0.8495 - val_loss: 0.3416 - val_accuracy: 0.8480\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3338 - accuracy: 0.8493 - val_loss: 0.3460 - val_accuracy: 0.8476\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3380 - accuracy: 0.8487 - val_loss: 0.3562 - val_accuracy: 0.8464\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 763us/step - loss: 0.3325 - accuracy: 0.8524 - val_loss: 0.3386 - val_accuracy: 0.8484\n",
      "400/400 [==============================] - 0s 715us/step - loss: 0.3270 - accuracy: 0.8562\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 969us/step - loss: 0.4702 - accuracy: 0.7738 - val_loss: 0.3789 - val_accuracy: 0.8146\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3767 - accuracy: 0.8232 - val_loss: 0.3631 - val_accuracy: 0.8306\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 854us/step - loss: 0.3574 - accuracy: 0.8371 - val_loss: 0.3586 - val_accuracy: 0.8358\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3458 - accuracy: 0.8475 - val_loss: 0.3584 - val_accuracy: 0.8370\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3534 - accuracy: 0.8435 - val_loss: 0.3557 - val_accuracy: 0.8394\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3556 - accuracy: 0.8395 - val_loss: 0.3611 - val_accuracy: 0.8342\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3433 - accuracy: 0.8506 - val_loss: 0.3527 - val_accuracy: 0.8426\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 736us/step - loss: 0.3489 - accuracy: 0.8438 - val_loss: 0.3565 - val_accuracy: 0.8398\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3451 - accuracy: 0.8471 - val_loss: 0.3480 - val_accuracy: 0.8406\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3332 - accuracy: 0.8508 - val_loss: 0.3497 - val_accuracy: 0.8408\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 777us/step - loss: 0.3423 - accuracy: 0.8497 - val_loss: 0.3477 - val_accuracy: 0.8444\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3373 - accuracy: 0.8529 - val_loss: 0.3446 - val_accuracy: 0.8460\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 772us/step - loss: 0.3340 - accuracy: 0.8517 - val_loss: 0.3447 - val_accuracy: 0.8476\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3354 - accuracy: 0.8526 - val_loss: 0.3456 - val_accuracy: 0.8474\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3437 - accuracy: 0.8488 - val_loss: 0.3476 - val_accuracy: 0.8464\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3354 - accuracy: 0.8502 - val_loss: 0.3478 - val_accuracy: 0.8438\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3399 - accuracy: 0.8494 - val_loss: 0.3461 - val_accuracy: 0.8456\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 916us/step - loss: 0.3428 - accuracy: 0.8474 - val_loss: 0.3505 - val_accuracy: 0.8464\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3313 - accuracy: 0.8562 - val_loss: 0.3497 - val_accuracy: 0.8434\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 901us/step - loss: 0.3287 - accuracy: 0.8545 - val_loss: 0.3475 - val_accuracy: 0.8420\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3364 - accuracy: 0.8553 - val_loss: 0.3460 - val_accuracy: 0.8464\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 756us/step - loss: 0.3394 - accuracy: 0.8508 - val_loss: 0.3485 - val_accuracy: 0.8488\n",
      "400/400 [==============================] - 0s 742us/step - loss: 0.3482 - accuracy: 0.8493\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 811us/step - loss: 0.4772 - accuracy: 0.7821 - val_loss: 0.3845 - val_accuracy: 0.8200\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 736us/step - loss: 0.3844 - accuracy: 0.8169 - val_loss: 0.3749 - val_accuracy: 0.8172\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3677 - accuracy: 0.8328 - val_loss: 0.3625 - val_accuracy: 0.8346\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3606 - accuracy: 0.8358 - val_loss: 0.3632 - val_accuracy: 0.8332\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.3705 - accuracy: 0.8309 - val_loss: 0.3707 - val_accuracy: 0.8332\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 999us/step - loss: 0.3504 - accuracy: 0.8463 - val_loss: 0.3602 - val_accuracy: 0.8374\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3563 - accuracy: 0.8407 - val_loss: 0.3613 - val_accuracy: 0.8398\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 826us/step - loss: 0.3537 - accuracy: 0.8439 - val_loss: 0.3589 - val_accuracy: 0.8402\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 794us/step - loss: 0.3561 - accuracy: 0.8406 - val_loss: 0.3617 - val_accuracy: 0.8388\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 815us/step - loss: 0.3596 - accuracy: 0.8391 - val_loss: 0.3615 - val_accuracy: 0.8372\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3558 - accuracy: 0.8433 - val_loss: 0.3596 - val_accuracy: 0.8420\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 764us/step - loss: 0.3608 - accuracy: 0.8339 - val_loss: 0.3641 - val_accuracy: 0.8398\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 768us/step - loss: 0.3638 - accuracy: 0.8397 - val_loss: 0.3616 - val_accuracy: 0.8372\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 884us/step - loss: 0.3572 - accuracy: 0.8411 - val_loss: 0.3634 - val_accuracy: 0.8398\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3600 - accuracy: 0.8428 - val_loss: 0.3665 - val_accuracy: 0.8408\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 816us/step - loss: 0.3581 - accuracy: 0.8453 - val_loss: 0.3570 - val_accuracy: 0.8404\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 934us/step - loss: 0.3636 - accuracy: 0.8407 - val_loss: 0.3557 - val_accuracy: 0.8412\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3501 - accuracy: 0.8432 - val_loss: 0.3548 - val_accuracy: 0.8422\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 999us/step - loss: 0.3535 - accuracy: 0.8469 - val_loss: 0.3569 - val_accuracy: 0.8430\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3425 - accuracy: 0.8527 - val_loss: 0.3665 - val_accuracy: 0.8412\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3487 - accuracy: 0.8469 - val_loss: 0.3593 - val_accuracy: 0.8448\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 765us/step - loss: 0.3479 - accuracy: 0.8500 - val_loss: 0.3565 - val_accuracy: 0.8452\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3535 - accuracy: 0.8465 - val_loss: 0.3601 - val_accuracy: 0.8400\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3439 - accuracy: 0.8484 - val_loss: 0.3526 - val_accuracy: 0.8434\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 764us/step - loss: 0.3465 - accuracy: 0.8504 - val_loss: 0.3540 - val_accuracy: 0.8422\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 767us/step - loss: 0.3541 - accuracy: 0.8477 - val_loss: 0.3632 - val_accuracy: 0.8418\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 993us/step - loss: 0.3492 - accuracy: 0.8490 - val_loss: 0.3542 - val_accuracy: 0.8452\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3459 - accuracy: 0.8519 - val_loss: 0.3601 - val_accuracy: 0.8432\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 810us/step - loss: 0.3447 - accuracy: 0.8514 - val_loss: 0.3566 - val_accuracy: 0.8440\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 735us/step - loss: 0.3375 - accuracy: 0.8517 - val_loss: 0.3539 - val_accuracy: 0.8442\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3389 - accuracy: 0.8507 - val_loss: 0.3603 - val_accuracy: 0.8424\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3554 - accuracy: 0.8472 - val_loss: 0.3723 - val_accuracy: 0.8410\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 798us/step - loss: 0.3443 - accuracy: 0.8515 - val_loss: 0.3582 - val_accuracy: 0.8428\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 795us/step - loss: 0.3530 - accuracy: 0.8449 - val_loss: 0.3504 - val_accuracy: 0.8450\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 736us/step - loss: 0.3385 - accuracy: 0.8528 - val_loss: 0.3611 - val_accuracy: 0.8428\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3468 - accuracy: 0.8506 - val_loss: 0.3544 - val_accuracy: 0.8406\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 2s 962us/step - loss: 0.3508 - accuracy: 0.8502 - val_loss: 0.3593 - val_accuracy: 0.8414\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.8531 - val_loss: 0.3546 - val_accuracy: 0.8440\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 890us/step - loss: 0.3365 - accuracy: 0.8553 - val_loss: 0.3634 - val_accuracy: 0.8454\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 765us/step - loss: 0.3432 - accuracy: 0.8499 - val_loss: 0.3560 - val_accuracy: 0.8444\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3383 - accuracy: 0.8513 - val_loss: 0.3581 - val_accuracy: 0.8450\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3369 - accuracy: 0.8544 - val_loss: 0.3661 - val_accuracy: 0.8402\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 790us/step - loss: 0.3419 - accuracy: 0.8486 - val_loss: 0.3587 - val_accuracy: 0.8452\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3452 - accuracy: 0.8483 - val_loss: 0.3536 - val_accuracy: 0.8454\n",
      "400/400 [==============================] - 0s 697us/step - loss: 0.3501 - accuracy: 0.8430\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 799us/step - loss: 0.4608 - accuracy: 0.7844 - val_loss: 0.3811 - val_accuracy: 0.8218\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 914us/step - loss: 0.3762 - accuracy: 0.8271 - val_loss: 0.3751 - val_accuracy: 0.8270\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3703 - accuracy: 0.8320 - val_loss: 0.3652 - val_accuracy: 0.8368\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 891us/step - loss: 0.3561 - accuracy: 0.8414 - val_loss: 0.3645 - val_accuracy: 0.8382\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3635 - accuracy: 0.8399 - val_loss: 0.3660 - val_accuracy: 0.8340\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3590 - accuracy: 0.8384 - val_loss: 0.3632 - val_accuracy: 0.8378\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 785us/step - loss: 0.3551 - accuracy: 0.8456 - val_loss: 0.3641 - val_accuracy: 0.8390\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3577 - accuracy: 0.8414 - val_loss: 0.3604 - val_accuracy: 0.8408\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 828us/step - loss: 0.3498 - accuracy: 0.8483 - val_loss: 0.3590 - val_accuracy: 0.8398\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3576 - accuracy: 0.8450 - val_loss: 0.3608 - val_accuracy: 0.8400\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 906us/step - loss: 0.3568 - accuracy: 0.8434 - val_loss: 0.3618 - val_accuracy: 0.8386\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3607 - accuracy: 0.8460 - val_loss: 0.3642 - val_accuracy: 0.8396\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3444 - accuracy: 0.8533 - val_loss: 0.3593 - val_accuracy: 0.8424\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3549 - accuracy: 0.8453 - val_loss: 0.3591 - val_accuracy: 0.8378\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3461 - accuracy: 0.8488 - val_loss: 0.3558 - val_accuracy: 0.8426\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3436 - accuracy: 0.8507 - val_loss: 0.3533 - val_accuracy: 0.8450\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 2s 949us/step - loss: 0.3403 - accuracy: 0.8550 - val_loss: 0.3523 - val_accuracy: 0.8436\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3452 - accuracy: 0.8526 - val_loss: 0.3535 - val_accuracy: 0.8426\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 882us/step - loss: 0.3475 - accuracy: 0.8497 - val_loss: 0.3571 - val_accuracy: 0.8440\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3450 - accuracy: 0.8495 - val_loss: 0.3537 - val_accuracy: 0.8446\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3419 - accuracy: 0.8529 - val_loss: 0.3765 - val_accuracy: 0.8428\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 749us/step - loss: 0.3450 - accuracy: 0.8462 - val_loss: 0.3519 - val_accuracy: 0.8442\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 793us/step - loss: 0.3333 - accuracy: 0.8602 - val_loss: 0.3501 - val_accuracy: 0.8464\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 775us/step - loss: 0.3420 - accuracy: 0.8539 - val_loss: 0.3604 - val_accuracy: 0.8430\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3382 - accuracy: 0.8568 - val_loss: 0.3540 - val_accuracy: 0.8446\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3386 - accuracy: 0.8563 - val_loss: 0.3650 - val_accuracy: 0.8440\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3384 - accuracy: 0.8586 - val_loss: 0.3523 - val_accuracy: 0.8424\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 804us/step - loss: 0.3304 - accuracy: 0.8590 - val_loss: 0.3727 - val_accuracy: 0.8434\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3265 - accuracy: 0.8658 - val_loss: 0.3541 - val_accuracy: 0.8446\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3446 - accuracy: 0.8552 - val_loss: 0.3617 - val_accuracy: 0.8444\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 746us/step - loss: 0.3301 - accuracy: 0.8627 - val_loss: 0.3661 - val_accuracy: 0.8436\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 921us/step - loss: 0.3348 - accuracy: 0.8633 - val_loss: 0.3541 - val_accuracy: 0.8438\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3338 - accuracy: 0.8602 - val_loss: 0.3547 - val_accuracy: 0.8438\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3557 - accuracy: 0.8378\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 906us/step - loss: 0.4582 - accuracy: 0.7816 - val_loss: 0.3740 - val_accuracy: 0.8162\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3732 - accuracy: 0.8237 - val_loss: 0.3794 - val_accuracy: 0.8386\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3613 - accuracy: 0.8347 - val_loss: 0.3581 - val_accuracy: 0.8352\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 901us/step - loss: 0.3588 - accuracy: 0.8386 - val_loss: 0.3633 - val_accuracy: 0.8378\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3456 - accuracy: 0.8436 - val_loss: 0.3560 - val_accuracy: 0.8406\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 815us/step - loss: 0.3447 - accuracy: 0.8460 - val_loss: 0.3434 - val_accuracy: 0.8430\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3411 - accuracy: 0.8509 - val_loss: 0.3439 - val_accuracy: 0.8494\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 894us/step - loss: 0.3426 - accuracy: 0.8496 - val_loss: 0.3403 - val_accuracy: 0.8512\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3424 - accuracy: 0.8448 - val_loss: 0.3497 - val_accuracy: 0.8474\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 922us/step - loss: 0.3307 - accuracy: 0.8515 - val_loss: 0.3404 - val_accuracy: 0.8504\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3394 - accuracy: 0.8431 - val_loss: 0.3402 - val_accuracy: 0.8510\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3358 - accuracy: 0.8484 - val_loss: 0.3394 - val_accuracy: 0.8492\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3403 - accuracy: 0.8490 - val_loss: 0.3496 - val_accuracy: 0.8506\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 795us/step - loss: 0.3314 - accuracy: 0.8541 - val_loss: 0.3424 - val_accuracy: 0.8450\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3262 - accuracy: 0.8571 - val_loss: 0.3382 - val_accuracy: 0.8488\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 889us/step - loss: 0.3388 - accuracy: 0.8489 - val_loss: 0.3626 - val_accuracy: 0.8350\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3283 - accuracy: 0.8543 - val_loss: 0.3427 - val_accuracy: 0.8488\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 926us/step - loss: 0.3273 - accuracy: 0.8576 - val_loss: 0.3444 - val_accuracy: 0.8484\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3312 - accuracy: 0.8565 - val_loss: 0.3421 - val_accuracy: 0.8498\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 796us/step - loss: 0.3331 - accuracy: 0.8495 - val_loss: 0.3425 - val_accuracy: 0.8490\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3297 - accuracy: 0.8562 - val_loss: 0.3373 - val_accuracy: 0.8522\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3287 - accuracy: 0.8564 - val_loss: 0.3583 - val_accuracy: 0.8520\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3274 - accuracy: 0.8575 - val_loss: 0.3409 - val_accuracy: 0.8524\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3261 - accuracy: 0.8557 - val_loss: 0.3424 - val_accuracy: 0.8506\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3353 - accuracy: 0.8528 - val_loss: 0.3418 - val_accuracy: 0.8522\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3333 - accuracy: 0.8567 - val_loss: 0.3488 - val_accuracy: 0.8516\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3376 - accuracy: 0.8525 - val_loss: 0.3552 - val_accuracy: 0.8496\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3290 - accuracy: 0.8581 - val_loss: 0.3469 - val_accuracy: 0.8502\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3323 - accuracy: 0.8561 - val_loss: 0.3443 - val_accuracy: 0.8506\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 805us/step - loss: 0.3303 - accuracy: 0.8580 - val_loss: 0.3530 - val_accuracy: 0.8478\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3235 - accuracy: 0.8590 - val_loss: 0.3533 - val_accuracy: 0.8498\n",
      "400/400 [==============================] - 0s 852us/step - loss: 0.3290 - accuracy: 0.8530\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 805us/step - loss: 0.4552 - accuracy: 0.7819 - val_loss: 0.3734 - val_accuracy: 0.8180\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3762 - accuracy: 0.8264 - val_loss: 0.3639 - val_accuracy: 0.8342\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 889us/step - loss: 0.3624 - accuracy: 0.8381 - val_loss: 0.3649 - val_accuracy: 0.8356\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3649 - accuracy: 0.8366 - val_loss: 0.3635 - val_accuracy: 0.8414\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3598 - accuracy: 0.8387 - val_loss: 0.3567 - val_accuracy: 0.8428\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3515 - accuracy: 0.8446 - val_loss: 0.3531 - val_accuracy: 0.8436\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 751us/step - loss: 0.3520 - accuracy: 0.8418 - val_loss: 0.3521 - val_accuracy: 0.8438\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3545 - accuracy: 0.8410 - val_loss: 0.3511 - val_accuracy: 0.8410\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 880us/step - loss: 0.3535 - accuracy: 0.8407 - val_loss: 0.3499 - val_accuracy: 0.8420\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3481 - accuracy: 0.8442 - val_loss: 0.3548 - val_accuracy: 0.8418\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3453 - accuracy: 0.8496 - val_loss: 0.3505 - val_accuracy: 0.8432\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 2s 974us/step - loss: 0.3441 - accuracy: 0.8493 - val_loss: 0.3465 - val_accuracy: 0.8466\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 763us/step - loss: 0.3430 - accuracy: 0.8517 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3436 - accuracy: 0.8515 - val_loss: 0.3484 - val_accuracy: 0.8406\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 831us/step - loss: 0.3401 - accuracy: 0.8502 - val_loss: 0.3490 - val_accuracy: 0.8460\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3430 - accuracy: 0.8510 - val_loss: 0.3596 - val_accuracy: 0.8454\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3448 - accuracy: 0.8537 - val_loss: 0.3685 - val_accuracy: 0.8366\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 839us/step - loss: 0.3427 - accuracy: 0.8526 - val_loss: 0.3437 - val_accuracy: 0.8454\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3422 - accuracy: 0.8539 - val_loss: 0.3479 - val_accuracy: 0.8492\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3368 - accuracy: 0.8515 - val_loss: 0.3724 - val_accuracy: 0.8470\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3428 - accuracy: 0.8474 - val_loss: 0.3488 - val_accuracy: 0.8504\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3421 - accuracy: 0.8509 - val_loss: 0.3438 - val_accuracy: 0.8476\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3334 - accuracy: 0.8541 - val_loss: 0.3458 - val_accuracy: 0.8488\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3373 - accuracy: 0.8510 - val_loss: 0.3507 - val_accuracy: 0.8448\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3387 - accuracy: 0.8544 - val_loss: 0.3511 - val_accuracy: 0.8484\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 751us/step - loss: 0.3383 - accuracy: 0.8563 - val_loss: 0.3618 - val_accuracy: 0.8492\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3360 - accuracy: 0.8565 - val_loss: 0.3518 - val_accuracy: 0.8520\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3271 - accuracy: 0.8586 - val_loss: 0.3522 - val_accuracy: 0.8508\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3339 - accuracy: 0.8550\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 3s 1ms/step - loss: 0.4522 - accuracy: 0.7844 - val_loss: 0.3752 - val_accuracy: 0.8278\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 792us/step - loss: 0.3760 - accuracy: 0.8259 - val_loss: 0.3639 - val_accuracy: 0.8338\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 798us/step - loss: 0.3541 - accuracy: 0.8373 - val_loss: 0.3641 - val_accuracy: 0.8360\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3552 - accuracy: 0.8388 - val_loss: 0.3555 - val_accuracy: 0.8406\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3537 - accuracy: 0.8417 - val_loss: 0.3538 - val_accuracy: 0.8402\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3477 - accuracy: 0.8457 - val_loss: 0.3505 - val_accuracy: 0.8430\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 752us/step - loss: 0.3429 - accuracy: 0.8472 - val_loss: 0.3591 - val_accuracy: 0.8322\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3438 - accuracy: 0.8446 - val_loss: 0.3620 - val_accuracy: 0.8410\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 864us/step - loss: 0.3474 - accuracy: 0.8439 - val_loss: 0.3459 - val_accuracy: 0.8464\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3458 - accuracy: 0.8452 - val_loss: 0.3533 - val_accuracy: 0.8412\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3457 - accuracy: 0.8449 - val_loss: 0.3471 - val_accuracy: 0.8464\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 2s 953us/step - loss: 0.3342 - accuracy: 0.8506 - val_loss: 0.3542 - val_accuracy: 0.8458\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3374 - accuracy: 0.8500 - val_loss: 0.3528 - val_accuracy: 0.8460\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3451 - accuracy: 0.8476 - val_loss: 0.3463 - val_accuracy: 0.8472\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3338 - accuracy: 0.8534 - val_loss: 0.3497 - val_accuracy: 0.8424\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 825us/step - loss: 0.3337 - accuracy: 0.8512 - val_loss: 0.3526 - val_accuracy: 0.8420\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 754us/step - loss: 0.3372 - accuracy: 0.8527 - val_loss: 0.3425 - val_accuracy: 0.8456\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3393 - accuracy: 0.8506 - val_loss: 0.3434 - val_accuracy: 0.8470\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3346 - accuracy: 0.8526 - val_loss: 0.3440 - val_accuracy: 0.8454\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 906us/step - loss: 0.3393 - accuracy: 0.8493 - val_loss: 0.3529 - val_accuracy: 0.8480\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.8536 - val_loss: 0.3651 - val_accuracy: 0.8332\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3309 - accuracy: 0.8541 - val_loss: 0.3428 - val_accuracy: 0.8454\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3430 - accuracy: 0.8498 - val_loss: 0.3508 - val_accuracy: 0.8426\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3290 - accuracy: 0.8535 - val_loss: 0.3495 - val_accuracy: 0.8488\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3290 - accuracy: 0.8540 - val_loss: 0.3441 - val_accuracy: 0.8446\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3385 - accuracy: 0.8522 - val_loss: 0.3471 - val_accuracy: 0.8462\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3290 - accuracy: 0.8530 - val_loss: 0.3868 - val_accuracy: 0.8426\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3431 - accuracy: 0.8505\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 3s 1ms/step - loss: 0.4538 - accuracy: 0.7879 - val_loss: 0.3925 - val_accuracy: 0.8184\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3760 - accuracy: 0.8258 - val_loss: 0.3697 - val_accuracy: 0.8272\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3558 - accuracy: 0.8369 - val_loss: 0.3643 - val_accuracy: 0.8288\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3632 - accuracy: 0.8372 - val_loss: 0.3650 - val_accuracy: 0.8370\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 934us/step - loss: 0.3608 - accuracy: 0.8389 - val_loss: 0.3603 - val_accuracy: 0.8380\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3653 - accuracy: 0.8337 - val_loss: 0.3681 - val_accuracy: 0.8358\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3553 - accuracy: 0.8433 - val_loss: 0.3591 - val_accuracy: 0.8420\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3560 - accuracy: 0.8417 - val_loss: 0.3603 - val_accuracy: 0.8392\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3655 - accuracy: 0.8342 - val_loss: 0.3578 - val_accuracy: 0.8422\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3619 - accuracy: 0.8405 - val_loss: 0.3580 - val_accuracy: 0.8412\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 759us/step - loss: 0.3544 - accuracy: 0.8456 - val_loss: 0.3591 - val_accuracy: 0.8396\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 2s 949us/step - loss: 0.3548 - accuracy: 0.8440 - val_loss: 0.3533 - val_accuracy: 0.8426\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3475 - accuracy: 0.8464 - val_loss: 0.3532 - val_accuracy: 0.8450\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 953us/step - loss: 0.3561 - accuracy: 0.8395 - val_loss: 0.3575 - val_accuracy: 0.8442\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3427 - accuracy: 0.8508 - val_loss: 0.3517 - val_accuracy: 0.8436\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3436 - accuracy: 0.8492 - val_loss: 0.3456 - val_accuracy: 0.8456\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3489 - accuracy: 0.8459 - val_loss: 0.3637 - val_accuracy: 0.8460\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3435 - accuracy: 0.8511 - val_loss: 0.3522 - val_accuracy: 0.8448\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 864us/step - loss: 0.3422 - accuracy: 0.8518 - val_loss: 0.3430 - val_accuracy: 0.8422\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3464 - accuracy: 0.8462 - val_loss: 0.3546 - val_accuracy: 0.8438\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 958us/step - loss: 0.3415 - accuracy: 0.8509 - val_loss: 0.3514 - val_accuracy: 0.8452\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3395 - accuracy: 0.8540 - val_loss: 0.3410 - val_accuracy: 0.8426\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3340 - accuracy: 0.8542 - val_loss: 0.3493 - val_accuracy: 0.8460\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3382 - accuracy: 0.8553 - val_loss: 0.3495 - val_accuracy: 0.8454\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3378 - accuracy: 0.8519 - val_loss: 0.3498 - val_accuracy: 0.8468\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3416 - accuracy: 0.8514 - val_loss: 0.3436 - val_accuracy: 0.8458\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 969us/step - loss: 0.3348 - accuracy: 0.8544 - val_loss: 0.3442 - val_accuracy: 0.8430\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3356 - accuracy: 0.8512 - val_loss: 0.3798 - val_accuracy: 0.8452\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3345 - accuracy: 0.8544 - val_loss: 0.3542 - val_accuracy: 0.8450\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3346 - accuracy: 0.8521 - val_loss: 0.3657 - val_accuracy: 0.8436\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3376 - accuracy: 0.8525 - val_loss: 0.3702 - val_accuracy: 0.8428\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3459 - accuracy: 0.8510 - val_loss: 0.3562 - val_accuracy: 0.8430\n",
      "400/400 [==============================] - 0s 715us/step - loss: 0.3406 - accuracy: 0.8518\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4395 - accuracy: 0.7950 - val_loss: 0.3712 - val_accuracy: 0.8208\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3623 - accuracy: 0.8342 - val_loss: 0.3683 - val_accuracy: 0.8400\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3552 - accuracy: 0.8391 - val_loss: 0.3575 - val_accuracy: 0.8402\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3432 - accuracy: 0.8480 - val_loss: 0.3574 - val_accuracy: 0.8410\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 764us/step - loss: 0.3516 - accuracy: 0.8458 - val_loss: 0.3518 - val_accuracy: 0.8440\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 876us/step - loss: 0.3437 - accuracy: 0.8505 - val_loss: 0.3463 - val_accuracy: 0.8460\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3363 - accuracy: 0.8517 - val_loss: 0.3491 - val_accuracy: 0.8428\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3400 - accuracy: 0.8523 - val_loss: 0.3434 - val_accuracy: 0.8454\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 805us/step - loss: 0.3380 - accuracy: 0.8521 - val_loss: 0.3479 - val_accuracy: 0.8430\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3391 - accuracy: 0.8497 - val_loss: 0.3432 - val_accuracy: 0.8472\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3328 - accuracy: 0.8510 - val_loss: 0.3414 - val_accuracy: 0.8458\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3289 - accuracy: 0.8595 - val_loss: 0.3420 - val_accuracy: 0.8484\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 735us/step - loss: 0.3368 - accuracy: 0.8483 - val_loss: 0.3439 - val_accuracy: 0.8508\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3323 - accuracy: 0.8544 - val_loss: 0.3414 - val_accuracy: 0.8462\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 767us/step - loss: 0.3327 - accuracy: 0.8547 - val_loss: 0.3390 - val_accuracy: 0.8478\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 813us/step - loss: 0.3352 - accuracy: 0.8504 - val_loss: 0.3402 - val_accuracy: 0.8486\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3358 - accuracy: 0.8507 - val_loss: 0.3380 - val_accuracy: 0.8502\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3229 - accuracy: 0.8592 - val_loss: 0.3417 - val_accuracy: 0.8438\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 842us/step - loss: 0.3276 - accuracy: 0.8574 - val_loss: 0.3450 - val_accuracy: 0.8488\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3272 - accuracy: 0.8562 - val_loss: 0.3498 - val_accuracy: 0.8486\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3345 - accuracy: 0.8557 - val_loss: 0.3623 - val_accuracy: 0.8506\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3361 - accuracy: 0.8549 - val_loss: 0.3493 - val_accuracy: 0.8478\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3291 - accuracy: 0.8576 - val_loss: 0.3455 - val_accuracy: 0.8472\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 736us/step - loss: 0.3303 - accuracy: 0.8549 - val_loss: 0.3470 - val_accuracy: 0.8504\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3314 - accuracy: 0.8566 - val_loss: 0.3483 - val_accuracy: 0.8490\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 871us/step - loss: 0.3267 - accuracy: 0.8592 - val_loss: 0.3453 - val_accuracy: 0.8516\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3348 - accuracy: 0.8525 - val_loss: 0.3432 - val_accuracy: 0.8476\n",
      "400/400 [==============================] - 0s 732us/step - loss: 0.3394 - accuracy: 0.8447\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 3s 1ms/step - loss: 0.4334 - accuracy: 0.7943 - val_loss: 0.3662 - val_accuracy: 0.8300\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3724 - accuracy: 0.8304 - val_loss: 0.3662 - val_accuracy: 0.8376\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 833us/step - loss: 0.3547 - accuracy: 0.8412 - val_loss: 0.3653 - val_accuracy: 0.8402\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3641 - accuracy: 0.8388 - val_loss: 0.3714 - val_accuracy: 0.8392\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3468 - accuracy: 0.8484 - val_loss: 0.3566 - val_accuracy: 0.8440\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 790us/step - loss: 0.3573 - accuracy: 0.8434 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3426 - accuracy: 0.8509 - val_loss: 0.3592 - val_accuracy: 0.8460\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3410 - accuracy: 0.8525 - val_loss: 0.3446 - val_accuracy: 0.8486\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 848us/step - loss: 0.3441 - accuracy: 0.8517 - val_loss: 0.3428 - val_accuracy: 0.8514\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 752us/step - loss: 0.3413 - accuracy: 0.8475 - val_loss: 0.3543 - val_accuracy: 0.8470\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 883us/step - loss: 0.3388 - accuracy: 0.8534 - val_loss: 0.3445 - val_accuracy: 0.8486\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3380 - accuracy: 0.8532 - val_loss: 0.3443 - val_accuracy: 0.8452\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3304 - accuracy: 0.8586 - val_loss: 0.3491 - val_accuracy: 0.8446\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3437 - accuracy: 0.8496 - val_loss: 0.3496 - val_accuracy: 0.8474\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 770us/step - loss: 0.3422 - accuracy: 0.8488 - val_loss: 0.3488 - val_accuracy: 0.8432\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 858us/step - loss: 0.3396 - accuracy: 0.8523 - val_loss: 0.3545 - val_accuracy: 0.8470\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 913us/step - loss: 0.3334 - accuracy: 0.8569 - val_loss: 0.3518 - val_accuracy: 0.8466\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3346 - accuracy: 0.8542 - val_loss: 0.3626 - val_accuracy: 0.8466\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 763us/step - loss: 0.3317 - accuracy: 0.8580 - val_loss: 0.3465 - val_accuracy: 0.8488\n",
      "400/400 [==============================] - 0s 702us/step - loss: 0.3367 - accuracy: 0.8525\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 909us/step - loss: 0.4344 - accuracy: 0.7944 - val_loss: 0.3795 - val_accuracy: 0.8302\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 794us/step - loss: 0.3565 - accuracy: 0.8443 - val_loss: 0.3609 - val_accuracy: 0.8370\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 793us/step - loss: 0.3526 - accuracy: 0.8408 - val_loss: 0.3625 - val_accuracy: 0.8396\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 784us/step - loss: 0.3568 - accuracy: 0.8416 - val_loss: 0.3665 - val_accuracy: 0.8380\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 778us/step - loss: 0.3549 - accuracy: 0.8437 - val_loss: 0.3477 - val_accuracy: 0.8444\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 908us/step - loss: 0.3450 - accuracy: 0.8490 - val_loss: 0.3532 - val_accuracy: 0.8424\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3353 - accuracy: 0.8526 - val_loss: 0.3501 - val_accuracy: 0.8440\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 948us/step - loss: 0.3452 - accuracy: 0.8533 - val_loss: 0.3508 - val_accuracy: 0.8468\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 780us/step - loss: 0.3495 - accuracy: 0.8465 - val_loss: 0.3441 - val_accuracy: 0.8462\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 772us/step - loss: 0.3488 - accuracy: 0.8439 - val_loss: 0.3414 - val_accuracy: 0.8480\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 927us/step - loss: 0.3386 - accuracy: 0.8529 - val_loss: 0.3646 - val_accuracy: 0.8406\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 780us/step - loss: 0.3509 - accuracy: 0.8436 - val_loss: 0.3472 - val_accuracy: 0.8454\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 782us/step - loss: 0.3393 - accuracy: 0.8543 - val_loss: 0.3794 - val_accuracy: 0.8422\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 790us/step - loss: 0.3389 - accuracy: 0.8505 - val_loss: 0.3441 - val_accuracy: 0.8478\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 793us/step - loss: 0.3329 - accuracy: 0.8549 - val_loss: 0.3488 - val_accuracy: 0.8462\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 918us/step - loss: 0.3320 - accuracy: 0.8524 - val_loss: 0.3452 - val_accuracy: 0.8474\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3343 - accuracy: 0.8540 - val_loss: 0.3469 - val_accuracy: 0.8478\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 2s 956us/step - loss: 0.3298 - accuracy: 0.8561 - val_loss: 0.3403 - val_accuracy: 0.8500\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 804us/step - loss: 0.3291 - accuracy: 0.8557 - val_loss: 0.3377 - val_accuracy: 0.8486\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 821us/step - loss: 0.3365 - accuracy: 0.8559 - val_loss: 0.3401 - val_accuracy: 0.8460\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 911us/step - loss: 0.3306 - accuracy: 0.8558 - val_loss: 0.3426 - val_accuracy: 0.8476\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 779us/step - loss: 0.3311 - accuracy: 0.8554 - val_loss: 0.3383 - val_accuracy: 0.8498\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 763us/step - loss: 0.3386 - accuracy: 0.8561 - val_loss: 0.3425 - val_accuracy: 0.8512\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 812us/step - loss: 0.3299 - accuracy: 0.8593 - val_loss: 0.3375 - val_accuracy: 0.8508\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3286 - accuracy: 0.8606 - val_loss: 0.3396 - val_accuracy: 0.8474\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.8545 - val_loss: 0.3631 - val_accuracy: 0.8464\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 793us/step - loss: 0.3334 - accuracy: 0.8581 - val_loss: 0.3416 - val_accuracy: 0.8504\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 777us/step - loss: 0.3416 - accuracy: 0.8523 - val_loss: 0.3951 - val_accuracy: 0.8454\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 765us/step - loss: 0.3416 - accuracy: 0.8551 - val_loss: 0.3519 - val_accuracy: 0.8472\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 765us/step - loss: 0.3393 - accuracy: 0.8550 - val_loss: 0.3556 - val_accuracy: 0.8460\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 899us/step - loss: 0.3339 - accuracy: 0.8612 - val_loss: 0.3573 - val_accuracy: 0.8462\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 818us/step - loss: 0.3334 - accuracy: 0.8555 - val_loss: 0.3474 - val_accuracy: 0.8488\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3452 - accuracy: 0.8540 - val_loss: 0.3539 - val_accuracy: 0.8462\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3396 - accuracy: 0.8568 - val_loss: 0.3681 - val_accuracy: 0.8396\n",
      "400/400 [==============================] - 0s 732us/step - loss: 0.3296 - accuracy: 0.8560\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4393 - accuracy: 0.7877 - val_loss: 0.3730 - val_accuracy: 0.8200\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 770us/step - loss: 0.3736 - accuracy: 0.8260 - val_loss: 0.3732 - val_accuracy: 0.8340\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 772us/step - loss: 0.3638 - accuracy: 0.8382 - val_loss: 0.3695 - val_accuracy: 0.8370\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 793us/step - loss: 0.3644 - accuracy: 0.8425 - val_loss: 0.3631 - val_accuracy: 0.8392\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 775us/step - loss: 0.3582 - accuracy: 0.8402 - val_loss: 0.3942 - val_accuracy: 0.8188\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 793us/step - loss: 0.3513 - accuracy: 0.8447 - val_loss: 0.3531 - val_accuracy: 0.8418\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 977us/step - loss: 0.3520 - accuracy: 0.8469 - val_loss: 0.3486 - val_accuracy: 0.8448\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3417 - accuracy: 0.8541 - val_loss: 0.3539 - val_accuracy: 0.8416\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 2s 973us/step - loss: 0.3451 - accuracy: 0.8484 - val_loss: 0.3552 - val_accuracy: 0.8334\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 812us/step - loss: 0.3340 - accuracy: 0.8572 - val_loss: 0.3524 - val_accuracy: 0.8422\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 782us/step - loss: 0.3383 - accuracy: 0.8531 - val_loss: 0.3574 - val_accuracy: 0.8404\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 794us/step - loss: 0.3388 - accuracy: 0.8532 - val_loss: 0.3459 - val_accuracy: 0.8444\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 777us/step - loss: 0.3350 - accuracy: 0.8548 - val_loss: 0.3499 - val_accuracy: 0.8442\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 778us/step - loss: 0.3397 - accuracy: 0.8500 - val_loss: 0.3643 - val_accuracy: 0.8416\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 796us/step - loss: 0.3328 - accuracy: 0.8501 - val_loss: 0.3613 - val_accuracy: 0.8412\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3439 - accuracy: 0.8518 - val_loss: 0.3542 - val_accuracy: 0.8440\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3440 - accuracy: 0.8517 - val_loss: 0.3514 - val_accuracy: 0.8442\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 765us/step - loss: 0.3326 - accuracy: 0.8560 - val_loss: 0.3481 - val_accuracy: 0.8474\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3354 - accuracy: 0.8580 - val_loss: 0.3446 - val_accuracy: 0.8442\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 795us/step - loss: 0.3341 - accuracy: 0.8559 - val_loss: 0.3429 - val_accuracy: 0.8440\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3410 - accuracy: 0.8485 - val_loss: 0.3417 - val_accuracy: 0.8476\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3262 - accuracy: 0.8570 - val_loss: 0.3522 - val_accuracy: 0.8422\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 767us/step - loss: 0.3289 - accuracy: 0.8569 - val_loss: 0.3397 - val_accuracy: 0.8464\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3280 - accuracy: 0.8581 - val_loss: 0.3483 - val_accuracy: 0.8458\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3433 - accuracy: 0.8540 - val_loss: 0.3558 - val_accuracy: 0.8448\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 857us/step - loss: 0.3358 - accuracy: 0.8555 - val_loss: 0.4331 - val_accuracy: 0.8110\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3361 - accuracy: 0.8520 - val_loss: 0.3551 - val_accuracy: 0.8422\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 776us/step - loss: 0.3303 - accuracy: 0.8578 - val_loss: 0.3546 - val_accuracy: 0.8442\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 905us/step - loss: 0.3379 - accuracy: 0.8562 - val_loss: 0.3579 - val_accuracy: 0.8400\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.8587 - val_loss: 0.3764 - val_accuracy: 0.8362\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 776us/step - loss: 0.3433 - accuracy: 0.8490 - val_loss: 0.3538 - val_accuracy: 0.8416\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 805us/step - loss: 0.3352 - accuracy: 0.8560 - val_loss: 0.3576 - val_accuracy: 0.8408\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3364 - accuracy: 0.8581 - val_loss: 0.3664 - val_accuracy: 0.8460\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3399 - accuracy: 0.8503\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 3s 1ms/step - loss: 0.4394 - accuracy: 0.7928 - val_loss: 0.3753 - val_accuracy: 0.8348\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 783us/step - loss: 0.3643 - accuracy: 0.8324 - val_loss: 0.3691 - val_accuracy: 0.8338\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3591 - accuracy: 0.8414 - val_loss: 0.3828 - val_accuracy: 0.8352\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3568 - accuracy: 0.8394 - val_loss: 0.3600 - val_accuracy: 0.8416\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 765us/step - loss: 0.3662 - accuracy: 0.8418 - val_loss: 0.3682 - val_accuracy: 0.8400\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3596 - accuracy: 0.8401 - val_loss: 0.3605 - val_accuracy: 0.8398\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3584 - accuracy: 0.8391 - val_loss: 0.3645 - val_accuracy: 0.8432\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3490 - accuracy: 0.8462 - val_loss: 0.3535 - val_accuracy: 0.8390\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3482 - accuracy: 0.8498 - val_loss: 0.3544 - val_accuracy: 0.8380\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 783us/step - loss: 0.3526 - accuracy: 0.8413 - val_loss: 0.3704 - val_accuracy: 0.8396\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 751us/step - loss: 0.3475 - accuracy: 0.8488 - val_loss: 0.3498 - val_accuracy: 0.8454\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3475 - accuracy: 0.8450 - val_loss: 0.3449 - val_accuracy: 0.8454\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3494 - accuracy: 0.8450 - val_loss: 0.3712 - val_accuracy: 0.8356\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 775us/step - loss: 0.3535 - accuracy: 0.8478 - val_loss: 0.3515 - val_accuracy: 0.8438\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 887us/step - loss: 0.3468 - accuracy: 0.8476 - val_loss: 0.3503 - val_accuracy: 0.8424\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3390 - accuracy: 0.8535 - val_loss: 0.3577 - val_accuracy: 0.8394\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 2s 962us/step - loss: 0.3462 - accuracy: 0.8482 - val_loss: 0.3453 - val_accuracy: 0.8470\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3387 - accuracy: 0.8563 - val_loss: 0.3456 - val_accuracy: 0.8464\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3429 - accuracy: 0.8522 - val_loss: 0.3517 - val_accuracy: 0.8448\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3453 - accuracy: 0.8526 - val_loss: 0.3465 - val_accuracy: 0.8458\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 850us/step - loss: 0.3408 - accuracy: 0.8533 - val_loss: 0.3478 - val_accuracy: 0.8448\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 847us/step - loss: 0.3392 - accuracy: 0.8539 - val_loss: 0.3612 - val_accuracy: 0.8420\n",
      "400/400 [==============================] - 0s 802us/step - loss: 0.3486 - accuracy: 0.8445\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 797us/step - loss: 0.4408 - accuracy: 0.7943 - val_loss: 0.3730 - val_accuracy: 0.8206\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 843us/step - loss: 0.3700 - accuracy: 0.8306 - val_loss: 0.3656 - val_accuracy: 0.8346\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 869us/step - loss: 0.3600 - accuracy: 0.8396 - val_loss: 0.3711 - val_accuracy: 0.8374\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3620 - accuracy: 0.8380 - val_loss: 0.3597 - val_accuracy: 0.8368\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3539 - accuracy: 0.8425 - val_loss: 0.3667 - val_accuracy: 0.8404\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 746us/step - loss: 0.3491 - accuracy: 0.8489 - val_loss: 0.3619 - val_accuracy: 0.8402\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3503 - accuracy: 0.8465 - val_loss: 0.3516 - val_accuracy: 0.8416\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 764us/step - loss: 0.3518 - accuracy: 0.8423 - val_loss: 0.3533 - val_accuracy: 0.8446\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 848us/step - loss: 0.3434 - accuracy: 0.8488 - val_loss: 0.3548 - val_accuracy: 0.8444\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3372 - accuracy: 0.8533 - val_loss: 0.3434 - val_accuracy: 0.8464\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 816us/step - loss: 0.3394 - accuracy: 0.8525 - val_loss: 0.3482 - val_accuracy: 0.8424\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3401 - accuracy: 0.8504 - val_loss: 0.3514 - val_accuracy: 0.8448\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3358 - accuracy: 0.8562 - val_loss: 0.3477 - val_accuracy: 0.8440\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 773us/step - loss: 0.3398 - accuracy: 0.8486 - val_loss: 0.3432 - val_accuracy: 0.8460\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 772us/step - loss: 0.3410 - accuracy: 0.8519 - val_loss: 0.3499 - val_accuracy: 0.8470\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3414 - accuracy: 0.8525 - val_loss: 0.3557 - val_accuracy: 0.8380\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 773us/step - loss: 0.3310 - accuracy: 0.8581 - val_loss: 0.3442 - val_accuracy: 0.8482\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3386 - accuracy: 0.8542 - val_loss: 0.3507 - val_accuracy: 0.8460\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3325 - accuracy: 0.8567 - val_loss: 0.3487 - val_accuracy: 0.8432\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 949us/step - loss: 0.3431 - accuracy: 0.8522 - val_loss: 0.3435 - val_accuracy: 0.8452\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 856us/step - loss: 0.3393 - accuracy: 0.8566 - val_loss: 0.3423 - val_accuracy: 0.8472\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3343 - accuracy: 0.8536 - val_loss: 0.3482 - val_accuracy: 0.8476\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3318 - accuracy: 0.8578 - val_loss: 0.3630 - val_accuracy: 0.8462\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3260 - accuracy: 0.8602 - val_loss: 0.3615 - val_accuracy: 0.8448\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 2s 989us/step - loss: 0.3348 - accuracy: 0.8543 - val_loss: 0.3486 - val_accuracy: 0.8448\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3355 - accuracy: 0.8553 - val_loss: 0.3420 - val_accuracy: 0.8496\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3341 - accuracy: 0.8562 - val_loss: 0.3516 - val_accuracy: 0.8490\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 776us/step - loss: 0.3418 - accuracy: 0.8547 - val_loss: 0.3496 - val_accuracy: 0.8460\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3372 - accuracy: 0.8569 - val_loss: 0.3635 - val_accuracy: 0.8426\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 767us/step - loss: 0.3344 - accuracy: 0.8561 - val_loss: 0.3488 - val_accuracy: 0.8460\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 749us/step - loss: 0.3242 - accuracy: 0.8629 - val_loss: 0.3601 - val_accuracy: 0.8456\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 908us/step - loss: 0.3320 - accuracy: 0.8614 - val_loss: 0.3746 - val_accuracy: 0.8462\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3390 - accuracy: 0.8565 - val_loss: 0.3471 - val_accuracy: 0.8468\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3287 - accuracy: 0.8627 - val_loss: 0.3606 - val_accuracy: 0.8462\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 820us/step - loss: 0.3378 - accuracy: 0.8589 - val_loss: 0.3600 - val_accuracy: 0.8440\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 785us/step - loss: 0.3369 - accuracy: 0.8587 - val_loss: 0.3513 - val_accuracy: 0.8456\n",
      "400/400 [==============================] - 0s 747us/step - loss: 0.3459 - accuracy: 0.8440\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 816us/step - loss: 0.4793 - accuracy: 0.7749 - val_loss: 0.3770 - val_accuracy: 0.8120\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3735 - accuracy: 0.8223 - val_loss: 0.3693 - val_accuracy: 0.8318\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3666 - accuracy: 0.8284 - val_loss: 0.3673 - val_accuracy: 0.8234\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 896us/step - loss: 0.3528 - accuracy: 0.8361 - val_loss: 0.3628 - val_accuracy: 0.8262\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3645 - accuracy: 0.8311 - val_loss: 0.3604 - val_accuracy: 0.8348\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3496 - accuracy: 0.8393 - val_loss: 0.3588 - val_accuracy: 0.8324\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3494 - accuracy: 0.8417 - val_loss: 0.3573 - val_accuracy: 0.8356\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3545 - accuracy: 0.8391 - val_loss: 0.3562 - val_accuracy: 0.8344\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3490 - accuracy: 0.8407 - val_loss: 0.3551 - val_accuracy: 0.8368\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3553 - accuracy: 0.8389 - val_loss: 0.3547 - val_accuracy: 0.8364\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3516 - accuracy: 0.8377 - val_loss: 0.3546 - val_accuracy: 0.8394\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3534 - accuracy: 0.8376 - val_loss: 0.3516 - val_accuracy: 0.8392\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3494 - accuracy: 0.8421 - val_loss: 0.3498 - val_accuracy: 0.8420\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3521 - accuracy: 0.8412 - val_loss: 0.3498 - val_accuracy: 0.8428\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 683us/step - loss: 0.3482 - accuracy: 0.8445 - val_loss: 0.3483 - val_accuracy: 0.8436\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3441 - accuracy: 0.8450 - val_loss: 0.3478 - val_accuracy: 0.8432\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3372 - accuracy: 0.8496 - val_loss: 0.3504 - val_accuracy: 0.8454\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3511 - accuracy: 0.8446 - val_loss: 0.3483 - val_accuracy: 0.8416\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 996us/step - loss: 0.3415 - accuracy: 0.8503 - val_loss: 0.3469 - val_accuracy: 0.8450\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3471 - accuracy: 0.8428 - val_loss: 0.3470 - val_accuracy: 0.8460\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 972us/step - loss: 0.3435 - accuracy: 0.8499 - val_loss: 0.3473 - val_accuracy: 0.8418\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 655us/step - loss: 0.3380 - accuracy: 0.8457 - val_loss: 0.3479 - val_accuracy: 0.8414\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3463 - accuracy: 0.8462 - val_loss: 0.3471 - val_accuracy: 0.8420\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3471 - accuracy: 0.8425 - val_loss: 0.3465 - val_accuracy: 0.8446\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3447 - accuracy: 0.8476 - val_loss: 0.3473 - val_accuracy: 0.8428\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3439 - accuracy: 0.8476 - val_loss: 0.3471 - val_accuracy: 0.8426\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3375 - accuracy: 0.8504 - val_loss: 0.3458 - val_accuracy: 0.8476\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py\", line 223, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py\", line 166, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1145, in fit\n",
      "    callbacks.on_epoch_end(epoch, epoch_logs)\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 428, in on_epoch_end\n",
      "    callback.on_epoch_end(epoch, logs)\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 1344, in on_epoch_end\n",
      "    self._save_model(epoch=epoch, logs=logs)\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 1418, in _save_model\n",
      "    raise e\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 1408, in _save_model\n",
      "    self.model.save(filepath, overwrite=True, options=self._options)\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 2001, in save\n",
      "    save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\", line 153, in save_model\n",
      "    hdf5_format.save_model_to_hdf5(\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\", line 108, in save_model_to_hdf5\n",
      "    f = h5py.File(filepath, mode='w')\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\", line 406, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size,\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\", line 179, in make_fid\n",
      "    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)\n",
      "  File \"h5py\\_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py\\_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py\\h5f.pyx\", line 108, in h5py.h5f.create\n",
      "OSError: Unable to create file (unable to open file: name = 'Checkpoints\\ANN_1000ep_ES_CV.h5', errno = 13, error message = 'Permission denied', flags = 13, o_flags = 302)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 3s 1ms/step - loss: 0.4776 - accuracy: 0.7809 - val_loss: 0.3767 - val_accuracy: 0.8228\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3722 - accuracy: 0.8262 - val_loss: 0.3673 - val_accuracy: 0.8256\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3669 - accuracy: 0.8347 - val_loss: 0.3663 - val_accuracy: 0.8236\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3634 - accuracy: 0.8338 - val_loss: 0.3620 - val_accuracy: 0.8294\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3502 - accuracy: 0.8412 - val_loss: 0.3594 - val_accuracy: 0.8342\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3466 - accuracy: 0.8390 - val_loss: 0.3584 - val_accuracy: 0.8318\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3509 - accuracy: 0.8384 - val_loss: 0.3581 - val_accuracy: 0.8376\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3444 - accuracy: 0.8456 - val_loss: 0.3568 - val_accuracy: 0.8344\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3539 - accuracy: 0.8385 - val_loss: 0.3575 - val_accuracy: 0.8334\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3578 - accuracy: 0.8394 - val_loss: 0.3565 - val_accuracy: 0.8380\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 819us/step - loss: 0.3485 - accuracy: 0.8443 - val_loss: 0.3535 - val_accuracy: 0.8370\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3520 - accuracy: 0.8409 - val_loss: 0.3541 - val_accuracy: 0.8384\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3497 - accuracy: 0.8402 - val_loss: 0.3515 - val_accuracy: 0.8408\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3450 - accuracy: 0.8459 - val_loss: 0.3515 - val_accuracy: 0.8430\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3440 - accuracy: 0.8470 - val_loss: 0.3526 - val_accuracy: 0.8378\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3386 - accuracy: 0.8495 - val_loss: 0.3498 - val_accuracy: 0.8452\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 861us/step - loss: 0.3400 - accuracy: 0.8481 - val_loss: 0.3491 - val_accuracy: 0.8434\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3424 - accuracy: 0.8483 - val_loss: 0.3517 - val_accuracy: 0.8454\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3441 - accuracy: 0.8483 - val_loss: 0.3491 - val_accuracy: 0.8444\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3338 - accuracy: 0.8521 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3372 - accuracy: 0.8518 - val_loss: 0.3481 - val_accuracy: 0.8426\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 971us/step - loss: 0.3435 - accuracy: 0.8477 - val_loss: 0.3478 - val_accuracy: 0.8438\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3336 - accuracy: 0.8522 - val_loss: 0.3470 - val_accuracy: 0.8452\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 2s 949us/step - loss: 0.3545 - accuracy: 0.8383 - val_loss: 0.3491 - val_accuracy: 0.8408\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3374 - accuracy: 0.8526 - val_loss: 0.3472 - val_accuracy: 0.8438\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 723us/step - loss: 0.3345 - accuracy: 0.8536 - val_loss: 0.3473 - val_accuracy: 0.8434\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 787us/step - loss: 0.3423 - accuracy: 0.8529 - val_loss: 0.3492 - val_accuracy: 0.8400\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3476 - accuracy: 0.8450 - val_loss: 0.3475 - val_accuracy: 0.8438\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3401 - accuracy: 0.8511 - val_loss: 0.3469 - val_accuracy: 0.8442\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 864us/step - loss: 0.3445 - accuracy: 0.8484 - val_loss: 0.3477 - val_accuracy: 0.8440\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3411 - accuracy: 0.8514 - val_loss: 0.3466 - val_accuracy: 0.8448\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3440 - accuracy: 0.8449 - val_loss: 0.3473 - val_accuracy: 0.8432\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 800us/step - loss: 0.3416 - accuracy: 0.8477 - val_loss: 0.3476 - val_accuracy: 0.8480\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3371 - accuracy: 0.8511 - val_loss: 0.3481 - val_accuracy: 0.8422\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3464 - accuracy: 0.8456 - val_loss: 0.3470 - val_accuracy: 0.8452\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3405 - accuracy: 0.8489 - val_loss: 0.3475 - val_accuracy: 0.8426\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3454 - accuracy: 0.8481 - val_loss: 0.3476 - val_accuracy: 0.8428\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3393 - accuracy: 0.8543 - val_loss: 0.3466 - val_accuracy: 0.8444\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3469 - accuracy: 0.8466 - val_loss: 0.3481 - val_accuracy: 0.8434\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 806us/step - loss: 0.3400 - accuracy: 0.8473 - val_loss: 0.3473 - val_accuracy: 0.8432\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3407 - accuracy: 0.8503 - val_loss: 0.3480 - val_accuracy: 0.8482\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3354 - accuracy: 0.8533 - val_loss: 0.3476 - val_accuracy: 0.8448\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3517 - accuracy: 0.8445 - val_loss: 0.3475 - val_accuracy: 0.8484\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3379 - accuracy: 0.8519 - val_loss: 0.3470 - val_accuracy: 0.8464\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3485 - accuracy: 0.8479 - val_loss: 0.3476 - val_accuracy: 0.8442\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3470 - accuracy: 0.8477 - val_loss: 0.3498 - val_accuracy: 0.8430\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3390 - accuracy: 0.8494 - val_loss: 0.3472 - val_accuracy: 0.8468\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3345 - accuracy: 0.8546 - val_loss: 0.3503 - val_accuracy: 0.8424\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3419 - accuracy: 0.8503\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 782us/step - loss: 0.4764 - accuracy: 0.7823 - val_loss: 0.3774 - val_accuracy: 0.8118\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3687 - accuracy: 0.8251 - val_loss: 0.3663 - val_accuracy: 0.8244\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3680 - accuracy: 0.8281 - val_loss: 0.3628 - val_accuracy: 0.8296\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3610 - accuracy: 0.8315 - val_loss: 0.3602 - val_accuracy: 0.8324\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 836us/step - loss: 0.3595 - accuracy: 0.8357 - val_loss: 0.3604 - val_accuracy: 0.8352\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3570 - accuracy: 0.8381 - val_loss: 0.3596 - val_accuracy: 0.8312\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3542 - accuracy: 0.8392 - val_loss: 0.3562 - val_accuracy: 0.8350\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 886us/step - loss: 0.3518 - accuracy: 0.8401 - val_loss: 0.3548 - val_accuracy: 0.8368\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3521 - accuracy: 0.8418 - val_loss: 0.3534 - val_accuracy: 0.8384\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3456 - accuracy: 0.8416 - val_loss: 0.3535 - val_accuracy: 0.8372\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3481 - accuracy: 0.8461 - val_loss: 0.3574 - val_accuracy: 0.8330\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 735us/step - loss: 0.3428 - accuracy: 0.8461 - val_loss: 0.3511 - val_accuracy: 0.8384\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3472 - accuracy: 0.8451 - val_loss: 0.3494 - val_accuracy: 0.8400\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3435 - accuracy: 0.8474 - val_loss: 0.3503 - val_accuracy: 0.8404\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3458 - accuracy: 0.8451 - val_loss: 0.3480 - val_accuracy: 0.8458\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3439 - accuracy: 0.8431 - val_loss: 0.3480 - val_accuracy: 0.8428\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 683us/step - loss: 0.3429 - accuracy: 0.8493 - val_loss: 0.3488 - val_accuracy: 0.8440\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 835us/step - loss: 0.3506 - accuracy: 0.8425 - val_loss: 0.3474 - val_accuracy: 0.8428\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3399 - accuracy: 0.8496 - val_loss: 0.3465 - val_accuracy: 0.8442\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3494 - accuracy: 0.8420 - val_loss: 0.3493 - val_accuracy: 0.8414\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 828us/step - loss: 0.3445 - accuracy: 0.8485 - val_loss: 0.3477 - val_accuracy: 0.8434\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3277 - accuracy: 0.8543 - val_loss: 0.3464 - val_accuracy: 0.8436\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3400 - accuracy: 0.8512 - val_loss: 0.3466 - val_accuracy: 0.8440\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3414 - accuracy: 0.8520 - val_loss: 0.3503 - val_accuracy: 0.8402\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 752us/step - loss: 0.3455 - accuracy: 0.8466 - val_loss: 0.3473 - val_accuracy: 0.8450\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3435 - accuracy: 0.8484 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3351 - accuracy: 0.8528 - val_loss: 0.3468 - val_accuracy: 0.8450\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3465 - accuracy: 0.8463 - val_loss: 0.3474 - val_accuracy: 0.8442\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3321 - accuracy: 0.8556 - val_loss: 0.3474 - val_accuracy: 0.8456\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3393 - accuracy: 0.8496 - val_loss: 0.3479 - val_accuracy: 0.8442\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3367 - accuracy: 0.8533 - val_loss: 0.3493 - val_accuracy: 0.8426\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3457 - accuracy: 0.8438 - val_loss: 0.3504 - val_accuracy: 0.8440\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3475 - accuracy: 0.8462\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4803 - accuracy: 0.7833 - val_loss: 0.3738 - val_accuracy: 0.8228\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 693us/step - loss: 0.3664 - accuracy: 0.8276 - val_loss: 0.3677 - val_accuracy: 0.8236\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3693 - accuracy: 0.8259 - val_loss: 0.3636 - val_accuracy: 0.8276\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 688us/step - loss: 0.3538 - accuracy: 0.8370 - val_loss: 0.3623 - val_accuracy: 0.8270\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3629 - accuracy: 0.8344 - val_loss: 0.3594 - val_accuracy: 0.8342\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3560 - accuracy: 0.8382 - val_loss: 0.3582 - val_accuracy: 0.8320\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3621 - accuracy: 0.8341 - val_loss: 0.3583 - val_accuracy: 0.8364\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 838us/step - loss: 0.3564 - accuracy: 0.8399 - val_loss: 0.3568 - val_accuracy: 0.8356\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3527 - accuracy: 0.8437 - val_loss: 0.3540 - val_accuracy: 0.8374\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 676us/step - loss: 0.3516 - accuracy: 0.8453 - val_loss: 0.3539 - val_accuracy: 0.8364\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 782us/step - loss: 0.3510 - accuracy: 0.8403 - val_loss: 0.3521 - val_accuracy: 0.8388\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 764us/step - loss: 0.3449 - accuracy: 0.8449 - val_loss: 0.3506 - val_accuracy: 0.8384\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3493 - accuracy: 0.8435 - val_loss: 0.3533 - val_accuracy: 0.8414\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3454 - accuracy: 0.8487 - val_loss: 0.3497 - val_accuracy: 0.8396\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 855us/step - loss: 0.3473 - accuracy: 0.8462 - val_loss: 0.3485 - val_accuracy: 0.8426\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3412 - accuracy: 0.8543 - val_loss: 0.3482 - val_accuracy: 0.8444\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3399 - accuracy: 0.8477 - val_loss: 0.3506 - val_accuracy: 0.8398\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3399 - accuracy: 0.8498 - val_loss: 0.3504 - val_accuracy: 0.8386\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3386 - accuracy: 0.8517 - val_loss: 0.3487 - val_accuracy: 0.8476\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3389 - accuracy: 0.8499 - val_loss: 0.3474 - val_accuracy: 0.8432\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3458 - accuracy: 0.8451 - val_loss: 0.3467 - val_accuracy: 0.8440\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3411 - accuracy: 0.8500 - val_loss: 0.3477 - val_accuracy: 0.8442\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3394 - accuracy: 0.8474 - val_loss: 0.3467 - val_accuracy: 0.8450\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3392 - accuracy: 0.8500 - val_loss: 0.3488 - val_accuracy: 0.8420\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 915us/step - loss: 0.3383 - accuracy: 0.8488 - val_loss: 0.3474 - val_accuracy: 0.8436\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3501 - accuracy: 0.8444 - val_loss: 0.3467 - val_accuracy: 0.8448\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3433 - accuracy: 0.8468 - val_loss: 0.3473 - val_accuracy: 0.8430\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 768us/step - loss: 0.3400 - accuracy: 0.8510 - val_loss: 0.3475 - val_accuracy: 0.8430\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3455 - accuracy: 0.8460 - val_loss: 0.3483 - val_accuracy: 0.8486\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3382 - accuracy: 0.8508 - val_loss: 0.3474 - val_accuracy: 0.8436\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 788us/step - loss: 0.3436 - accuracy: 0.8460 - val_loss: 0.3469 - val_accuracy: 0.8458\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3416 - accuracy: 0.8490 - val_loss: 0.3469 - val_accuracy: 0.8438\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.3357 - accuracy: 0.8531 - val_loss: 0.3476 - val_accuracy: 0.8442\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.3372 - accuracy: 0.8546 - val_loss: 0.3464 - val_accuracy: 0.8446\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 731us/step - loss: 0.3384 - accuracy: 0.8486 - val_loss: 0.3464 - val_accuracy: 0.8470\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3372 - accuracy: 0.8484 - val_loss: 0.3465 - val_accuracy: 0.8460\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 683us/step - loss: 0.3464 - accuracy: 0.8490 - val_loss: 0.3469 - val_accuracy: 0.8452\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 2s 977us/step - loss: 0.3423 - accuracy: 0.8493 - val_loss: 0.3469 - val_accuracy: 0.8434\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3363 - accuracy: 0.8523 - val_loss: 0.3467 - val_accuracy: 0.8438\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 929us/step - loss: 0.3458 - accuracy: 0.8483 - val_loss: 0.3475 - val_accuracy: 0.8478\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3372 - accuracy: 0.8496 - val_loss: 0.3476 - val_accuracy: 0.8468\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3450 - accuracy: 0.8472 - val_loss: 0.3465 - val_accuracy: 0.8466\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.3455 - accuracy: 0.8474 - val_loss: 0.3491 - val_accuracy: 0.8460\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3455 - accuracy: 0.8475 - val_loss: 0.3473 - val_accuracy: 0.8466\n",
      "400/400 [==============================] - 0s 687us/step - loss: 0.3428 - accuracy: 0.8478\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4718 - accuracy: 0.7870 - val_loss: 0.3754 - val_accuracy: 0.8176\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3731 - accuracy: 0.8270 - val_loss: 0.3673 - val_accuracy: 0.8276\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3593 - accuracy: 0.8370 - val_loss: 0.3649 - val_accuracy: 0.8328\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 752us/step - loss: 0.3568 - accuracy: 0.8358 - val_loss: 0.3629 - val_accuracy: 0.8304\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3536 - accuracy: 0.8437 - val_loss: 0.3608 - val_accuracy: 0.8348\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3531 - accuracy: 0.8420 - val_loss: 0.3598 - val_accuracy: 0.8376\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 668us/step - loss: 0.3536 - accuracy: 0.8407 - val_loss: 0.3573 - val_accuracy: 0.8346\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3447 - accuracy: 0.8457 - val_loss: 0.3555 - val_accuracy: 0.8338\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 873us/step - loss: 0.3527 - accuracy: 0.8427 - val_loss: 0.3551 - val_accuracy: 0.8346\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 735us/step - loss: 0.3408 - accuracy: 0.8486 - val_loss: 0.3535 - val_accuracy: 0.8390\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3422 - accuracy: 0.8496 - val_loss: 0.3557 - val_accuracy: 0.8386\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 837us/step - loss: 0.3484 - accuracy: 0.8455 - val_loss: 0.3533 - val_accuracy: 0.8378\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3429 - accuracy: 0.8512 - val_loss: 0.3512 - val_accuracy: 0.8396\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 958us/step - loss: 0.3497 - accuracy: 0.8450 - val_loss: 0.3514 - val_accuracy: 0.8406\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3410 - accuracy: 0.8512 - val_loss: 0.3493 - val_accuracy: 0.8436\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3394 - accuracy: 0.8513 - val_loss: 0.3483 - val_accuracy: 0.8424\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3387 - accuracy: 0.8524 - val_loss: 0.3478 - val_accuracy: 0.8420\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3383 - accuracy: 0.8500 - val_loss: 0.3486 - val_accuracy: 0.8412\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 683us/step - loss: 0.3424 - accuracy: 0.8478 - val_loss: 0.3480 - val_accuracy: 0.8440\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3408 - accuracy: 0.8474 - val_loss: 0.3484 - val_accuracy: 0.8454\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3311 - accuracy: 0.8533 - val_loss: 0.3460 - val_accuracy: 0.8450\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3363 - accuracy: 0.8549 - val_loss: 0.3460 - val_accuracy: 0.8460\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 780us/step - loss: 0.3420 - accuracy: 0.8502 - val_loss: 0.3475 - val_accuracy: 0.8436\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3401 - accuracy: 0.8488 - val_loss: 0.3469 - val_accuracy: 0.8438\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3403 - accuracy: 0.8508 - val_loss: 0.3467 - val_accuracy: 0.8450\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3443 - accuracy: 0.8479 - val_loss: 0.3471 - val_accuracy: 0.8458\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3494 - accuracy: 0.8461 - val_loss: 0.3483 - val_accuracy: 0.8460\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 898us/step - loss: 0.3443 - accuracy: 0.8477 - val_loss: 0.3489 - val_accuracy: 0.8428\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3455 - accuracy: 0.8458 - val_loss: 0.3486 - val_accuracy: 0.8428\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3427 - accuracy: 0.8500 - val_loss: 0.3488 - val_accuracy: 0.8436\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 785us/step - loss: 0.3392 - accuracy: 0.8534 - val_loss: 0.3458 - val_accuracy: 0.8450\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3409 - accuracy: 0.8500 - val_loss: 0.3464 - val_accuracy: 0.8458\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3366 - accuracy: 0.8509 - val_loss: 0.3466 - val_accuracy: 0.8432\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 897us/step - loss: 0.3343 - accuracy: 0.8542 - val_loss: 0.3469 - val_accuracy: 0.8438\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3383 - accuracy: 0.8523 - val_loss: 0.3463 - val_accuracy: 0.8470\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3428 - accuracy: 0.8482 - val_loss: 0.3479 - val_accuracy: 0.8442\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3380 - accuracy: 0.8514 - val_loss: 0.3457 - val_accuracy: 0.8464\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3517 - accuracy: 0.8465 - val_loss: 0.3471 - val_accuracy: 0.8472\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 923us/step - loss: 0.3362 - accuracy: 0.8537 - val_loss: 0.3465 - val_accuracy: 0.8460\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3378 - accuracy: 0.8501 - val_loss: 0.3464 - val_accuracy: 0.8454\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 817us/step - loss: 0.3384 - accuracy: 0.8543 - val_loss: 0.3473 - val_accuracy: 0.8436\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3382 - accuracy: 0.8535 - val_loss: 0.3480 - val_accuracy: 0.8466\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3394 - accuracy: 0.8503 - val_loss: 0.3487 - val_accuracy: 0.8436\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 2s 938us/step - loss: 0.3371 - accuracy: 0.8510 - val_loss: 0.3468 - val_accuracy: 0.8464\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3384 - accuracy: 0.8498 - val_loss: 0.3495 - val_accuracy: 0.8470\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 2s 964us/step - loss: 0.3354 - accuracy: 0.8529 - val_loss: 0.3463 - val_accuracy: 0.8464\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3396 - accuracy: 0.8520 - val_loss: 0.3471 - val_accuracy: 0.8436\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3509 - accuracy: 0.8438\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 989us/step - loss: 0.4681 - accuracy: 0.7800 - val_loss: 0.3740 - val_accuracy: 0.8232\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3741 - accuracy: 0.8227 - val_loss: 0.3684 - val_accuracy: 0.8218\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 759us/step - loss: 0.3713 - accuracy: 0.8257 - val_loss: 0.3647 - val_accuracy: 0.8304\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3610 - accuracy: 0.8335 - val_loss: 0.3622 - val_accuracy: 0.8322\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 879us/step - loss: 0.3563 - accuracy: 0.8361 - val_loss: 0.3618 - val_accuracy: 0.8286\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 958us/step - loss: 0.3598 - accuracy: 0.8340 - val_loss: 0.3587 - val_accuracy: 0.8336\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3451 - accuracy: 0.8444 - val_loss: 0.3568 - val_accuracy: 0.8350\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 775us/step - loss: 0.3521 - accuracy: 0.8411 - val_loss: 0.3560 - val_accuracy: 0.8350\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3518 - accuracy: 0.8397 - val_loss: 0.3543 - val_accuracy: 0.8360\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3432 - accuracy: 0.8487 - val_loss: 0.3541 - val_accuracy: 0.8360\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3474 - accuracy: 0.8435 - val_loss: 0.3517 - val_accuracy: 0.8388\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 759us/step - loss: 0.3505 - accuracy: 0.8427 - val_loss: 0.3502 - val_accuracy: 0.8410\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3480 - accuracy: 0.8433 - val_loss: 0.3516 - val_accuracy: 0.8404\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 723us/step - loss: 0.3485 - accuracy: 0.8436 - val_loss: 0.3527 - val_accuracy: 0.8392\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 798us/step - loss: 0.3414 - accuracy: 0.8483 - val_loss: 0.3510 - val_accuracy: 0.8444\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3440 - accuracy: 0.8467 - val_loss: 0.3488 - val_accuracy: 0.8424\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3478 - accuracy: 0.8460 - val_loss: 0.3480 - val_accuracy: 0.8408\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3435 - accuracy: 0.8465 - val_loss: 0.3469 - val_accuracy: 0.8430\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 972us/step - loss: 0.3483 - accuracy: 0.8434 - val_loss: 0.3480 - val_accuracy: 0.8440\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3425 - accuracy: 0.8483 - val_loss: 0.3472 - val_accuracy: 0.8470\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 917us/step - loss: 0.3396 - accuracy: 0.8465 - val_loss: 0.3455 - val_accuracy: 0.8444\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3377 - accuracy: 0.8499 - val_loss: 0.3454 - val_accuracy: 0.8448\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3495 - accuracy: 0.8480 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3417 - accuracy: 0.8482 - val_loss: 0.3464 - val_accuracy: 0.8442\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3433 - accuracy: 0.8469 - val_loss: 0.3465 - val_accuracy: 0.8460\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 2s 949us/step - loss: 0.3460 - accuracy: 0.8445 - val_loss: 0.3461 - val_accuracy: 0.8434\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 769us/step - loss: 0.3380 - accuracy: 0.8523 - val_loss: 0.3448 - val_accuracy: 0.8466\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3469 - accuracy: 0.8458 - val_loss: 0.3479 - val_accuracy: 0.8442\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 922us/step - loss: 0.3412 - accuracy: 0.8519 - val_loss: 0.3456 - val_accuracy: 0.8448\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3464 - accuracy: 0.8480 - val_loss: 0.3472 - val_accuracy: 0.8434\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3441 - accuracy: 0.8480 - val_loss: 0.3499 - val_accuracy: 0.8414\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3404 - accuracy: 0.8490 - val_loss: 0.3465 - val_accuracy: 0.8478\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3350 - accuracy: 0.8528 - val_loss: 0.3463 - val_accuracy: 0.8478\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3395 - accuracy: 0.8505 - val_loss: 0.3449 - val_accuracy: 0.8476\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 879us/step - loss: 0.3476 - accuracy: 0.8466 - val_loss: 0.3465 - val_accuracy: 0.8446\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3413 - accuracy: 0.8521 - val_loss: 0.3454 - val_accuracy: 0.8446\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3436 - accuracy: 0.8501 - val_loss: 0.3484 - val_accuracy: 0.8442\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3358 - accuracy: 0.8508\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 743us/step - loss: 0.4689 - accuracy: 0.7844 - val_loss: 0.3727 - val_accuracy: 0.8250\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3769 - accuracy: 0.8199 - val_loss: 0.3660 - val_accuracy: 0.8248\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3539 - accuracy: 0.8378 - val_loss: 0.3635 - val_accuracy: 0.8246\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 754us/step - loss: 0.3582 - accuracy: 0.8376 - val_loss: 0.3613 - val_accuracy: 0.8308\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3574 - accuracy: 0.8350 - val_loss: 0.3585 - val_accuracy: 0.8340\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3536 - accuracy: 0.8382 - val_loss: 0.3581 - val_accuracy: 0.8342\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 967us/step - loss: 0.3552 - accuracy: 0.8348 - val_loss: 0.3573 - val_accuracy: 0.8364\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3528 - accuracy: 0.8423 - val_loss: 0.3566 - val_accuracy: 0.8332\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 806us/step - loss: 0.3402 - accuracy: 0.8469 - val_loss: 0.3550 - val_accuracy: 0.8372\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3428 - accuracy: 0.8483 - val_loss: 0.3541 - val_accuracy: 0.8380\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3385 - accuracy: 0.8518 - val_loss: 0.3534 - val_accuracy: 0.8358\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3518 - accuracy: 0.8440 - val_loss: 0.3531 - val_accuracy: 0.8388\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3504 - accuracy: 0.8439 - val_loss: 0.3532 - val_accuracy: 0.8374\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3444 - accuracy: 0.8504 - val_loss: 0.3552 - val_accuracy: 0.8354\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3418 - accuracy: 0.8505 - val_loss: 0.3505 - val_accuracy: 0.8406\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3520 - accuracy: 0.8450 - val_loss: 0.3512 - val_accuracy: 0.8390\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 752us/step - loss: 0.3437 - accuracy: 0.8504 - val_loss: 0.3500 - val_accuracy: 0.8446\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3426 - accuracy: 0.8490 - val_loss: 0.3492 - val_accuracy: 0.8448\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.3429 - accuracy: 0.8454 - val_loss: 0.3501 - val_accuracy: 0.8440\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 929us/step - loss: 0.3416 - accuracy: 0.8449 - val_loss: 0.3480 - val_accuracy: 0.8450\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3410 - accuracy: 0.8496 - val_loss: 0.3485 - val_accuracy: 0.8460\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3424 - accuracy: 0.8503 - val_loss: 0.3480 - val_accuracy: 0.8430\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 913us/step - loss: 0.3397 - accuracy: 0.8476 - val_loss: 0.3496 - val_accuracy: 0.8392\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3460 - accuracy: 0.8443 - val_loss: 0.3484 - val_accuracy: 0.8410\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3423 - accuracy: 0.8468 - val_loss: 0.3480 - val_accuracy: 0.8416\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 698us/step - loss: 0.3446 - accuracy: 0.8468 - val_loss: 0.3480 - val_accuracy: 0.8434\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 824us/step - loss: 0.3492 - accuracy: 0.8425 - val_loss: 0.3510 - val_accuracy: 0.8404\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3324 - accuracy: 0.8537 - val_loss: 0.3493 - val_accuracy: 0.8408\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3462 - accuracy: 0.8483 - val_loss: 0.3476 - val_accuracy: 0.8438\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3486 - accuracy: 0.8454 - val_loss: 0.3501 - val_accuracy: 0.8444\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3508 - accuracy: 0.8411 - val_loss: 0.3473 - val_accuracy: 0.8442\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3495 - accuracy: 0.8437 - val_loss: 0.3477 - val_accuracy: 0.8440\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3438 - accuracy: 0.8466 - val_loss: 0.3471 - val_accuracy: 0.8466\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3433 - accuracy: 0.8461 - val_loss: 0.3466 - val_accuracy: 0.8442\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3409 - accuracy: 0.8478 - val_loss: 0.3487 - val_accuracy: 0.8432\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3386 - accuracy: 0.8470 - val_loss: 0.3475 - val_accuracy: 0.8454\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 892us/step - loss: 0.3419 - accuracy: 0.8492 - val_loss: 0.3478 - val_accuracy: 0.8444\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3464 - accuracy: 0.8462 - val_loss: 0.3489 - val_accuracy: 0.8420\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3463 - accuracy: 0.8453 - val_loss: 0.3471 - val_accuracy: 0.8466\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 790us/step - loss: 0.3340 - accuracy: 0.8532 - val_loss: 0.3468 - val_accuracy: 0.8432\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3440 - accuracy: 0.8478 - val_loss: 0.3472 - val_accuracy: 0.8438\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3394 - accuracy: 0.8494 - val_loss: 0.3465 - val_accuracy: 0.8454\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3398 - accuracy: 0.8505 - val_loss: 0.3469 - val_accuracy: 0.8466\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3379 - accuracy: 0.8477 - val_loss: 0.3481 - val_accuracy: 0.8486\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3415 - accuracy: 0.8467 - val_loss: 0.3473 - val_accuracy: 0.8440\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3469 - accuracy: 0.8454 - val_loss: 0.3485 - val_accuracy: 0.8448\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3431 - accuracy: 0.8485 - val_loss: 0.3475 - val_accuracy: 0.8460\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3384 - accuracy: 0.8510 - val_loss: 0.3466 - val_accuracy: 0.8458\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3417 - accuracy: 0.8502 - val_loss: 0.3499 - val_accuracy: 0.8430\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 816us/step - loss: 0.3369 - accuracy: 0.8513 - val_loss: 0.3462 - val_accuracy: 0.8448\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3383 - accuracy: 0.8478 - val_loss: 0.3476 - val_accuracy: 0.8448\n",
      "Epoch 52/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3345 - accuracy: 0.8532 - val_loss: 0.3483 - val_accuracy: 0.8442\n",
      "Epoch 53/1000\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.3442 - accuracy: 0.8476 - val_loss: 0.3489 - val_accuracy: 0.8466\n",
      "Epoch 54/1000\n",
      "1600/1600 [==============================] - 2s 988us/step - loss: 0.3431 - accuracy: 0.8480 - val_loss: 0.3478 - val_accuracy: 0.8472\n",
      "Epoch 55/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3370 - accuracy: 0.8503 - val_loss: 0.3459 - val_accuracy: 0.8482\n",
      "Epoch 56/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3377 - accuracy: 0.8484 - val_loss: 0.3466 - val_accuracy: 0.8454\n",
      "Epoch 57/1000\n",
      "1600/1600 [==============================] - 1s 810us/step - loss: 0.3370 - accuracy: 0.8530 - val_loss: 0.3460 - val_accuracy: 0.8460\n",
      "Epoch 58/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3501 - accuracy: 0.8441 - val_loss: 0.3480 - val_accuracy: 0.8462\n",
      "Epoch 59/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3383 - accuracy: 0.8508 - val_loss: 0.3462 - val_accuracy: 0.8464\n",
      "Epoch 60/1000\n",
      "1600/1600 [==============================] - 1s 873us/step - loss: 0.3380 - accuracy: 0.8493 - val_loss: 0.3462 - val_accuracy: 0.8466\n",
      "Epoch 61/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3306 - accuracy: 0.8540 - val_loss: 0.3465 - val_accuracy: 0.8470\n",
      "Epoch 62/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3364 - accuracy: 0.8519 - val_loss: 0.3461 - val_accuracy: 0.8470\n",
      "Epoch 63/1000\n",
      "1600/1600 [==============================] - 1s 909us/step - loss: 0.3326 - accuracy: 0.8518 - val_loss: 0.3462 - val_accuracy: 0.8458\n",
      "Epoch 64/1000\n",
      "1600/1600 [==============================] - 1s 792us/step - loss: 0.3445 - accuracy: 0.8460 - val_loss: 0.3475 - val_accuracy: 0.8448\n",
      "Epoch 65/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3362 - accuracy: 0.8534 - val_loss: 0.3466 - val_accuracy: 0.8462\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3405 - accuracy: 0.8533\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4706 - accuracy: 0.7816 - val_loss: 0.3710 - val_accuracy: 0.8284\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3677 - accuracy: 0.8266 - val_loss: 0.3658 - val_accuracy: 0.8258\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 841us/step - loss: 0.3626 - accuracy: 0.8293 - val_loss: 0.3635 - val_accuracy: 0.8254\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3536 - accuracy: 0.8367 - val_loss: 0.3618 - val_accuracy: 0.8340\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3612 - accuracy: 0.8316 - val_loss: 0.3590 - val_accuracy: 0.8326\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3560 - accuracy: 0.8382 - val_loss: 0.3584 - val_accuracy: 0.8308\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3508 - accuracy: 0.8383 - val_loss: 0.3553 - val_accuracy: 0.8352\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3446 - accuracy: 0.8462 - val_loss: 0.3557 - val_accuracy: 0.8406\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 897us/step - loss: 0.3625 - accuracy: 0.8352 - val_loss: 0.3555 - val_accuracy: 0.8380\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3486 - accuracy: 0.8405 - val_loss: 0.3533 - val_accuracy: 0.8380\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3487 - accuracy: 0.8412 - val_loss: 0.3525 - val_accuracy: 0.8398\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3554 - accuracy: 0.8385 - val_loss: 0.3524 - val_accuracy: 0.8394\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3440 - accuracy: 0.8466 - val_loss: 0.3500 - val_accuracy: 0.8406\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 976us/step - loss: 0.3404 - accuracy: 0.8478 - val_loss: 0.3495 - val_accuracy: 0.8430\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3401 - accuracy: 0.8455 - val_loss: 0.3499 - val_accuracy: 0.8428\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 982us/step - loss: 0.3421 - accuracy: 0.8480 - val_loss: 0.3490 - val_accuracy: 0.8432\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 688us/step - loss: 0.3409 - accuracy: 0.8495 - val_loss: 0.3496 - val_accuracy: 0.8426\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3414 - accuracy: 0.8481 - val_loss: 0.3469 - val_accuracy: 0.8448\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3449 - accuracy: 0.8485 - val_loss: 0.3486 - val_accuracy: 0.8422\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3363 - accuracy: 0.8491 - val_loss: 0.3467 - val_accuracy: 0.8446\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 903us/step - loss: 0.3452 - accuracy: 0.8502 - val_loss: 0.3495 - val_accuracy: 0.8412\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3409 - accuracy: 0.8458 - val_loss: 0.3489 - val_accuracy: 0.8414\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3410 - accuracy: 0.8486 - val_loss: 0.3464 - val_accuracy: 0.8442\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 878us/step - loss: 0.3345 - accuracy: 0.8485 - val_loss: 0.3482 - val_accuracy: 0.8430\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3405 - accuracy: 0.8468 - val_loss: 0.3464 - val_accuracy: 0.8438\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3385 - accuracy: 0.8490 - val_loss: 0.3459 - val_accuracy: 0.8450\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 713us/step - loss: 0.3431 - accuracy: 0.8472 - val_loss: 0.3459 - val_accuracy: 0.8446\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3388 - accuracy: 0.8490 - val_loss: 0.3482 - val_accuracy: 0.8450\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3429 - accuracy: 0.8477 - val_loss: 0.3480 - val_accuracy: 0.8446\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3427 - accuracy: 0.8483 - val_loss: 0.3474 - val_accuracy: 0.8476\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 683us/step - loss: 0.3365 - accuracy: 0.8519 - val_loss: 0.3472 - val_accuracy: 0.8442\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 805us/step - loss: 0.3345 - accuracy: 0.8540 - val_loss: 0.3459 - val_accuracy: 0.8452\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3402 - accuracy: 0.8507 - val_loss: 0.3479 - val_accuracy: 0.8458\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 665us/step - loss: 0.3423 - accuracy: 0.8476 - val_loss: 0.3471 - val_accuracy: 0.8446\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3459 - accuracy: 0.8482 - val_loss: 0.3465 - val_accuracy: 0.8468\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 934us/step - loss: 0.3320 - accuracy: 0.8553 - val_loss: 0.3466 - val_accuracy: 0.8468\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3470 - accuracy: 0.8493\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 3s 1ms/step - loss: 0.4660 - accuracy: 0.7846 - val_loss: 0.3727 - val_accuracy: 0.8216\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3714 - accuracy: 0.8286 - val_loss: 0.3656 - val_accuracy: 0.8316\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3617 - accuracy: 0.8300 - val_loss: 0.3629 - val_accuracy: 0.8324\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3646 - accuracy: 0.8327 - val_loss: 0.3617 - val_accuracy: 0.8348\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3592 - accuracy: 0.8340 - val_loss: 0.3587 - val_accuracy: 0.8350\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3521 - accuracy: 0.8415 - val_loss: 0.3588 - val_accuracy: 0.8326\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3554 - accuracy: 0.8370 - val_loss: 0.3572 - val_accuracy: 0.8334\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3546 - accuracy: 0.8393 - val_loss: 0.3556 - val_accuracy: 0.8350\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 754us/step - loss: 0.3626 - accuracy: 0.8353 - val_loss: 0.3568 - val_accuracy: 0.8362\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 759us/step - loss: 0.3548 - accuracy: 0.8434 - val_loss: 0.3553 - val_accuracy: 0.8418\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 716us/step - loss: 0.3518 - accuracy: 0.8428 - val_loss: 0.3513 - val_accuracy: 0.8402\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3426 - accuracy: 0.8481 - val_loss: 0.3505 - val_accuracy: 0.8398\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 899us/step - loss: 0.3438 - accuracy: 0.8477 - val_loss: 0.3524 - val_accuracy: 0.8394\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3500 - accuracy: 0.8435 - val_loss: 0.3502 - val_accuracy: 0.8390\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3473 - accuracy: 0.8416 - val_loss: 0.3481 - val_accuracy: 0.8420\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3479 - accuracy: 0.8451 - val_loss: 0.3496 - val_accuracy: 0.8414\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 862us/step - loss: 0.3400 - accuracy: 0.8467 - val_loss: 0.3480 - val_accuracy: 0.8448\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3464 - accuracy: 0.8462 - val_loss: 0.3523 - val_accuracy: 0.8392\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3405 - accuracy: 0.8473 - val_loss: 0.3478 - val_accuracy: 0.8474\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3425 - accuracy: 0.8443 - val_loss: 0.3464 - val_accuracy: 0.8444\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 895us/step - loss: 0.3449 - accuracy: 0.8432 - val_loss: 0.3476 - val_accuracy: 0.8474\n",
      "Epoch 22/1000\n",
      "1589/1600 [============================>.] - ETA: 0s - loss: 0.3532 - accuracy: 0.8392"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = ModelCheckpoint(\"Checkpoints/ANN_1000ep_ES_CV.h5\")\n",
    "early_stopping_cb = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 10, restore_best_weights=True)\n",
    "\n",
    "param_grid = {\"n_hidden\": [1, 2, 3],\n",
    "              \"neurons\": [15, 20, 30, 45],\n",
    "              \"activation\": [\"relu\", \"tanh\", \"sigmoid\"]}\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs = 1000, batch_size = 10, verbose = 1)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X_train, y_train, epochs=1000, batch_size = 10, verbose=1,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best set of parameter is n_hidden=2, neurons=45, and activation = \"relu\". So, we fitted the model with such such hyper-parameter below (in Best Performing Model section)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Performing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2000/2000 [==============================] - 2s 754us/step - loss: 0.4324 - accuracy: 0.7959 - val_loss: 0.3753 - val_accuracy: 0.8162\n",
      "Epoch 2/1000\n",
      "2000/2000 [==============================] - 1s 715us/step - loss: 0.3647 - accuracy: 0.8297 - val_loss: 0.3599 - val_accuracy: 0.8388\n",
      "Epoch 3/1000\n",
      "2000/2000 [==============================] - 2s 765us/step - loss: 0.3579 - accuracy: 0.8395 - val_loss: 0.3554 - val_accuracy: 0.8400\n",
      "Epoch 4/1000\n",
      "2000/2000 [==============================] - 1s 734us/step - loss: 0.3522 - accuracy: 0.8416 - val_loss: 0.3518 - val_accuracy: 0.8432\n",
      "Epoch 5/1000\n",
      "2000/2000 [==============================] - 1s 701us/step - loss: 0.3486 - accuracy: 0.8471 - val_loss: 0.3532 - val_accuracy: 0.8416\n",
      "Epoch 6/1000\n",
      "2000/2000 [==============================] - 1s 698us/step - loss: 0.3501 - accuracy: 0.8453 - val_loss: 0.3467 - val_accuracy: 0.8448\n",
      "Epoch 7/1000\n",
      "2000/2000 [==============================] - 1s 712us/step - loss: 0.3448 - accuracy: 0.8464 - val_loss: 0.3457 - val_accuracy: 0.8466\n",
      "Epoch 8/1000\n",
      "2000/2000 [==============================] - 1s 697us/step - loss: 0.3396 - accuracy: 0.8504 - val_loss: 0.3418 - val_accuracy: 0.8446\n",
      "Epoch 9/1000\n",
      "2000/2000 [==============================] - 1s 684us/step - loss: 0.3367 - accuracy: 0.8522 - val_loss: 0.3502 - val_accuracy: 0.8462\n",
      "Epoch 10/1000\n",
      "2000/2000 [==============================] - 1s 696us/step - loss: 0.3415 - accuracy: 0.8508 - val_loss: 0.3542 - val_accuracy: 0.8452\n",
      "Epoch 11/1000\n",
      "2000/2000 [==============================] - 1s 691us/step - loss: 0.3400 - accuracy: 0.8523 - val_loss: 0.3579 - val_accuracy: 0.8406\n",
      "Epoch 12/1000\n",
      "2000/2000 [==============================] - 1s 697us/step - loss: 0.3398 - accuracy: 0.8491 - val_loss: 0.3417 - val_accuracy: 0.8466\n",
      "Epoch 13/1000\n",
      "2000/2000 [==============================] - 1s 682us/step - loss: 0.3401 - accuracy: 0.8472 - val_loss: 0.3515 - val_accuracy: 0.8434\n",
      "Epoch 14/1000\n",
      "2000/2000 [==============================] - 1s 678us/step - loss: 0.3349 - accuracy: 0.8546 - val_loss: 0.3514 - val_accuracy: 0.8452\n",
      "Epoch 15/1000\n",
      "2000/2000 [==============================] - 1s 710us/step - loss: 0.3341 - accuracy: 0.8515 - val_loss: 0.3368 - val_accuracy: 0.8472\n",
      "Epoch 16/1000\n",
      "2000/2000 [==============================] - 1s 700us/step - loss: 0.3319 - accuracy: 0.8552 - val_loss: 0.3374 - val_accuracy: 0.8484\n",
      "Epoch 17/1000\n",
      "2000/2000 [==============================] - 2s 860us/step - loss: 0.3296 - accuracy: 0.8579 - val_loss: 0.3424 - val_accuracy: 0.8464\n",
      "Epoch 18/1000\n",
      "2000/2000 [==============================] - 1s 674us/step - loss: 0.3264 - accuracy: 0.8586 - val_loss: 0.3391 - val_accuracy: 0.8494\n",
      "Epoch 19/1000\n",
      "2000/2000 [==============================] - 1s 667us/step - loss: 0.3308 - accuracy: 0.8550 - val_loss: 0.3509 - val_accuracy: 0.8428\n",
      "Epoch 20/1000\n",
      "2000/2000 [==============================] - 1s 710us/step - loss: 0.3257 - accuracy: 0.8578 - val_loss: 0.3446 - val_accuracy: 0.8506\n",
      "Epoch 21/1000\n",
      "2000/2000 [==============================] - 1s 676us/step - loss: 0.3322 - accuracy: 0.8587 - val_loss: 0.3637 - val_accuracy: 0.8440\n",
      "Epoch 22/1000\n",
      "2000/2000 [==============================] - 1s 701us/step - loss: 0.3302 - accuracy: 0.8555 - val_loss: 0.3467 - val_accuracy: 0.8474\n",
      "Epoch 23/1000\n",
      "2000/2000 [==============================] - 1s 680us/step - loss: 0.3324 - accuracy: 0.8578 - val_loss: 0.3418 - val_accuracy: 0.8482\n",
      "Epoch 24/1000\n",
      "2000/2000 [==============================] - 1s 699us/step - loss: 0.3281 - accuracy: 0.8596 - val_loss: 0.3468 - val_accuracy: 0.8468\n",
      "Epoch 25/1000\n",
      "2000/2000 [==============================] - 1s 689us/step - loss: 0.3332 - accuracy: 0.8568 - val_loss: 0.3602 - val_accuracy: 0.8448\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = ModelCheckpoint(\"Checkpoints/ANN_2HLys_45neurons_1000ep_ES.h5\")\n",
    "early_stopping_cb = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 10, restore_best_weights=True)\n",
    "\n",
    "model1 = create_model(n_hidden=2, neurons=45, activation=\"relu\")\n",
    "\n",
    "history1 = model1.fit(X_train, y_train, epochs=1000, batch_size = 10, verbose=1,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [checkpoint_cb, early_stopping_cb])\n",
    "\n",
    "model1.save(\"Models/ANN_2HLyr_45neurons_10BS_1000ep_ES10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 767us/step - loss: 0.3368 - accuracy: 0.8472\n",
      "Accuracy: 84.72%\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model1.evaluate(X_valid, y_valid)\n",
    "print('Accuracy: %.2f' % (accuracy*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history1.history['loss']\n",
    "val_loss = history1.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss)+1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label = 'Trainning loss')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning on a more constrained space (to avoid having large model variace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 798us/step - loss: 0.4954 - accuracy: 0.7718 - val_loss: 0.3776 - val_accuracy: 0.8168\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3771 - accuracy: 0.8180 - val_loss: 0.3711 - val_accuracy: 0.8236\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 673us/step - loss: 0.3744 - accuracy: 0.8146 - val_loss: 0.3683 - val_accuracy: 0.8292\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 800us/step - loss: 0.3640 - accuracy: 0.8287 - val_loss: 0.3643 - val_accuracy: 0.8240\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 830us/step - loss: 0.3649 - accuracy: 0.8286 - val_loss: 0.3616 - val_accuracy: 0.8252\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 825us/step - loss: 0.3565 - accuracy: 0.8337 - val_loss: 0.3606 - val_accuracy: 0.8288\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 787us/step - loss: 0.3584 - accuracy: 0.8307 - val_loss: 0.3611 - val_accuracy: 0.8266\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 656us/step - loss: 0.3581 - accuracy: 0.8328 - val_loss: 0.3585 - val_accuracy: 0.8290\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 656us/step - loss: 0.3491 - accuracy: 0.8395 - val_loss: 0.3557 - val_accuracy: 0.8322\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 659us/step - loss: 0.3538 - accuracy: 0.8379 - val_loss: 0.3568 - val_accuracy: 0.8354\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3521 - accuracy: 0.8361 - val_loss: 0.3541 - val_accuracy: 0.8324\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 837us/step - loss: 0.3470 - accuracy: 0.8409 - val_loss: 0.3533 - val_accuracy: 0.8316\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 773us/step - loss: 0.3569 - accuracy: 0.8351 - val_loss: 0.3521 - val_accuracy: 0.8338\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3533 - accuracy: 0.8390 - val_loss: 0.3520 - val_accuracy: 0.8352\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 828us/step - loss: 0.3413 - accuracy: 0.8403 - val_loss: 0.3538 - val_accuracy: 0.8330\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3415 - accuracy: 0.8379 - val_loss: 0.3523 - val_accuracy: 0.8350\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 673us/step - loss: 0.3399 - accuracy: 0.8461 - val_loss: 0.3505 - val_accuracy: 0.8390\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 935us/step - loss: 0.3381 - accuracy: 0.8452 - val_loss: 0.3484 - val_accuracy: 0.8374\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3427 - accuracy: 0.8425 - val_loss: 0.3480 - val_accuracy: 0.8378\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3430 - accuracy: 0.8460 - val_loss: 0.3484 - val_accuracy: 0.8378\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 651us/step - loss: 0.3428 - accuracy: 0.8429 - val_loss: 0.3454 - val_accuracy: 0.8420\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 918us/step - loss: 0.3522 - accuracy: 0.8395 - val_loss: 0.3451 - val_accuracy: 0.8422\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3383 - accuracy: 0.8484 - val_loss: 0.3457 - val_accuracy: 0.8454\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3431 - accuracy: 0.8444 - val_loss: 0.3445 - val_accuracy: 0.8412\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 664us/step - loss: 0.3338 - accuracy: 0.8494 - val_loss: 0.3432 - val_accuracy: 0.8430\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3436 - accuracy: 0.8455 - val_loss: 0.3455 - val_accuracy: 0.8452\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3316 - accuracy: 0.8533 - val_loss: 0.3427 - val_accuracy: 0.8454\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3276 - accuracy: 0.8562 - val_loss: 0.3413 - val_accuracy: 0.8480\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3353 - accuracy: 0.8512 - val_loss: 0.3441 - val_accuracy: 0.8448\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 676us/step - loss: 0.3264 - accuracy: 0.8549 - val_loss: 0.3425 - val_accuracy: 0.8440\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 660us/step - loss: 0.3367 - accuracy: 0.8504 - val_loss: 0.3429 - val_accuracy: 0.8462\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3375 - accuracy: 0.8471 - val_loss: 0.3418 - val_accuracy: 0.8464\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3367 - accuracy: 0.8492 - val_loss: 0.3421 - val_accuracy: 0.8470\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3353 - accuracy: 0.8524 - val_loss: 0.3405 - val_accuracy: 0.8462\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 683us/step - loss: 0.3322 - accuracy: 0.8500 - val_loss: 0.3427 - val_accuracy: 0.8418\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3325 - accuracy: 0.8551 - val_loss: 0.3408 - val_accuracy: 0.8448\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3284 - accuracy: 0.8537 - val_loss: 0.3402 - val_accuracy: 0.8456\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3269 - accuracy: 0.8570 - val_loss: 0.3389 - val_accuracy: 0.8470\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 814us/step - loss: 0.3305 - accuracy: 0.8558 - val_loss: 0.3405 - val_accuracy: 0.8462\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.3353 - accuracy: 0.8470 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.3295 - accuracy: 0.8518 - val_loss: 0.3402 - val_accuracy: 0.8470\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 693us/step - loss: 0.3338 - accuracy: 0.8503 - val_loss: 0.3395 - val_accuracy: 0.8464\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.3247 - accuracy: 0.8554 - val_loss: 0.3384 - val_accuracy: 0.8470\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3395 - accuracy: 0.8487 - val_loss: 0.3403 - val_accuracy: 0.8492\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3365 - accuracy: 0.8471 - val_loss: 0.3401 - val_accuracy: 0.8442\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3299 - accuracy: 0.8514 - val_loss: 0.3392 - val_accuracy: 0.8470\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3333 - accuracy: 0.8546 - val_loss: 0.3414 - val_accuracy: 0.8456\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 665us/step - loss: 0.3283 - accuracy: 0.8548 - val_loss: 0.3388 - val_accuracy: 0.8450\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3218 - accuracy: 0.8582 - val_loss: 0.3387 - val_accuracy: 0.8462\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 661us/step - loss: 0.3304 - accuracy: 0.8532 - val_loss: 0.3399 - val_accuracy: 0.8458\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 1s 670us/step - loss: 0.3395 - accuracy: 0.8499 - val_loss: 0.3370 - val_accuracy: 0.8484\n",
      "Epoch 52/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3338 - accuracy: 0.8538 - val_loss: 0.3399 - val_accuracy: 0.8484\n",
      "Epoch 53/1000\n",
      "1600/1600 [==============================] - 1s 661us/step - loss: 0.3252 - accuracy: 0.8590 - val_loss: 0.3370 - val_accuracy: 0.8472\n",
      "Epoch 54/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3255 - accuracy: 0.8524 - val_loss: 0.3396 - val_accuracy: 0.8464\n",
      "Epoch 55/1000\n",
      "1600/1600 [==============================] - 1s 662us/step - loss: 0.3373 - accuracy: 0.8489 - val_loss: 0.3391 - val_accuracy: 0.8458\n",
      "Epoch 56/1000\n",
      "1600/1600 [==============================] - 1s 818us/step - loss: 0.3374 - accuracy: 0.8484 - val_loss: 0.3397 - val_accuracy: 0.8476\n",
      "Epoch 57/1000\n",
      "1600/1600 [==============================] - 1s 863us/step - loss: 0.3244 - accuracy: 0.8581 - val_loss: 0.3378 - val_accuracy: 0.8484\n",
      "Epoch 58/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3358 - accuracy: 0.8475 - val_loss: 0.3418 - val_accuracy: 0.8472\n",
      "Epoch 59/1000\n",
      "1600/1600 [==============================] - 1s 653us/step - loss: 0.3269 - accuracy: 0.8524 - val_loss: 0.3398 - val_accuracy: 0.8442\n",
      "Epoch 60/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3246 - accuracy: 0.8527 - val_loss: 0.3378 - val_accuracy: 0.8464\n",
      "Epoch 61/1000\n",
      "1600/1600 [==============================] - 1s 813us/step - loss: 0.3286 - accuracy: 0.8521 - val_loss: 0.3394 - val_accuracy: 0.8482\n",
      "400/400 [==============================] - 0s 737us/step - loss: 0.3275 - accuracy: 0.8530\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 909us/step - loss: 0.5034 - accuracy: 0.7726 - val_loss: 0.3796 - val_accuracy: 0.8128\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3690 - accuracy: 0.8262 - val_loss: 0.3698 - val_accuracy: 0.8206\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 660us/step - loss: 0.3653 - accuracy: 0.8297 - val_loss: 0.3698 - val_accuracy: 0.8282\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 854us/step - loss: 0.3698 - accuracy: 0.8257 - val_loss: 0.3631 - val_accuracy: 0.8230\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 812us/step - loss: 0.3668 - accuracy: 0.8331 - val_loss: 0.3640 - val_accuracy: 0.8232\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3522 - accuracy: 0.8404 - val_loss: 0.3608 - val_accuracy: 0.8258\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 646us/step - loss: 0.3517 - accuracy: 0.8368 - val_loss: 0.3580 - val_accuracy: 0.8310\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3587 - accuracy: 0.8347 - val_loss: 0.3578 - val_accuracy: 0.8336\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 2s 995us/step - loss: 0.3515 - accuracy: 0.8387 - val_loss: 0.3559 - val_accuracy: 0.8320\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 998us/step - loss: 0.3492 - accuracy: 0.8377 - val_loss: 0.3545 - val_accuracy: 0.8342\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 904us/step - loss: 0.3542 - accuracy: 0.8366 - val_loss: 0.3546 - val_accuracy: 0.8306\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3514 - accuracy: 0.8394 - val_loss: 0.3543 - val_accuracy: 0.8346\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.3537 - accuracy: 0.8378 - val_loss: 0.3530 - val_accuracy: 0.8324\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3499 - accuracy: 0.8411 - val_loss: 0.3521 - val_accuracy: 0.8346\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 799us/step - loss: 0.3489 - accuracy: 0.8433 - val_loss: 0.3498 - val_accuracy: 0.8358\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3492 - accuracy: 0.8401 - val_loss: 0.3491 - val_accuracy: 0.8360\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3445 - accuracy: 0.8456 - val_loss: 0.3485 - val_accuracy: 0.8406\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3443 - accuracy: 0.8417 - val_loss: 0.3484 - val_accuracy: 0.8378\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3433 - accuracy: 0.8449 - val_loss: 0.3492 - val_accuracy: 0.8426\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3419 - accuracy: 0.8478 - val_loss: 0.3479 - val_accuracy: 0.8398\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3422 - accuracy: 0.8482 - val_loss: 0.3447 - val_accuracy: 0.8430\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 673us/step - loss: 0.3373 - accuracy: 0.8474 - val_loss: 0.3438 - val_accuracy: 0.8440\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3323 - accuracy: 0.8525 - val_loss: 0.3492 - val_accuracy: 0.8368\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3352 - accuracy: 0.8516 - val_loss: 0.3444 - val_accuracy: 0.8436\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 683us/step - loss: 0.3336 - accuracy: 0.8503 - val_loss: 0.3435 - val_accuracy: 0.8454\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 817us/step - loss: 0.3303 - accuracy: 0.8539 - val_loss: 0.3427 - val_accuracy: 0.8436\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3410 - accuracy: 0.8467 - val_loss: 0.3448 - val_accuracy: 0.8430\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 663us/step - loss: 0.3323 - accuracy: 0.8527 - val_loss: 0.3430 - val_accuracy: 0.8426\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3418 - accuracy: 0.8487 - val_loss: 0.3434 - val_accuracy: 0.8434\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3363 - accuracy: 0.8486 - val_loss: 0.3453 - val_accuracy: 0.8404\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 659us/step - loss: 0.3314 - accuracy: 0.8516 - val_loss: 0.3430 - val_accuracy: 0.8430\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 789us/step - loss: 0.3331 - accuracy: 0.8522 - val_loss: 0.3420 - val_accuracy: 0.8436\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3331 - accuracy: 0.8520 - val_loss: 0.3419 - val_accuracy: 0.8442\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3294 - accuracy: 0.8526 - val_loss: 0.3417 - val_accuracy: 0.8458\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 781us/step - loss: 0.3320 - accuracy: 0.8514 - val_loss: 0.3420 - val_accuracy: 0.8476\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3338 - accuracy: 0.8520 - val_loss: 0.3427 - val_accuracy: 0.8428\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3409 - accuracy: 0.8476 - val_loss: 0.3407 - val_accuracy: 0.8420\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 880us/step - loss: 0.3354 - accuracy: 0.8466 - val_loss: 0.3420 - val_accuracy: 0.8420\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3312 - accuracy: 0.8538 - val_loss: 0.3387 - val_accuracy: 0.8474\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3305 - accuracy: 0.8530 - val_loss: 0.3388 - val_accuracy: 0.8472\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 728us/step - loss: 0.3286 - accuracy: 0.8513 - val_loss: 0.3403 - val_accuracy: 0.8430\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3359 - accuracy: 0.8490 - val_loss: 0.3399 - val_accuracy: 0.8470\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3288 - accuracy: 0.8534 - val_loss: 0.3425 - val_accuracy: 0.8432\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3423 - accuracy: 0.8460 - val_loss: 0.3394 - val_accuracy: 0.8476\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3315 - accuracy: 0.8514 - val_loss: 0.3387 - val_accuracy: 0.8462\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3355 - accuracy: 0.8524 - val_loss: 0.3417 - val_accuracy: 0.8478\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 661us/step - loss: 0.3355 - accuracy: 0.8485 - val_loss: 0.3427 - val_accuracy: 0.8442\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3382 - accuracy: 0.8511 - val_loss: 0.3417 - val_accuracy: 0.8472\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 2s 987us/step - loss: 0.3314 - accuracy: 0.8535 - val_loss: 0.3399 - val_accuracy: 0.8442\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3264 - accuracy: 0.8562\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 755us/step - loss: 0.5009 - accuracy: 0.7763 - val_loss: 0.3800 - val_accuracy: 0.8166\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 749us/step - loss: 0.3779 - accuracy: 0.8179 - val_loss: 0.3729 - val_accuracy: 0.8232\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 768us/step - loss: 0.3714 - accuracy: 0.8236 - val_loss: 0.3688 - val_accuracy: 0.8200\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3647 - accuracy: 0.8274 - val_loss: 0.3655 - val_accuracy: 0.8270\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3598 - accuracy: 0.8329 - val_loss: 0.3629 - val_accuracy: 0.8286\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 693us/step - loss: 0.3568 - accuracy: 0.8310 - val_loss: 0.3606 - val_accuracy: 0.8258\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3573 - accuracy: 0.8279 - val_loss: 0.3598 - val_accuracy: 0.8258\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3473 - accuracy: 0.8392 - val_loss: 0.3587 - val_accuracy: 0.8266\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3441 - accuracy: 0.8404 - val_loss: 0.3578 - val_accuracy: 0.8292\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3594 - accuracy: 0.8307 - val_loss: 0.3595 - val_accuracy: 0.8336\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3514 - accuracy: 0.8364 - val_loss: 0.3578 - val_accuracy: 0.8330\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3431 - accuracy: 0.8409 - val_loss: 0.3548 - val_accuracy: 0.8318\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3454 - accuracy: 0.8371 - val_loss: 0.3537 - val_accuracy: 0.8334\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 683us/step - loss: 0.3451 - accuracy: 0.8422 - val_loss: 0.3552 - val_accuracy: 0.8310\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3503 - accuracy: 0.8374 - val_loss: 0.3535 - val_accuracy: 0.8364\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 775us/step - loss: 0.3443 - accuracy: 0.8403 - val_loss: 0.3535 - val_accuracy: 0.8322\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3473 - accuracy: 0.8400 - val_loss: 0.3517 - val_accuracy: 0.8342\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3452 - accuracy: 0.8415 - val_loss: 0.3524 - val_accuracy: 0.8340\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3442 - accuracy: 0.8444 - val_loss: 0.3501 - val_accuracy: 0.8400\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3403 - accuracy: 0.8441 - val_loss: 0.3492 - val_accuracy: 0.8402\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3385 - accuracy: 0.8477 - val_loss: 0.3485 - val_accuracy: 0.8396\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3453 - accuracy: 0.8400 - val_loss: 0.3495 - val_accuracy: 0.8386\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 693us/step - loss: 0.3421 - accuracy: 0.8462 - val_loss: 0.3478 - val_accuracy: 0.8398\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 673us/step - loss: 0.3450 - accuracy: 0.8453 - val_loss: 0.3470 - val_accuracy: 0.8424\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 662us/step - loss: 0.3418 - accuracy: 0.8456 - val_loss: 0.3469 - val_accuracy: 0.8402\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3370 - accuracy: 0.8502 - val_loss: 0.3466 - val_accuracy: 0.8420\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3414 - accuracy: 0.8451 - val_loss: 0.3479 - val_accuracy: 0.8402\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3365 - accuracy: 0.8509 - val_loss: 0.3445 - val_accuracy: 0.8424\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3348 - accuracy: 0.8487 - val_loss: 0.3452 - val_accuracy: 0.8434\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3372 - accuracy: 0.8492 - val_loss: 0.3450 - val_accuracy: 0.8448\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.3342 - accuracy: 0.8492 - val_loss: 0.3438 - val_accuracy: 0.8410\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 788us/step - loss: 0.3289 - accuracy: 0.8540 - val_loss: 0.3443 - val_accuracy: 0.8408\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 761us/step - loss: 0.3314 - accuracy: 0.8490 - val_loss: 0.3448 - val_accuracy: 0.8460\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3332 - accuracy: 0.8532 - val_loss: 0.3423 - val_accuracy: 0.8456\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 676us/step - loss: 0.3334 - accuracy: 0.8496 - val_loss: 0.3442 - val_accuracy: 0.8428\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3303 - accuracy: 0.8524 - val_loss: 0.3434 - val_accuracy: 0.8442\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3309 - accuracy: 0.8495 - val_loss: 0.3439 - val_accuracy: 0.8424\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3317 - accuracy: 0.8482 - val_loss: 0.3418 - val_accuracy: 0.8456\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3353 - accuracy: 0.8489 - val_loss: 0.3478 - val_accuracy: 0.8410\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3306 - accuracy: 0.8523 - val_loss: 0.3426 - val_accuracy: 0.8446\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3317 - accuracy: 0.8513 - val_loss: 0.3424 - val_accuracy: 0.8470\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3350 - accuracy: 0.8496 - val_loss: 0.3430 - val_accuracy: 0.8468\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3291 - accuracy: 0.8521 - val_loss: 0.3413 - val_accuracy: 0.8476\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.3250 - accuracy: 0.8529 - val_loss: 0.3411 - val_accuracy: 0.8450\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 791us/step - loss: 0.3350 - accuracy: 0.8496 - val_loss: 0.3404 - val_accuracy: 0.8474\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 908us/step - loss: 0.3377 - accuracy: 0.8479 - val_loss: 0.3431 - val_accuracy: 0.8440\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 803us/step - loss: 0.3317 - accuracy: 0.8524 - val_loss: 0.3407 - val_accuracy: 0.8466\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3286 - accuracy: 0.8524 - val_loss: 0.3405 - val_accuracy: 0.8460\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 665us/step - loss: 0.3307 - accuracy: 0.8528 - val_loss: 0.3398 - val_accuracy: 0.8470\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3240 - accuracy: 0.8545 - val_loss: 0.3409 - val_accuracy: 0.8462\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 1s 664us/step - loss: 0.3330 - accuracy: 0.8498 - val_loss: 0.3446 - val_accuracy: 0.8470\n",
      "Epoch 52/1000\n",
      "1600/1600 [==============================] - 1s 661us/step - loss: 0.3266 - accuracy: 0.8513 - val_loss: 0.3411 - val_accuracy: 0.8454\n",
      "Epoch 53/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3245 - accuracy: 0.8540 - val_loss: 0.3406 - val_accuracy: 0.8456\n",
      "Epoch 54/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3375 - accuracy: 0.8512 - val_loss: 0.3391 - val_accuracy: 0.8480\n",
      "Epoch 55/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3326 - accuracy: 0.8500 - val_loss: 0.3432 - val_accuracy: 0.8438\n",
      "Epoch 56/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3313 - accuracy: 0.8491 - val_loss: 0.3408 - val_accuracy: 0.8444\n",
      "Epoch 57/1000\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.3219 - accuracy: 0.8579 - val_loss: 0.3410 - val_accuracy: 0.8460\n",
      "Epoch 58/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3313 - accuracy: 0.8521 - val_loss: 0.3408 - val_accuracy: 0.8446\n",
      "Epoch 59/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3302 - accuracy: 0.8504 - val_loss: 0.3406 - val_accuracy: 0.8474\n",
      "Epoch 60/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3284 - accuracy: 0.8548 - val_loss: 0.3395 - val_accuracy: 0.8468\n",
      "Epoch 61/1000\n",
      "1600/1600 [==============================] - 1s 851us/step - loss: 0.3279 - accuracy: 0.8562 - val_loss: 0.3396 - val_accuracy: 0.8470\n",
      "Epoch 62/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3330 - accuracy: 0.8542 - val_loss: 0.3406 - val_accuracy: 0.8454\n",
      "Epoch 63/1000\n",
      "1600/1600 [==============================] - 1s 693us/step - loss: 0.3297 - accuracy: 0.8539 - val_loss: 0.3429 - val_accuracy: 0.8434\n",
      "Epoch 64/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3339 - accuracy: 0.8501 - val_loss: 0.3391 - val_accuracy: 0.8456\n",
      "400/400 [==============================] - 0s 717us/step - loss: 0.3389 - accuracy: 0.8508\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 770us/step - loss: 0.5041 - accuracy: 0.7746 - val_loss: 0.3808 - val_accuracy: 0.8150\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 716us/step - loss: 0.3785 - accuracy: 0.8207 - val_loss: 0.3723 - val_accuracy: 0.8214\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 816us/step - loss: 0.3694 - accuracy: 0.8276 - val_loss: 0.3702 - val_accuracy: 0.8168\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3688 - accuracy: 0.8262 - val_loss: 0.3671 - val_accuracy: 0.8256\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3628 - accuracy: 0.8266 - val_loss: 0.3637 - val_accuracy: 0.8250\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 863us/step - loss: 0.3599 - accuracy: 0.8273 - val_loss: 0.3623 - val_accuracy: 0.8244\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3578 - accuracy: 0.8319 - val_loss: 0.3624 - val_accuracy: 0.8250\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3489 - accuracy: 0.8407 - val_loss: 0.3595 - val_accuracy: 0.8246\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.3520 - accuracy: 0.8392 - val_loss: 0.3590 - val_accuracy: 0.8282\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3523 - accuracy: 0.8398 - val_loss: 0.3578 - val_accuracy: 0.8280\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py\", line 223, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py\", line 166, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1145, in fit\n",
      "    callbacks.on_epoch_end(epoch, epoch_logs)\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 428, in on_epoch_end\n",
      "    callback.on_epoch_end(epoch, logs)\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 1344, in on_epoch_end\n",
      "    self._save_model(epoch=epoch, logs=logs)\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 1418, in _save_model\n",
      "    raise e\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 1408, in _save_model\n",
      "    self.model.save(filepath, overwrite=True, options=self._options)\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 2001, in save\n",
      "    save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\", line 153, in save_model\n",
      "    hdf5_format.save_model_to_hdf5(\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\", line 108, in save_model_to_hdf5\n",
      "    f = h5py.File(filepath, mode='w')\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\", line 406, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size,\n",
      "  File \"C:\\Users\\GloriaHou\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\", line 179, in make_fid\n",
      "    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)\n",
      "  File \"h5py\\_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py\\_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py\\h5f.pyx\", line 108, in h5py.h5f.create\n",
      "OSError: Unable to create file (unable to open file: name = 'Checkpoints\\ANN_1000ep_ES_CV.h5', errno = 13, error message = 'Permission denied', flags = 13, o_flags = 302)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4978 - accuracy: 0.7703 - val_loss: 0.3776 - val_accuracy: 0.8178\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3651 - accuracy: 0.8302 - val_loss: 0.3691 - val_accuracy: 0.8218\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3564 - accuracy: 0.8329 - val_loss: 0.3655 - val_accuracy: 0.8244\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3552 - accuracy: 0.8356 - val_loss: 0.3625 - val_accuracy: 0.8238\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 670us/step - loss: 0.3564 - accuracy: 0.8350 - val_loss: 0.3616 - val_accuracy: 0.8244\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.3574 - accuracy: 0.8361 - val_loss: 0.3583 - val_accuracy: 0.8296\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3590 - accuracy: 0.8355 - val_loss: 0.3569 - val_accuracy: 0.8336\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3438 - accuracy: 0.8431 - val_loss: 0.3554 - val_accuracy: 0.8346\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 736us/step - loss: 0.3459 - accuracy: 0.8441 - val_loss: 0.3536 - val_accuracy: 0.8330\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3488 - accuracy: 0.8408 - val_loss: 0.3524 - val_accuracy: 0.8336\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3471 - accuracy: 0.8438 - val_loss: 0.3512 - val_accuracy: 0.8372\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 856us/step - loss: 0.3429 - accuracy: 0.8474 - val_loss: 0.3500 - val_accuracy: 0.8396\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 805us/step - loss: 0.3451 - accuracy: 0.8431 - val_loss: 0.3529 - val_accuracy: 0.8404\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3411 - accuracy: 0.8493 - val_loss: 0.3502 - val_accuracy: 0.8426\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 661us/step - loss: 0.3411 - accuracy: 0.8466 - val_loss: 0.3466 - val_accuracy: 0.8400\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3370 - accuracy: 0.8490 - val_loss: 0.3459 - val_accuracy: 0.8448\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3348 - accuracy: 0.8515 - val_loss: 0.3475 - val_accuracy: 0.8446\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3330 - accuracy: 0.8515 - val_loss: 0.3447 - val_accuracy: 0.8446\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 683us/step - loss: 0.3401 - accuracy: 0.8503 - val_loss: 0.3445 - val_accuracy: 0.8430\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3469 - accuracy: 0.8436 - val_loss: 0.3474 - val_accuracy: 0.8446\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 693us/step - loss: 0.3320 - accuracy: 0.8522 - val_loss: 0.3444 - val_accuracy: 0.8468\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 698us/step - loss: 0.3320 - accuracy: 0.8537 - val_loss: 0.3433 - val_accuracy: 0.8412\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3337 - accuracy: 0.8506 - val_loss: 0.3444 - val_accuracy: 0.8442\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3265 - accuracy: 0.8555 - val_loss: 0.3428 - val_accuracy: 0.8448\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3269 - accuracy: 0.8513 - val_loss: 0.3428 - val_accuracy: 0.8456\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 673us/step - loss: 0.3274 - accuracy: 0.8544 - val_loss: 0.3414 - val_accuracy: 0.8446\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3321 - accuracy: 0.8509 - val_loss: 0.3448 - val_accuracy: 0.8454\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3324 - accuracy: 0.8536 - val_loss: 0.3455 - val_accuracy: 0.8416\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 668us/step - loss: 0.3268 - accuracy: 0.8555 - val_loss: 0.3430 - val_accuracy: 0.8442\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 656us/step - loss: 0.3306 - accuracy: 0.8580 - val_loss: 0.3397 - val_accuracy: 0.8462\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3189 - accuracy: 0.8577 - val_loss: 0.3404 - val_accuracy: 0.8472\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 668us/step - loss: 0.3230 - accuracy: 0.8578 - val_loss: 0.3409 - val_accuracy: 0.8460\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3375 - accuracy: 0.8511 - val_loss: 0.3409 - val_accuracy: 0.8486\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3293 - accuracy: 0.8554 - val_loss: 0.3421 - val_accuracy: 0.8488\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 662us/step - loss: 0.3273 - accuracy: 0.8550 - val_loss: 0.3402 - val_accuracy: 0.8492\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3295 - accuracy: 0.8582 - val_loss: 0.3442 - val_accuracy: 0.8466\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3368 - accuracy: 0.8504 - val_loss: 0.3423 - val_accuracy: 0.8480\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3393 - accuracy: 0.8504 - val_loss: 0.3403 - val_accuracy: 0.8490\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3345 - accuracy: 0.8506 - val_loss: 0.3430 - val_accuracy: 0.8440\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.3255 - accuracy: 0.8573 - val_loss: 0.3432 - val_accuracy: 0.8474\n",
      "400/400 [==============================] - 0s 697us/step - loss: 0.3407 - accuracy: 0.8422\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 803us/step - loss: 0.4845 - accuracy: 0.7810 - val_loss: 0.3762 - val_accuracy: 0.8176\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3789 - accuracy: 0.8198 - val_loss: 0.3701 - val_accuracy: 0.8200\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3767 - accuracy: 0.8184 - val_loss: 0.3655 - val_accuracy: 0.8220\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 841us/step - loss: 0.3664 - accuracy: 0.8276 - val_loss: 0.3627 - val_accuracy: 0.8262\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3547 - accuracy: 0.8345 - val_loss: 0.3592 - val_accuracy: 0.8320\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 792us/step - loss: 0.3566 - accuracy: 0.8359 - val_loss: 0.3579 - val_accuracy: 0.8316\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3539 - accuracy: 0.8350 - val_loss: 0.3548 - val_accuracy: 0.8320\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3478 - accuracy: 0.8391 - val_loss: 0.3520 - val_accuracy: 0.8358\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3560 - accuracy: 0.8340 - val_loss: 0.3519 - val_accuracy: 0.8334\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3463 - accuracy: 0.8400 - val_loss: 0.3489 - val_accuracy: 0.8368\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3379 - accuracy: 0.8462 - val_loss: 0.3485 - val_accuracy: 0.8378\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3507 - accuracy: 0.8378 - val_loss: 0.3475 - val_accuracy: 0.8390\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3363 - accuracy: 0.8467 - val_loss: 0.3454 - val_accuracy: 0.8394\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.3379 - accuracy: 0.8461 - val_loss: 0.3458 - val_accuracy: 0.8404\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3463 - accuracy: 0.8417 - val_loss: 0.3459 - val_accuracy: 0.8400\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3371 - accuracy: 0.8478 - val_loss: 0.3422 - val_accuracy: 0.8452\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3426 - accuracy: 0.8469 - val_loss: 0.3435 - val_accuracy: 0.8430\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3374 - accuracy: 0.8446 - val_loss: 0.3428 - val_accuracy: 0.8460\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3395 - accuracy: 0.8467 - val_loss: 0.3445 - val_accuracy: 0.8464\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3328 - accuracy: 0.8530 - val_loss: 0.3440 - val_accuracy: 0.8436\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3444 - accuracy: 0.8442 - val_loss: 0.3430 - val_accuracy: 0.8454\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 777us/step - loss: 0.3411 - accuracy: 0.8527 - val_loss: 0.3431 - val_accuracy: 0.8452\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3247 - accuracy: 0.8555 - val_loss: 0.3442 - val_accuracy: 0.8452\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3321 - accuracy: 0.8525 - val_loss: 0.3451 - val_accuracy: 0.8452\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3358 - accuracy: 0.8510 - val_loss: 0.3481 - val_accuracy: 0.8468\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3304 - accuracy: 0.8529 - val_loss: 0.3431 - val_accuracy: 0.8450\n",
      "400/400 [==============================] - 0s 712us/step - loss: 0.3330 - accuracy: 0.8500\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 740us/step - loss: 0.4948 - accuracy: 0.7748 - val_loss: 0.3780 - val_accuracy: 0.8188\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3773 - accuracy: 0.8215 - val_loss: 0.3691 - val_accuracy: 0.8206\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 662us/step - loss: 0.3704 - accuracy: 0.8258 - val_loss: 0.3643 - val_accuracy: 0.8256\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 670us/step - loss: 0.3727 - accuracy: 0.8278 - val_loss: 0.3628 - val_accuracy: 0.8266\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 660us/step - loss: 0.3559 - accuracy: 0.8316 - val_loss: 0.3622 - val_accuracy: 0.8240\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3597 - accuracy: 0.8309 - val_loss: 0.3607 - val_accuracy: 0.8276\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3509 - accuracy: 0.8399 - val_loss: 0.3554 - val_accuracy: 0.8302\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3625 - accuracy: 0.8297 - val_loss: 0.3550 - val_accuracy: 0.8376\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3492 - accuracy: 0.8392 - val_loss: 0.3529 - val_accuracy: 0.8320\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.3502 - accuracy: 0.8452 - val_loss: 0.3502 - val_accuracy: 0.8368\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3503 - accuracy: 0.8383 - val_loss: 0.3489 - val_accuracy: 0.8402\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3430 - accuracy: 0.8432 - val_loss: 0.3468 - val_accuracy: 0.8412\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3378 - accuracy: 0.8501 - val_loss: 0.3458 - val_accuracy: 0.8428\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 817us/step - loss: 0.3327 - accuracy: 0.8529 - val_loss: 0.3456 - val_accuracy: 0.8444\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 934us/step - loss: 0.3357 - accuracy: 0.8492 - val_loss: 0.3465 - val_accuracy: 0.8448\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.3304 - accuracy: 0.8533 - val_loss: 0.3438 - val_accuracy: 0.8444\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.3398 - accuracy: 0.8479 - val_loss: 0.3459 - val_accuracy: 0.8390\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 676us/step - loss: 0.3319 - accuracy: 0.8561 - val_loss: 0.3444 - val_accuracy: 0.8430\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 663us/step - loss: 0.3362 - accuracy: 0.8495 - val_loss: 0.3423 - val_accuracy: 0.8436\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3345 - accuracy: 0.8514 - val_loss: 0.3432 - val_accuracy: 0.8442\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 908us/step - loss: 0.3336 - accuracy: 0.8501 - val_loss: 0.3440 - val_accuracy: 0.8470\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3383 - accuracy: 0.8502 - val_loss: 0.3414 - val_accuracy: 0.8462\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 676us/step - loss: 0.3331 - accuracy: 0.8496 - val_loss: 0.3472 - val_accuracy: 0.8398\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3343 - accuracy: 0.8504 - val_loss: 0.3412 - val_accuracy: 0.8454\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3347 - accuracy: 0.8514 - val_loss: 0.3409 - val_accuracy: 0.8452\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 813us/step - loss: 0.3268 - accuracy: 0.8539 - val_loss: 0.3415 - val_accuracy: 0.8466\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 676us/step - loss: 0.3286 - accuracy: 0.8528 - val_loss: 0.3432 - val_accuracy: 0.8436\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3372 - accuracy: 0.8506 - val_loss: 0.3447 - val_accuracy: 0.8436\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 688us/step - loss: 0.3382 - accuracy: 0.8482 - val_loss: 0.3417 - val_accuracy: 0.8468\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 657us/step - loss: 0.3334 - accuracy: 0.8493 - val_loss: 0.3437 - val_accuracy: 0.8452\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3258 - accuracy: 0.8545 - val_loss: 0.3417 - val_accuracy: 0.8472\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3329 - accuracy: 0.8500 - val_loss: 0.3437 - val_accuracy: 0.8446\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3296 - accuracy: 0.8537 - val_loss: 0.3398 - val_accuracy: 0.8480\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3337 - accuracy: 0.8527 - val_loss: 0.3422 - val_accuracy: 0.8462\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3347 - accuracy: 0.8505 - val_loss: 0.3408 - val_accuracy: 0.8466\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 662us/step - loss: 0.3295 - accuracy: 0.8563 - val_loss: 0.3409 - val_accuracy: 0.8468\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3367 - accuracy: 0.8479 - val_loss: 0.3431 - val_accuracy: 0.8454\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 772us/step - loss: 0.3409 - accuracy: 0.8525 - val_loss: 0.3427 - val_accuracy: 0.8462\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3280 - accuracy: 0.8522 - val_loss: 0.3471 - val_accuracy: 0.8470\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3332 - accuracy: 0.8504 - val_loss: 0.3456 - val_accuracy: 0.8470\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3352 - accuracy: 0.8481 - val_loss: 0.3433 - val_accuracy: 0.8462\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 662us/step - loss: 0.3343 - accuracy: 0.8485 - val_loss: 0.3433 - val_accuracy: 0.8480\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3334 - accuracy: 0.8524 - val_loss: 0.3424 - val_accuracy: 0.8460\n",
      "400/400 [==============================] - 0s 685us/step - loss: 0.3294 - accuracy: 0.8533\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 782us/step - loss: 0.4816 - accuracy: 0.7795 - val_loss: 0.3786 - val_accuracy: 0.8120\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 731us/step - loss: 0.3814 - accuracy: 0.8144 - val_loss: 0.3718 - val_accuracy: 0.8180\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3779 - accuracy: 0.8227 - val_loss: 0.3681 - val_accuracy: 0.8192\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3681 - accuracy: 0.8244 - val_loss: 0.3651 - val_accuracy: 0.8276\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3611 - accuracy: 0.8306 - val_loss: 0.3625 - val_accuracy: 0.8234\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3528 - accuracy: 0.8314 - val_loss: 0.3606 - val_accuracy: 0.8248\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3537 - accuracy: 0.8353 - val_loss: 0.3589 - val_accuracy: 0.8298\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3602 - accuracy: 0.8337 - val_loss: 0.3596 - val_accuracy: 0.8270\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3452 - accuracy: 0.8413 - val_loss: 0.3575 - val_accuracy: 0.8278\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3547 - accuracy: 0.8366 - val_loss: 0.3586 - val_accuracy: 0.8272\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 771us/step - loss: 0.3512 - accuracy: 0.8392 - val_loss: 0.3561 - val_accuracy: 0.8302\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3630 - accuracy: 0.8304 - val_loss: 0.3561 - val_accuracy: 0.8336\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3572 - accuracy: 0.8391 - val_loss: 0.3552 - val_accuracy: 0.8318\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3570 - accuracy: 0.8331 - val_loss: 0.3537 - val_accuracy: 0.8314\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 698us/step - loss: 0.3534 - accuracy: 0.8349 - val_loss: 0.3529 - val_accuracy: 0.8320\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3444 - accuracy: 0.8412 - val_loss: 0.3533 - val_accuracy: 0.8320\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3444 - accuracy: 0.8455 - val_loss: 0.3532 - val_accuracy: 0.8326\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3464 - accuracy: 0.8432 - val_loss: 0.3512 - val_accuracy: 0.8354\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3432 - accuracy: 0.8453 - val_loss: 0.3535 - val_accuracy: 0.8324\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3412 - accuracy: 0.8441 - val_loss: 0.3513 - val_accuracy: 0.8360\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3491 - accuracy: 0.8428 - val_loss: 0.3518 - val_accuracy: 0.8406\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 728us/step - loss: 0.3400 - accuracy: 0.8482 - val_loss: 0.3490 - val_accuracy: 0.8378\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3382 - accuracy: 0.8437 - val_loss: 0.3473 - val_accuracy: 0.8398\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3379 - accuracy: 0.8441 - val_loss: 0.3463 - val_accuracy: 0.8406\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 810us/step - loss: 0.3460 - accuracy: 0.8438 - val_loss: 0.3471 - val_accuracy: 0.8418\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3324 - accuracy: 0.8505 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3368 - accuracy: 0.8477 - val_loss: 0.3507 - val_accuracy: 0.8464\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3390 - accuracy: 0.8470 - val_loss: 0.3477 - val_accuracy: 0.8380\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3407 - accuracy: 0.8491 - val_loss: 0.3467 - val_accuracy: 0.8428\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3315 - accuracy: 0.8545 - val_loss: 0.3449 - val_accuracy: 0.8452\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3325 - accuracy: 0.8498 - val_loss: 0.3431 - val_accuracy: 0.8456\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3325 - accuracy: 0.8501 - val_loss: 0.3423 - val_accuracy: 0.8468\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 813us/step - loss: 0.3284 - accuracy: 0.8564 - val_loss: 0.3441 - val_accuracy: 0.8456\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3302 - accuracy: 0.8519 - val_loss: 0.3448 - val_accuracy: 0.8420\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3361 - accuracy: 0.8514 - val_loss: 0.3433 - val_accuracy: 0.8472\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 780us/step - loss: 0.3382 - accuracy: 0.8502 - val_loss: 0.3438 - val_accuracy: 0.8426\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3297 - accuracy: 0.8539 - val_loss: 0.3431 - val_accuracy: 0.8450\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3312 - accuracy: 0.8506 - val_loss: 0.3405 - val_accuracy: 0.8462\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 774us/step - loss: 0.3355 - accuracy: 0.8476 - val_loss: 0.3434 - val_accuracy: 0.8484\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3350 - accuracy: 0.8500 - val_loss: 0.3408 - val_accuracy: 0.8466\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3257 - accuracy: 0.8572 - val_loss: 0.3406 - val_accuracy: 0.8462\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3339 - accuracy: 0.8484 - val_loss: 0.3400 - val_accuracy: 0.8476\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 810us/step - loss: 0.3381 - accuracy: 0.8497 - val_loss: 0.3436 - val_accuracy: 0.8474\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3334 - accuracy: 0.8487 - val_loss: 0.3417 - val_accuracy: 0.8456\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3334 - accuracy: 0.8491 - val_loss: 0.3412 - val_accuracy: 0.8452\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 821us/step - loss: 0.3264 - accuracy: 0.8505 - val_loss: 0.3403 - val_accuracy: 0.8480\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 713us/step - loss: 0.3325 - accuracy: 0.8508 - val_loss: 0.3442 - val_accuracy: 0.8474\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3287 - accuracy: 0.8534 - val_loss: 0.3408 - val_accuracy: 0.8470\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3286 - accuracy: 0.8527 - val_loss: 0.3493 - val_accuracy: 0.8470\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 731us/step - loss: 0.3335 - accuracy: 0.8534 - val_loss: 0.3412 - val_accuracy: 0.8460\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 1s 839us/step - loss: 0.3323 - accuracy: 0.8505 - val_loss: 0.3427 - val_accuracy: 0.8470\n",
      "Epoch 52/1000\n",
      "1600/1600 [==============================] - 1s 849us/step - loss: 0.3215 - accuracy: 0.8538 - val_loss: 0.3393 - val_accuracy: 0.8476\n",
      "Epoch 53/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3280 - accuracy: 0.8527 - val_loss: 0.3445 - val_accuracy: 0.8470\n",
      "Epoch 54/1000\n",
      "1600/1600 [==============================] - 1s 792us/step - loss: 0.3253 - accuracy: 0.8566 - val_loss: 0.3390 - val_accuracy: 0.8480\n",
      "Epoch 55/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.8534 - val_loss: 0.3405 - val_accuracy: 0.8470\n",
      "Epoch 56/1000\n",
      "1600/1600 [==============================] - 1s 773us/step - loss: 0.3239 - accuracy: 0.8589 - val_loss: 0.3402 - val_accuracy: 0.8474\n",
      "Epoch 57/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3292 - accuracy: 0.8533 - val_loss: 0.3398 - val_accuracy: 0.8478\n",
      "Epoch 58/1000\n",
      "1600/1600 [==============================] - 1s 808us/step - loss: 0.3249 - accuracy: 0.8552 - val_loss: 0.3425 - val_accuracy: 0.8450\n",
      "Epoch 59/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3269 - accuracy: 0.8558 - val_loss: 0.3440 - val_accuracy: 0.8466\n",
      "Epoch 60/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3284 - accuracy: 0.8562 - val_loss: 0.3404 - val_accuracy: 0.8478\n",
      "Epoch 61/1000\n",
      "1600/1600 [==============================] - 1s 803us/step - loss: 0.3366 - accuracy: 0.8519 - val_loss: 0.3422 - val_accuracy: 0.8482\n",
      "Epoch 62/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3358 - accuracy: 0.8516 - val_loss: 0.3393 - val_accuracy: 0.8478\n",
      "Epoch 63/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3228 - accuracy: 0.8575 - val_loss: 0.3411 - val_accuracy: 0.8478\n",
      "Epoch 64/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3279 - accuracy: 0.8572 - val_loss: 0.3430 - val_accuracy: 0.8478\n",
      "400/400 [==============================] - 0s 690us/step - loss: 0.3390 - accuracy: 0.8500\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 765us/step - loss: 0.4958 - accuracy: 0.7735 - val_loss: 0.3759 - val_accuracy: 0.8162\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3673 - accuracy: 0.8238 - val_loss: 0.3682 - val_accuracy: 0.8256\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3685 - accuracy: 0.8264 - val_loss: 0.3668 - val_accuracy: 0.8300\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3626 - accuracy: 0.8312 - val_loss: 0.3620 - val_accuracy: 0.8236\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3537 - accuracy: 0.8331 - val_loss: 0.3593 - val_accuracy: 0.8262\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3586 - accuracy: 0.8353 - val_loss: 0.3604 - val_accuracy: 0.8258\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3504 - accuracy: 0.8367 - val_loss: 0.3566 - val_accuracy: 0.8342\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 770us/step - loss: 0.3489 - accuracy: 0.8396 - val_loss: 0.3572 - val_accuracy: 0.8370\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3490 - accuracy: 0.8414 - val_loss: 0.3538 - val_accuracy: 0.8356\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3515 - accuracy: 0.8365 - val_loss: 0.3516 - val_accuracy: 0.8344\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3466 - accuracy: 0.8416 - val_loss: 0.3509 - val_accuracy: 0.8410\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3368 - accuracy: 0.8487 - val_loss: 0.3501 - val_accuracy: 0.8386\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 840us/step - loss: 0.3282 - accuracy: 0.8534 - val_loss: 0.3473 - val_accuracy: 0.8406\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 716us/step - loss: 0.3399 - accuracy: 0.8477 - val_loss: 0.3461 - val_accuracy: 0.8428\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3436 - accuracy: 0.8482 - val_loss: 0.3477 - val_accuracy: 0.8434\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 787us/step - loss: 0.3363 - accuracy: 0.8480 - val_loss: 0.3470 - val_accuracy: 0.8394\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 878us/step - loss: 0.3418 - accuracy: 0.8453 - val_loss: 0.3461 - val_accuracy: 0.8462\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 790us/step - loss: 0.3395 - accuracy: 0.8467 - val_loss: 0.3432 - val_accuracy: 0.8442\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3333 - accuracy: 0.8485 - val_loss: 0.3437 - val_accuracy: 0.8418\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.3355 - accuracy: 0.8507 - val_loss: 0.3435 - val_accuracy: 0.8456\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3311 - accuracy: 0.8505 - val_loss: 0.3423 - val_accuracy: 0.8434\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3349 - accuracy: 0.8505 - val_loss: 0.3409 - val_accuracy: 0.8442\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3326 - accuracy: 0.8525 - val_loss: 0.3437 - val_accuracy: 0.8476\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3332 - accuracy: 0.8489 - val_loss: 0.3452 - val_accuracy: 0.8470\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3277 - accuracy: 0.8572 - val_loss: 0.3399 - val_accuracy: 0.8472\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3336 - accuracy: 0.8493 - val_loss: 0.3416 - val_accuracy: 0.8478\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3222 - accuracy: 0.8578 - val_loss: 0.3381 - val_accuracy: 0.8476\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3354 - accuracy: 0.8474 - val_loss: 0.3404 - val_accuracy: 0.8460\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3397 - accuracy: 0.8510 - val_loss: 0.3411 - val_accuracy: 0.8464\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3326 - accuracy: 0.8534 - val_loss: 0.3385 - val_accuracy: 0.8482\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3200 - accuracy: 0.8557 - val_loss: 0.3378 - val_accuracy: 0.8482\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3338 - accuracy: 0.8510 - val_loss: 0.3374 - val_accuracy: 0.8488\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3242 - accuracy: 0.8554 - val_loss: 0.3387 - val_accuracy: 0.8484\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3311 - accuracy: 0.8489 - val_loss: 0.3381 - val_accuracy: 0.8482\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3266 - accuracy: 0.8526 - val_loss: 0.3419 - val_accuracy: 0.8496\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3300 - accuracy: 0.8528 - val_loss: 0.3409 - val_accuracy: 0.8454\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3321 - accuracy: 0.8525 - val_loss: 0.3388 - val_accuracy: 0.8478\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3299 - accuracy: 0.8522 - val_loss: 0.3379 - val_accuracy: 0.8498\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3260 - accuracy: 0.8556 - val_loss: 0.3383 - val_accuracy: 0.8508\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3352 - accuracy: 0.8550 - val_loss: 0.3415 - val_accuracy: 0.8448\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3283 - accuracy: 0.8522 - val_loss: 0.3410 - val_accuracy: 0.8466\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3210 - accuracy: 0.8554 - val_loss: 0.3392 - val_accuracy: 0.8500\n",
      "400/400 [==============================] - 0s 697us/step - loss: 0.3325 - accuracy: 0.8495\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 789us/step - loss: 0.4900 - accuracy: 0.7791 - val_loss: 0.3769 - val_accuracy: 0.8156\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3684 - accuracy: 0.8241 - val_loss: 0.3691 - val_accuracy: 0.8186\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 793us/step - loss: 0.3585 - accuracy: 0.8344 - val_loss: 0.3647 - val_accuracy: 0.8280\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3549 - accuracy: 0.8383 - val_loss: 0.3611 - val_accuracy: 0.8248\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3496 - accuracy: 0.8404 - val_loss: 0.3616 - val_accuracy: 0.8256\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.3487 - accuracy: 0.8399 - val_loss: 0.3588 - val_accuracy: 0.8336\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3481 - accuracy: 0.8400 - val_loss: 0.3549 - val_accuracy: 0.8370\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3463 - accuracy: 0.8438 - val_loss: 0.3534 - val_accuracy: 0.8366\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 746us/step - loss: 0.3445 - accuracy: 0.8447 - val_loss: 0.3512 - val_accuracy: 0.8388\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3447 - accuracy: 0.8474 - val_loss: 0.3494 - val_accuracy: 0.8420\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3479 - accuracy: 0.8471 - val_loss: 0.3500 - val_accuracy: 0.8370\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3297 - accuracy: 0.8507 - val_loss: 0.3455 - val_accuracy: 0.8454\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3392 - accuracy: 0.8509 - val_loss: 0.3455 - val_accuracy: 0.8462\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3369 - accuracy: 0.8537 - val_loss: 0.3457 - val_accuracy: 0.8446\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3405 - accuracy: 0.8467 - val_loss: 0.3448 - val_accuracy: 0.8474\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3367 - accuracy: 0.8491 - val_loss: 0.3451 - val_accuracy: 0.8426\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3306 - accuracy: 0.8546 - val_loss: 0.3423 - val_accuracy: 0.8452\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3242 - accuracy: 0.8575 - val_loss: 0.3432 - val_accuracy: 0.8460\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3337 - accuracy: 0.8514 - val_loss: 0.3424 - val_accuracy: 0.8446\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3288 - accuracy: 0.8566 - val_loss: 0.3413 - val_accuracy: 0.8476\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3341 - accuracy: 0.8532 - val_loss: 0.3433 - val_accuracy: 0.8478\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3275 - accuracy: 0.8539 - val_loss: 0.3440 - val_accuracy: 0.8484\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 670us/step - loss: 0.3300 - accuracy: 0.8543 - val_loss: 0.3414 - val_accuracy: 0.8480\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3336 - accuracy: 0.8523 - val_loss: 0.3426 - val_accuracy: 0.8478\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3277 - accuracy: 0.8542 - val_loss: 0.3432 - val_accuracy: 0.8468\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 716us/step - loss: 0.3325 - accuracy: 0.8558 - val_loss: 0.3448 - val_accuracy: 0.8442\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3408 - accuracy: 0.8489 - val_loss: 0.3437 - val_accuracy: 0.8456\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3318 - accuracy: 0.8504 - val_loss: 0.3417 - val_accuracy: 0.8478\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 688us/step - loss: 0.3307 - accuracy: 0.8514 - val_loss: 0.3422 - val_accuracy: 0.8464\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3241 - accuracy: 0.8556 - val_loss: 0.3414 - val_accuracy: 0.8472\n",
      "400/400 [==============================] - 0s 715us/step - loss: 0.3447 - accuracy: 0.8395\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 745us/step - loss: 0.4762 - accuracy: 0.7841 - val_loss: 0.3748 - val_accuracy: 0.8204\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3667 - accuracy: 0.8277 - val_loss: 0.3680 - val_accuracy: 0.8272\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3735 - accuracy: 0.8235 - val_loss: 0.3639 - val_accuracy: 0.8306\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3636 - accuracy: 0.8275 - val_loss: 0.3629 - val_accuracy: 0.8226\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 783us/step - loss: 0.3611 - accuracy: 0.8308 - val_loss: 0.3587 - val_accuracy: 0.8320\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 883us/step - loss: 0.3570 - accuracy: 0.8357 - val_loss: 0.3559 - val_accuracy: 0.8324\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3491 - accuracy: 0.8401 - val_loss: 0.3529 - val_accuracy: 0.8332\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3480 - accuracy: 0.8396 - val_loss: 0.3518 - val_accuracy: 0.8350\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 647us/step - loss: 0.3458 - accuracy: 0.8416 - val_loss: 0.3510 - val_accuracy: 0.8356\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3424 - accuracy: 0.8461 - val_loss: 0.3490 - val_accuracy: 0.8404\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3522 - accuracy: 0.8412 - val_loss: 0.3465 - val_accuracy: 0.8404\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3411 - accuracy: 0.8454 - val_loss: 0.3468 - val_accuracy: 0.8408\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3406 - accuracy: 0.8485 - val_loss: 0.3481 - val_accuracy: 0.8408\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3343 - accuracy: 0.8463 - val_loss: 0.3458 - val_accuracy: 0.8448\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 670us/step - loss: 0.3360 - accuracy: 0.8453 - val_loss: 0.3452 - val_accuracy: 0.8448\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3325 - accuracy: 0.8528 - val_loss: 0.3432 - val_accuracy: 0.8434\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3392 - accuracy: 0.8463 - val_loss: 0.3435 - val_accuracy: 0.8432\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3251 - accuracy: 0.8550 - val_loss: 0.3414 - val_accuracy: 0.8452\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3314 - accuracy: 0.8547 - val_loss: 0.3422 - val_accuracy: 0.8454\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3330 - accuracy: 0.8562 - val_loss: 0.3416 - val_accuracy: 0.8454\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.3270 - accuracy: 0.8561 - val_loss: 0.3399 - val_accuracy: 0.8468\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3259 - accuracy: 0.8522 - val_loss: 0.3423 - val_accuracy: 0.8450\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3313 - accuracy: 0.8512 - val_loss: 0.3410 - val_accuracy: 0.8462\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3272 - accuracy: 0.8588 - val_loss: 0.3413 - val_accuracy: 0.8462\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.3338 - accuracy: 0.8517 - val_loss: 0.3429 - val_accuracy: 0.8456\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 688us/step - loss: 0.3304 - accuracy: 0.8530 - val_loss: 0.3446 - val_accuracy: 0.8470\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3356 - accuracy: 0.8527 - val_loss: 0.3408 - val_accuracy: 0.8456\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3311 - accuracy: 0.8536 - val_loss: 0.3416 - val_accuracy: 0.8474\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3305 - accuracy: 0.8520 - val_loss: 0.3394 - val_accuracy: 0.8480\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 831us/step - loss: 0.3299 - accuracy: 0.8533 - val_loss: 0.3393 - val_accuracy: 0.8464\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 820us/step - loss: 0.3349 - accuracy: 0.8527 - val_loss: 0.3397 - val_accuracy: 0.8464\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 693us/step - loss: 0.3198 - accuracy: 0.8586 - val_loss: 0.3402 - val_accuracy: 0.8468\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 665us/step - loss: 0.3304 - accuracy: 0.8510 - val_loss: 0.3400 - val_accuracy: 0.8464\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 746us/step - loss: 0.3254 - accuracy: 0.8557 - val_loss: 0.3410 - val_accuracy: 0.8478\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3311 - accuracy: 0.8515 - val_loss: 0.3430 - val_accuracy: 0.8464\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3308 - accuracy: 0.8533 - val_loss: 0.3407 - val_accuracy: 0.8474\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 806us/step - loss: 0.3280 - accuracy: 0.8530 - val_loss: 0.3453 - val_accuracy: 0.8468\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 817us/step - loss: 0.3351 - accuracy: 0.8505 - val_loss: 0.3434 - val_accuracy: 0.8460\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3296 - accuracy: 0.8521 - val_loss: 0.3399 - val_accuracy: 0.8476\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3319 - accuracy: 0.8527 - val_loss: 0.3421 - val_accuracy: 0.8472\n",
      "400/400 [==============================] - 0s 737us/step - loss: 0.3288 - accuracy: 0.8522\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.4781 - accuracy: 0.7757 - val_loss: 0.3780 - val_accuracy: 0.8176\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3729 - accuracy: 0.8234 - val_loss: 0.3699 - val_accuracy: 0.8188\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3708 - accuracy: 0.8240 - val_loss: 0.3661 - val_accuracy: 0.8216\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 663us/step - loss: 0.3675 - accuracy: 0.8291 - val_loss: 0.3625 - val_accuracy: 0.8238\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3548 - accuracy: 0.8344 - val_loss: 0.3602 - val_accuracy: 0.8250\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 751us/step - loss: 0.3652 - accuracy: 0.8292 - val_loss: 0.3612 - val_accuracy: 0.8318\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3619 - accuracy: 0.8320 - val_loss: 0.3570 - val_accuracy: 0.8302\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3568 - accuracy: 0.8330 - val_loss: 0.3568 - val_accuracy: 0.8328\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3487 - accuracy: 0.8400 - val_loss: 0.3560 - val_accuracy: 0.8322\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 660us/step - loss: 0.3624 - accuracy: 0.8331 - val_loss: 0.3559 - val_accuracy: 0.8336\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 676us/step - loss: 0.3523 - accuracy: 0.8352 - val_loss: 0.3545 - val_accuracy: 0.8304\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 653us/step - loss: 0.3552 - accuracy: 0.8364 - val_loss: 0.3543 - val_accuracy: 0.8304\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3441 - accuracy: 0.8440 - val_loss: 0.3539 - val_accuracy: 0.8310\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3551 - accuracy: 0.8375 - val_loss: 0.3537 - val_accuracy: 0.8308\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3551 - accuracy: 0.8401 - val_loss: 0.3542 - val_accuracy: 0.8296\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 670us/step - loss: 0.3487 - accuracy: 0.8378 - val_loss: 0.3521 - val_accuracy: 0.8334\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3481 - accuracy: 0.8392 - val_loss: 0.3505 - val_accuracy: 0.8362\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3494 - accuracy: 0.8386 - val_loss: 0.3511 - val_accuracy: 0.8390\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 889us/step - loss: 0.3468 - accuracy: 0.8411 - val_loss: 0.3499 - val_accuracy: 0.8348\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 670us/step - loss: 0.3469 - accuracy: 0.8409 - val_loss: 0.3497 - val_accuracy: 0.8350\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3370 - accuracy: 0.8470 - val_loss: 0.3473 - val_accuracy: 0.8400\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3417 - accuracy: 0.8459 - val_loss: 0.3473 - val_accuracy: 0.8426\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3422 - accuracy: 0.8423 - val_loss: 0.3463 - val_accuracy: 0.8400\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 673us/step - loss: 0.3358 - accuracy: 0.8519 - val_loss: 0.3478 - val_accuracy: 0.8408\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3382 - accuracy: 0.8478 - val_loss: 0.3453 - val_accuracy: 0.8408\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3350 - accuracy: 0.8495 - val_loss: 0.3443 - val_accuracy: 0.8410\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3385 - accuracy: 0.8482 - val_loss: 0.3475 - val_accuracy: 0.8416\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3363 - accuracy: 0.8519 - val_loss: 0.3456 - val_accuracy: 0.8408\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3382 - accuracy: 0.8491 - val_loss: 0.3431 - val_accuracy: 0.8456\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 676us/step - loss: 0.3349 - accuracy: 0.8501 - val_loss: 0.3434 - val_accuracy: 0.8444\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3371 - accuracy: 0.8493 - val_loss: 0.3463 - val_accuracy: 0.8470\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 665us/step - loss: 0.3378 - accuracy: 0.8513 - val_loss: 0.3483 - val_accuracy: 0.8438\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3404 - accuracy: 0.8461 - val_loss: 0.3445 - val_accuracy: 0.8450\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3421 - accuracy: 0.8430 - val_loss: 0.3426 - val_accuracy: 0.8430\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3361 - accuracy: 0.8502 - val_loss: 0.3413 - val_accuracy: 0.8456\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3397 - accuracy: 0.8484 - val_loss: 0.3434 - val_accuracy: 0.8446\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3379 - accuracy: 0.8463 - val_loss: 0.3410 - val_accuracy: 0.8460\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3370 - accuracy: 0.8508 - val_loss: 0.3421 - val_accuracy: 0.8458\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3315 - accuracy: 0.8505 - val_loss: 0.3433 - val_accuracy: 0.8474\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3353 - accuracy: 0.8483 - val_loss: 0.3409 - val_accuracy: 0.8456\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3371 - accuracy: 0.8496 - val_loss: 0.3418 - val_accuracy: 0.8448\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3333 - accuracy: 0.8536 - val_loss: 0.3412 - val_accuracy: 0.8440\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 683us/step - loss: 0.3289 - accuracy: 0.8557 - val_loss: 0.3403 - val_accuracy: 0.8466\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3395 - accuracy: 0.8494 - val_loss: 0.3406 - val_accuracy: 0.8442\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3361 - accuracy: 0.8514 - val_loss: 0.3433 - val_accuracy: 0.8438\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3368 - accuracy: 0.8512 - val_loss: 0.3404 - val_accuracy: 0.8460\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3350 - accuracy: 0.8504 - val_loss: 0.3423 - val_accuracy: 0.8468\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 688us/step - loss: 0.3269 - accuracy: 0.8516 - val_loss: 0.3412 - val_accuracy: 0.8436\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3294 - accuracy: 0.8569 - val_loss: 0.3398 - val_accuracy: 0.8464\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3383 - accuracy: 0.8510 - val_loss: 0.3445 - val_accuracy: 0.8476\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 1s 816us/step - loss: 0.3294 - accuracy: 0.8544 - val_loss: 0.3420 - val_accuracy: 0.8464\n",
      "Epoch 52/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3368 - accuracy: 0.8507 - val_loss: 0.3393 - val_accuracy: 0.8474\n",
      "Epoch 53/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3426 - accuracy: 0.8448 - val_loss: 0.3415 - val_accuracy: 0.8472\n",
      "Epoch 54/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3302 - accuracy: 0.8519 - val_loss: 0.3397 - val_accuracy: 0.8458\n",
      "Epoch 55/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3387 - accuracy: 0.8490 - val_loss: 0.3547 - val_accuracy: 0.8462\n",
      "Epoch 56/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3327 - accuracy: 0.8512 - val_loss: 0.3386 - val_accuracy: 0.8462\n",
      "Epoch 57/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3264 - accuracy: 0.8515 - val_loss: 0.3393 - val_accuracy: 0.8456\n",
      "Epoch 58/1000\n",
      "1600/1600 [==============================] - 1s 676us/step - loss: 0.3348 - accuracy: 0.8549 - val_loss: 0.3384 - val_accuracy: 0.8462\n",
      "Epoch 59/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3291 - accuracy: 0.8548 - val_loss: 0.3381 - val_accuracy: 0.8474\n",
      "Epoch 60/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3314 - accuracy: 0.8537 - val_loss: 0.3392 - val_accuracy: 0.8476\n",
      "Epoch 61/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3301 - accuracy: 0.8548 - val_loss: 0.3401 - val_accuracy: 0.8462\n",
      "Epoch 62/1000\n",
      "1600/1600 [==============================] - 1s 900us/step - loss: 0.3338 - accuracy: 0.8503 - val_loss: 0.3382 - val_accuracy: 0.8456\n",
      "Epoch 63/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3273 - accuracy: 0.8565 - val_loss: 0.3415 - val_accuracy: 0.8446\n",
      "Epoch 64/1000\n",
      "1600/1600 [==============================] - 1s 833us/step - loss: 0.3347 - accuracy: 0.8527 - val_loss: 0.3483 - val_accuracy: 0.8456\n",
      "Epoch 65/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3280 - accuracy: 0.8530 - val_loss: 0.3411 - val_accuracy: 0.8424\n",
      "Epoch 66/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3366 - accuracy: 0.8492 - val_loss: 0.3421 - val_accuracy: 0.8436\n",
      "Epoch 67/1000\n",
      "1600/1600 [==============================] - 1s 663us/step - loss: 0.3320 - accuracy: 0.8479 - val_loss: 0.3412 - val_accuracy: 0.8424\n",
      "Epoch 68/1000\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.3297 - accuracy: 0.8526 - val_loss: 0.3387 - val_accuracy: 0.8448\n",
      "Epoch 69/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3302 - accuracy: 0.8514 - val_loss: 0.3431 - val_accuracy: 0.8448\n",
      "400/400 [==============================] - 0s 735us/step - loss: 0.3270 - accuracy: 0.8530\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 964us/step - loss: 0.4797 - accuracy: 0.7831 - val_loss: 0.3767 - val_accuracy: 0.8138\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3737 - accuracy: 0.8219 - val_loss: 0.3679 - val_accuracy: 0.8214\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 839us/step - loss: 0.3604 - accuracy: 0.8322 - val_loss: 0.3646 - val_accuracy: 0.8276\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 683us/step - loss: 0.3560 - accuracy: 0.8303 - val_loss: 0.3628 - val_accuracy: 0.8230\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3575 - accuracy: 0.8290 - val_loss: 0.3591 - val_accuracy: 0.8316\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3467 - accuracy: 0.8384 - val_loss: 0.3575 - val_accuracy: 0.8334\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3546 - accuracy: 0.8338 - val_loss: 0.3579 - val_accuracy: 0.8270\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3432 - accuracy: 0.8417 - val_loss: 0.3543 - val_accuracy: 0.8322\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 649us/step - loss: 0.3485 - accuracy: 0.8396 - val_loss: 0.3543 - val_accuracy: 0.8322\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3466 - accuracy: 0.8401 - val_loss: 0.3535 - val_accuracy: 0.8330\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3410 - accuracy: 0.8443 - val_loss: 0.3522 - val_accuracy: 0.8376\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 668us/step - loss: 0.3483 - accuracy: 0.8412 - val_loss: 0.3502 - val_accuracy: 0.8378\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 659us/step - loss: 0.3391 - accuracy: 0.8472 - val_loss: 0.3482 - val_accuracy: 0.8408\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3490 - accuracy: 0.8405 - val_loss: 0.3498 - val_accuracy: 0.8412\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3356 - accuracy: 0.8488 - val_loss: 0.3482 - val_accuracy: 0.8394\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 928us/step - loss: 0.3433 - accuracy: 0.8439 - val_loss: 0.3475 - val_accuracy: 0.8418\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3369 - accuracy: 0.8471 - val_loss: 0.3487 - val_accuracy: 0.8376\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3364 - accuracy: 0.8500 - val_loss: 0.3450 - val_accuracy: 0.8406\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 683us/step - loss: 0.3402 - accuracy: 0.8450 - val_loss: 0.3474 - val_accuracy: 0.8436\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3356 - accuracy: 0.8481 - val_loss: 0.3434 - val_accuracy: 0.8442\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3377 - accuracy: 0.8447 - val_loss: 0.3440 - val_accuracy: 0.8420\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 888us/step - loss: 0.3411 - accuracy: 0.8473 - val_loss: 0.3467 - val_accuracy: 0.8432\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.3376 - accuracy: 0.8485 - val_loss: 0.3423 - val_accuracy: 0.8462\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3352 - accuracy: 0.8531 - val_loss: 0.3449 - val_accuracy: 0.8436\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3289 - accuracy: 0.8548 - val_loss: 0.3437 - val_accuracy: 0.8448\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3342 - accuracy: 0.8481 - val_loss: 0.3424 - val_accuracy: 0.8450\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3289 - accuracy: 0.8556 - val_loss: 0.3423 - val_accuracy: 0.8470\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3410 - accuracy: 0.8444 - val_loss: 0.3413 - val_accuracy: 0.8458\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3395 - accuracy: 0.8473 - val_loss: 0.3443 - val_accuracy: 0.8466\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3253 - accuracy: 0.8558 - val_loss: 0.3416 - val_accuracy: 0.8456\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3316 - accuracy: 0.8502 - val_loss: 0.3455 - val_accuracy: 0.8464\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 863us/step - loss: 0.3346 - accuracy: 0.8515 - val_loss: 0.3431 - val_accuracy: 0.8470\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3212 - accuracy: 0.8562 - val_loss: 0.3417 - val_accuracy: 0.8472\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3265 - accuracy: 0.8547 - val_loss: 0.3427 - val_accuracy: 0.8436\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 664us/step - loss: 0.3255 - accuracy: 0.8531 - val_loss: 0.3401 - val_accuracy: 0.8482\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 664us/step - loss: 0.3294 - accuracy: 0.8517 - val_loss: 0.3417 - val_accuracy: 0.8474\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3192 - accuracy: 0.8623 - val_loss: 0.3396 - val_accuracy: 0.8470\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3324 - accuracy: 0.8489 - val_loss: 0.3435 - val_accuracy: 0.8460\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3308 - accuracy: 0.8529 - val_loss: 0.3413 - val_accuracy: 0.8458\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3227 - accuracy: 0.8568 - val_loss: 0.3442 - val_accuracy: 0.8474\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3335 - accuracy: 0.8534 - val_loss: 0.3402 - val_accuracy: 0.8470\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 2s 966us/step - loss: 0.3240 - accuracy: 0.8510 - val_loss: 0.3406 - val_accuracy: 0.8462\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3315 - accuracy: 0.8492 - val_loss: 0.3420 - val_accuracy: 0.8454\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3287 - accuracy: 0.8516 - val_loss: 0.3399 - val_accuracy: 0.8474\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3262 - accuracy: 0.8543 - val_loss: 0.3445 - val_accuracy: 0.8470\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 661us/step - loss: 0.3276 - accuracy: 0.8580 - val_loss: 0.3399 - val_accuracy: 0.8468\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3316 - accuracy: 0.8503 - val_loss: 0.3401 - val_accuracy: 0.8458\n",
      "400/400 [==============================] - 0s 705us/step - loss: 0.3389 - accuracy: 0.8530\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 763us/step - loss: 0.4707 - accuracy: 0.7695 - val_loss: 0.3866 - val_accuracy: 0.8194\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3912 - accuracy: 0.8180 - val_loss: 0.3798 - val_accuracy: 0.8210\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3804 - accuracy: 0.8257 - val_loss: 0.3777 - val_accuracy: 0.8206\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3719 - accuracy: 0.8306 - val_loss: 0.3731 - val_accuracy: 0.8242\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3677 - accuracy: 0.8276 - val_loss: 0.3703 - val_accuracy: 0.8216\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 920us/step - loss: 0.3654 - accuracy: 0.8294 - val_loss: 0.3689 - val_accuracy: 0.8222\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3604 - accuracy: 0.8327 - val_loss: 0.3685 - val_accuracy: 0.8226\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3675 - accuracy: 0.8266 - val_loss: 0.3663 - val_accuracy: 0.8228\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3630 - accuracy: 0.8305 - val_loss: 0.3640 - val_accuracy: 0.8258\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3604 - accuracy: 0.8328 - val_loss: 0.3640 - val_accuracy: 0.8274\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3522 - accuracy: 0.8413 - val_loss: 0.3637 - val_accuracy: 0.8272\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3557 - accuracy: 0.8336 - val_loss: 0.3639 - val_accuracy: 0.8282\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3642 - accuracy: 0.8321 - val_loss: 0.3653 - val_accuracy: 0.8226\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3585 - accuracy: 0.8321 - val_loss: 0.3632 - val_accuracy: 0.8248\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 840us/step - loss: 0.3578 - accuracy: 0.8376 - val_loss: 0.3641 - val_accuracy: 0.8288\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3540 - accuracy: 0.8392 - val_loss: 0.3687 - val_accuracy: 0.8336\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 908us/step - loss: 0.3533 - accuracy: 0.8387 - val_loss: 0.3632 - val_accuracy: 0.8238\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 823us/step - loss: 0.3550 - accuracy: 0.8366 - val_loss: 0.3632 - val_accuracy: 0.8300\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3604 - accuracy: 0.8317 - val_loss: 0.3642 - val_accuracy: 0.8244\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3559 - accuracy: 0.8383 - val_loss: 0.3631 - val_accuracy: 0.8298\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3562 - accuracy: 0.8310 - val_loss: 0.3596 - val_accuracy: 0.8286\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3527 - accuracy: 0.8395 - val_loss: 0.3590 - val_accuracy: 0.8302\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3541 - accuracy: 0.8387 - val_loss: 0.3596 - val_accuracy: 0.8266\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3469 - accuracy: 0.8394 - val_loss: 0.3589 - val_accuracy: 0.8272\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3544 - accuracy: 0.8369 - val_loss: 0.3612 - val_accuracy: 0.8260\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3591 - accuracy: 0.8409 - val_loss: 0.3635 - val_accuracy: 0.8330\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3584 - accuracy: 0.8357 - val_loss: 0.3591 - val_accuracy: 0.8304\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 816us/step - loss: 0.3531 - accuracy: 0.8433 - val_loss: 0.3648 - val_accuracy: 0.8318\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 2s 938us/step - loss: 0.3588 - accuracy: 0.8382 - val_loss: 0.3594 - val_accuracy: 0.8328\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 807us/step - loss: 0.3489 - accuracy: 0.8404 - val_loss: 0.3593 - val_accuracy: 0.8292\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3603 - accuracy: 0.8353 - val_loss: 0.3609 - val_accuracy: 0.8278\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 688us/step - loss: 0.3586 - accuracy: 0.8362 - val_loss: 0.3597 - val_accuracy: 0.8268\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3585 - accuracy: 0.8385 - val_loss: 0.3619 - val_accuracy: 0.8268\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3548 - accuracy: 0.8360 - val_loss: 0.3597 - val_accuracy: 0.8304\n",
      "400/400 [==============================] - 0s 690us/step - loss: 0.3594 - accuracy: 0.8325\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 896us/step - loss: 0.4756 - accuracy: 0.7848 - val_loss: 0.3771 - val_accuracy: 0.8212\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3634 - accuracy: 0.8305 - val_loss: 0.3748 - val_accuracy: 0.8274\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3572 - accuracy: 0.8331 - val_loss: 0.3632 - val_accuracy: 0.8302\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3635 - accuracy: 0.8317 - val_loss: 0.3615 - val_accuracy: 0.8250\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3593 - accuracy: 0.8327 - val_loss: 0.3584 - val_accuracy: 0.8318\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 783us/step - loss: 0.3546 - accuracy: 0.8390 - val_loss: 0.3560 - val_accuracy: 0.8352\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3470 - accuracy: 0.8391 - val_loss: 0.3570 - val_accuracy: 0.8394\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 985us/step - loss: 0.3438 - accuracy: 0.8435 - val_loss: 0.3535 - val_accuracy: 0.8334\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3443 - accuracy: 0.8467 - val_loss: 0.3501 - val_accuracy: 0.8370\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3405 - accuracy: 0.8463 - val_loss: 0.3477 - val_accuracy: 0.8420\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 735us/step - loss: 0.3437 - accuracy: 0.8476 - val_loss: 0.3459 - val_accuracy: 0.8410\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 668us/step - loss: 0.3452 - accuracy: 0.8468 - val_loss: 0.3466 - val_accuracy: 0.8424\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3329 - accuracy: 0.8528 - val_loss: 0.3478 - val_accuracy: 0.8374\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3453 - accuracy: 0.8452 - val_loss: 0.3443 - val_accuracy: 0.8470\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 790us/step - loss: 0.3323 - accuracy: 0.8498 - val_loss: 0.3428 - val_accuracy: 0.8444\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 848us/step - loss: 0.3453 - accuracy: 0.8433 - val_loss: 0.3461 - val_accuracy: 0.8428\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 821us/step - loss: 0.3392 - accuracy: 0.8510 - val_loss: 0.3449 - val_accuracy: 0.8468\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3292 - accuracy: 0.8549 - val_loss: 0.3443 - val_accuracy: 0.8462\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 827us/step - loss: 0.3347 - accuracy: 0.8524 - val_loss: 0.3436 - val_accuracy: 0.8448\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 861us/step - loss: 0.3310 - accuracy: 0.8567 - val_loss: 0.3420 - val_accuracy: 0.8444\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 751us/step - loss: 0.3310 - accuracy: 0.8533 - val_loss: 0.3464 - val_accuracy: 0.8470\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3264 - accuracy: 0.8527 - val_loss: 0.3415 - val_accuracy: 0.8458\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3306 - accuracy: 0.8546 - val_loss: 0.3422 - val_accuracy: 0.8478\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3324 - accuracy: 0.8488 - val_loss: 0.3412 - val_accuracy: 0.8484\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3280 - accuracy: 0.8576 - val_loss: 0.3421 - val_accuracy: 0.8458\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3296 - accuracy: 0.8556 - val_loss: 0.3445 - val_accuracy: 0.8474\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3351 - accuracy: 0.8528 - val_loss: 0.3458 - val_accuracy: 0.8448\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 678us/step - loss: 0.3373 - accuracy: 0.8505 - val_loss: 0.3453 - val_accuracy: 0.8442\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3333 - accuracy: 0.8538 - val_loss: 0.3412 - val_accuracy: 0.8468\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 2s 984us/step - loss: 0.3356 - accuracy: 0.8491 - val_loss: 0.3433 - val_accuracy: 0.8482\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3236 - accuracy: 0.8571 - val_loss: 0.3421 - val_accuracy: 0.8472\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 754us/step - loss: 0.3343 - accuracy: 0.8511 - val_loss: 0.3448 - val_accuracy: 0.8482\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3252 - accuracy: 0.8594 - val_loss: 0.3479 - val_accuracy: 0.8478\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 661us/step - loss: 0.3261 - accuracy: 0.8535 - val_loss: 0.3424 - val_accuracy: 0.8478\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 763us/step - loss: 0.3265 - accuracy: 0.8567 - val_loss: 0.3423 - val_accuracy: 0.8468\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 848us/step - loss: 0.3311 - accuracy: 0.8547 - val_loss: 0.3437 - val_accuracy: 0.8460\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 782us/step - loss: 0.3353 - accuracy: 0.8494 - val_loss: 0.3433 - val_accuracy: 0.8470\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3271 - accuracy: 0.8580 - val_loss: 0.3493 - val_accuracy: 0.8476\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3330 - accuracy: 0.8532 - val_loss: 0.3441 - val_accuracy: 0.8462\n",
      "400/400 [==============================] - 0s 700us/step - loss: 0.3414 - accuracy: 0.8422\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 765us/step - loss: 0.4756 - accuracy: 0.7780 - val_loss: 0.3745 - val_accuracy: 0.8174\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3712 - accuracy: 0.8243 - val_loss: 0.3692 - val_accuracy: 0.8210\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3626 - accuracy: 0.8270 - val_loss: 0.3650 - val_accuracy: 0.8292\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 900us/step - loss: 0.3693 - accuracy: 0.8254 - val_loss: 0.3630 - val_accuracy: 0.8232\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3608 - accuracy: 0.8289 - val_loss: 0.3600 - val_accuracy: 0.8254\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3546 - accuracy: 0.8345 - val_loss: 0.3599 - val_accuracy: 0.8266\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 806us/step - loss: 0.3538 - accuracy: 0.8343 - val_loss: 0.3565 - val_accuracy: 0.8310\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3476 - accuracy: 0.8401 - val_loss: 0.3537 - val_accuracy: 0.8326\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3517 - accuracy: 0.8387 - val_loss: 0.3543 - val_accuracy: 0.8322\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 688us/step - loss: 0.3463 - accuracy: 0.8412 - val_loss: 0.3528 - val_accuracy: 0.8342\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3419 - accuracy: 0.8451 - val_loss: 0.3504 - val_accuracy: 0.8392\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3542 - accuracy: 0.8378 - val_loss: 0.3524 - val_accuracy: 0.8440\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3435 - accuracy: 0.8424 - val_loss: 0.3543 - val_accuracy: 0.8324\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3431 - accuracy: 0.8434 - val_loss: 0.3464 - val_accuracy: 0.8422\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3360 - accuracy: 0.8481 - val_loss: 0.3460 - val_accuracy: 0.8434\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3457 - accuracy: 0.8427 - val_loss: 0.3470 - val_accuracy: 0.8438\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3424 - accuracy: 0.8456 - val_loss: 0.3459 - val_accuracy: 0.8424\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 807us/step - loss: 0.3354 - accuracy: 0.8494 - val_loss: 0.3441 - val_accuracy: 0.8426\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 765us/step - loss: 0.3432 - accuracy: 0.8472 - val_loss: 0.3453 - val_accuracy: 0.8446\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3315 - accuracy: 0.8485 - val_loss: 0.3410 - val_accuracy: 0.8468\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3375 - accuracy: 0.8477 - val_loss: 0.3414 - val_accuracy: 0.8454\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3352 - accuracy: 0.8512 - val_loss: 0.3483 - val_accuracy: 0.8394\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3376 - accuracy: 0.8466 - val_loss: 0.3419 - val_accuracy: 0.8460\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 783us/step - loss: 0.3360 - accuracy: 0.8495 - val_loss: 0.3490 - val_accuracy: 0.8478\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3317 - accuracy: 0.8487 - val_loss: 0.3412 - val_accuracy: 0.8434\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3240 - accuracy: 0.8554 - val_loss: 0.3426 - val_accuracy: 0.8450\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3409 - accuracy: 0.8469 - val_loss: 0.3399 - val_accuracy: 0.8462\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.3298 - accuracy: 0.8550 - val_loss: 0.3391 - val_accuracy: 0.8466\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 928us/step - loss: 0.3278 - accuracy: 0.8512 - val_loss: 0.3393 - val_accuracy: 0.8474\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3320 - accuracy: 0.8504 - val_loss: 0.3422 - val_accuracy: 0.8488\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3260 - accuracy: 0.8535 - val_loss: 0.3397 - val_accuracy: 0.8460\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3306 - accuracy: 0.8518 - val_loss: 0.3424 - val_accuracy: 0.8452\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3347 - accuracy: 0.8503 - val_loss: 0.3413 - val_accuracy: 0.8478\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3261 - accuracy: 0.8529 - val_loss: 0.3385 - val_accuracy: 0.8486\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 821us/step - loss: 0.3317 - accuracy: 0.8534 - val_loss: 0.3404 - val_accuracy: 0.8486\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.3366 - accuracy: 0.8505 - val_loss: 0.3393 - val_accuracy: 0.8464\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3285 - accuracy: 0.8572 - val_loss: 0.3397 - val_accuracy: 0.8478\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3230 - accuracy: 0.8574 - val_loss: 0.3403 - val_accuracy: 0.8484\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3342 - accuracy: 0.8555 - val_loss: 0.3412 - val_accuracy: 0.8468\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3282 - accuracy: 0.8563 - val_loss: 0.3386 - val_accuracy: 0.8484\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 926us/step - loss: 0.3416 - accuracy: 0.8496 - val_loss: 0.3395 - val_accuracy: 0.8488\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 898us/step - loss: 0.3368 - accuracy: 0.8482 - val_loss: 0.3396 - val_accuracy: 0.8488\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3321 - accuracy: 0.8518 - val_loss: 0.3383 - val_accuracy: 0.8482\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 801us/step - loss: 0.3287 - accuracy: 0.8577 - val_loss: 0.3387 - val_accuracy: 0.8502\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3342 - accuracy: 0.8526 - val_loss: 0.3381 - val_accuracy: 0.8504\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3363 - accuracy: 0.8497 - val_loss: 0.3461 - val_accuracy: 0.8500\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3414 - accuracy: 0.8510 - val_loss: 0.3420 - val_accuracy: 0.8498\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3326 - accuracy: 0.8551 - val_loss: 0.3397 - val_accuracy: 0.8486\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 822us/step - loss: 0.3311 - accuracy: 0.8525 - val_loss: 0.3394 - val_accuracy: 0.8486\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 665us/step - loss: 0.3307 - accuracy: 0.8544 - val_loss: 0.3380 - val_accuracy: 0.8504\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3306 - accuracy: 0.8551 - val_loss: 0.3398 - val_accuracy: 0.8502\n",
      "Epoch 52/1000\n",
      "1600/1600 [==============================] - 1s 907us/step - loss: 0.3331 - accuracy: 0.8513 - val_loss: 0.3395 - val_accuracy: 0.8488\n",
      "Epoch 53/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3398 - accuracy: 0.8501 - val_loss: 0.3398 - val_accuracy: 0.8496\n",
      "Epoch 54/1000\n",
      "1600/1600 [==============================] - 1s 693us/step - loss: 0.3348 - accuracy: 0.8543 - val_loss: 0.3379 - val_accuracy: 0.8512\n",
      "Epoch 55/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3224 - accuracy: 0.8595 - val_loss: 0.3377 - val_accuracy: 0.8498\n",
      "Epoch 56/1000\n",
      "1600/1600 [==============================] - 1s 731us/step - loss: 0.3296 - accuracy: 0.8545 - val_loss: 0.3394 - val_accuracy: 0.8488\n",
      "Epoch 57/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3297 - accuracy: 0.8552 - val_loss: 0.3401 - val_accuracy: 0.8494\n",
      "Epoch 58/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3267 - accuracy: 0.8555 - val_loss: 0.3381 - val_accuracy: 0.8522\n",
      "Epoch 59/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3311 - accuracy: 0.8526 - val_loss: 0.3367 - val_accuracy: 0.8504\n",
      "Epoch 60/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3288 - accuracy: 0.8583 - val_loss: 0.3367 - val_accuracy: 0.8482\n",
      "Epoch 61/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3298 - accuracy: 0.8581 - val_loss: 0.3373 - val_accuracy: 0.8508\n",
      "Epoch 62/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3353 - accuracy: 0.8532 - val_loss: 0.3412 - val_accuracy: 0.8468\n",
      "Epoch 63/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3245 - accuracy: 0.8574 - val_loss: 0.3385 - val_accuracy: 0.8504\n",
      "Epoch 64/1000\n",
      "1600/1600 [==============================] - 1s 823us/step - loss: 0.3377 - accuracy: 0.8513 - val_loss: 0.3365 - val_accuracy: 0.8502\n",
      "Epoch 65/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3303 - accuracy: 0.8576 - val_loss: 0.3408 - val_accuracy: 0.8508\n",
      "Epoch 66/1000\n",
      "1600/1600 [==============================] - 1s 759us/step - loss: 0.3258 - accuracy: 0.8549 - val_loss: 0.3421 - val_accuracy: 0.8472\n",
      "Epoch 67/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3346 - accuracy: 0.8538 - val_loss: 0.3400 - val_accuracy: 0.8494\n",
      "Epoch 68/1000\n",
      "1600/1600 [==============================] - 1s 688us/step - loss: 0.3318 - accuracy: 0.8519 - val_loss: 0.3428 - val_accuracy: 0.8500\n",
      "Epoch 69/1000\n",
      "1600/1600 [==============================] - 1s 735us/step - loss: 0.3292 - accuracy: 0.8563 - val_loss: 0.3356 - val_accuracy: 0.8512\n",
      "Epoch 70/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3241 - accuracy: 0.8598 - val_loss: 0.3447 - val_accuracy: 0.8464\n",
      "Epoch 71/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3327 - accuracy: 0.8524 - val_loss: 0.3374 - val_accuracy: 0.8496\n",
      "Epoch 72/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3269 - accuracy: 0.8562 - val_loss: 0.3396 - val_accuracy: 0.8500\n",
      "Epoch 73/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3238 - accuracy: 0.8581 - val_loss: 0.3366 - val_accuracy: 0.8506\n",
      "Epoch 74/1000\n",
      "1600/1600 [==============================] - 1s 868us/step - loss: 0.3194 - accuracy: 0.8610 - val_loss: 0.3456 - val_accuracy: 0.8514\n",
      "Epoch 75/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3276 - accuracy: 0.8578 - val_loss: 0.3383 - val_accuracy: 0.8486\n",
      "Epoch 76/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3350 - accuracy: 0.8512 - val_loss: 0.3395 - val_accuracy: 0.8500\n",
      "Epoch 77/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3266 - accuracy: 0.8595 - val_loss: 0.3357 - val_accuracy: 0.8500\n",
      "Epoch 78/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3254 - accuracy: 0.8591 - val_loss: 0.3508 - val_accuracy: 0.8514\n",
      "Epoch 79/1000\n",
      "1600/1600 [==============================] - 2s 947us/step - loss: 0.3320 - accuracy: 0.8551 - val_loss: 0.3411 - val_accuracy: 0.8508\n",
      "400/400 [==============================] - 0s 840us/step - loss: 0.3279 - accuracy: 0.8510\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 755us/step - loss: 0.4767 - accuracy: 0.7802 - val_loss: 0.3769 - val_accuracy: 0.8166\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 664us/step - loss: 0.3682 - accuracy: 0.8259 - val_loss: 0.3693 - val_accuracy: 0.8278\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 665us/step - loss: 0.3737 - accuracy: 0.8186 - val_loss: 0.3635 - val_accuracy: 0.8246\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3522 - accuracy: 0.8364 - val_loss: 0.3601 - val_accuracy: 0.8274\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 661us/step - loss: 0.3679 - accuracy: 0.8266 - val_loss: 0.3581 - val_accuracy: 0.8318\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 657us/step - loss: 0.3564 - accuracy: 0.8337 - val_loss: 0.3548 - val_accuracy: 0.8316\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3578 - accuracy: 0.8327 - val_loss: 0.3544 - val_accuracy: 0.8318\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3482 - accuracy: 0.8420 - val_loss: 0.3496 - val_accuracy: 0.8382\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 670us/step - loss: 0.3400 - accuracy: 0.8446 - val_loss: 0.3482 - val_accuracy: 0.8364\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 904us/step - loss: 0.3452 - accuracy: 0.8469 - val_loss: 0.3486 - val_accuracy: 0.8398\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3480 - accuracy: 0.8407 - val_loss: 0.3451 - val_accuracy: 0.8420\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 831us/step - loss: 0.3473 - accuracy: 0.8469 - val_loss: 0.3496 - val_accuracy: 0.8440\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3511 - accuracy: 0.8399 - val_loss: 0.3439 - val_accuracy: 0.8452\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3350 - accuracy: 0.8490 - val_loss: 0.3433 - val_accuracy: 0.8462\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 772us/step - loss: 0.3366 - accuracy: 0.8511 - val_loss: 0.3428 - val_accuracy: 0.8466\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 805us/step - loss: 0.3259 - accuracy: 0.8541 - val_loss: 0.3454 - val_accuracy: 0.8470\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 807us/step - loss: 0.3405 - accuracy: 0.8479 - val_loss: 0.3460 - val_accuracy: 0.8458\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3326 - accuracy: 0.8531 - val_loss: 0.3426 - val_accuracy: 0.8442\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3381 - accuracy: 0.8507 - val_loss: 0.3455 - val_accuracy: 0.8426\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3342 - accuracy: 0.8532 - val_loss: 0.3427 - val_accuracy: 0.8458\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3321 - accuracy: 0.8507 - val_loss: 0.3431 - val_accuracy: 0.8442\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3295 - accuracy: 0.8504 - val_loss: 0.3424 - val_accuracy: 0.8458\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3308 - accuracy: 0.8519 - val_loss: 0.3429 - val_accuracy: 0.8450\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3281 - accuracy: 0.8520 - val_loss: 0.3415 - val_accuracy: 0.8468\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 662us/step - loss: 0.3390 - accuracy: 0.8488 - val_loss: 0.3434 - val_accuracy: 0.8456\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 867us/step - loss: 0.3339 - accuracy: 0.8495 - val_loss: 0.3424 - val_accuracy: 0.8476\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3272 - accuracy: 0.8573 - val_loss: 0.3437 - val_accuracy: 0.8472\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 788us/step - loss: 0.3381 - accuracy: 0.8492 - val_loss: 0.3419 - val_accuracy: 0.8454\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 805us/step - loss: 0.3357 - accuracy: 0.8468 - val_loss: 0.3426 - val_accuracy: 0.8452\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3286 - accuracy: 0.8506 - val_loss: 0.3441 - val_accuracy: 0.8448\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 661us/step - loss: 0.3345 - accuracy: 0.8504 - val_loss: 0.3429 - val_accuracy: 0.8454\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 656us/step - loss: 0.3338 - accuracy: 0.8494 - val_loss: 0.3470 - val_accuracy: 0.8484\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3318 - accuracy: 0.8512 - val_loss: 0.3420 - val_accuracy: 0.8462\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 673us/step - loss: 0.3395 - accuracy: 0.8478 - val_loss: 0.3420 - val_accuracy: 0.8482\n",
      "400/400 [==============================] - 0s 790us/step - loss: 0.3308 - accuracy: 0.8537\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 746us/step - loss: 0.4753 - accuracy: 0.7810 - val_loss: 0.3772 - val_accuracy: 0.8128\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3682 - accuracy: 0.8242 - val_loss: 0.3667 - val_accuracy: 0.8202\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 688us/step - loss: 0.3658 - accuracy: 0.8275 - val_loss: 0.3630 - val_accuracy: 0.8250\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3508 - accuracy: 0.8378 - val_loss: 0.3619 - val_accuracy: 0.8266\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3578 - accuracy: 0.8298 - val_loss: 0.3567 - val_accuracy: 0.8310\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 790us/step - loss: 0.3487 - accuracy: 0.8382 - val_loss: 0.3552 - val_accuracy: 0.8310\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3520 - accuracy: 0.8399 - val_loss: 0.3569 - val_accuracy: 0.8320\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3448 - accuracy: 0.8419 - val_loss: 0.3547 - val_accuracy: 0.8344\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3449 - accuracy: 0.8401 - val_loss: 0.3503 - val_accuracy: 0.8366\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 983us/step - loss: 0.3445 - accuracy: 0.8425 - val_loss: 0.3479 - val_accuracy: 0.8426\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3400 - accuracy: 0.8446 - val_loss: 0.3476 - val_accuracy: 0.8386\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3383 - accuracy: 0.8437 - val_loss: 0.3475 - val_accuracy: 0.8420\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3383 - accuracy: 0.8502 - val_loss: 0.3464 - val_accuracy: 0.8412\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3368 - accuracy: 0.8496 - val_loss: 0.3474 - val_accuracy: 0.8398\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 819us/step - loss: 0.3377 - accuracy: 0.8450 - val_loss: 0.3436 - val_accuracy: 0.8452\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3344 - accuracy: 0.8496 - val_loss: 0.3462 - val_accuracy: 0.8392\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3440 - accuracy: 0.8441 - val_loss: 0.3442 - val_accuracy: 0.8414\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3350 - accuracy: 0.8506 - val_loss: 0.3439 - val_accuracy: 0.8416\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 664us/step - loss: 0.3383 - accuracy: 0.8482 - val_loss: 0.3413 - val_accuracy: 0.8476\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.3268 - accuracy: 0.8547 - val_loss: 0.3410 - val_accuracy: 0.8464\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3360 - accuracy: 0.8463 - val_loss: 0.3447 - val_accuracy: 0.8462\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 673us/step - loss: 0.3352 - accuracy: 0.8508 - val_loss: 0.3419 - val_accuracy: 0.8450\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3305 - accuracy: 0.8509 - val_loss: 0.3439 - val_accuracy: 0.8434\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3259 - accuracy: 0.8550 - val_loss: 0.3394 - val_accuracy: 0.8474\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 875us/step - loss: 0.3239 - accuracy: 0.8555 - val_loss: 0.3394 - val_accuracy: 0.8478\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3361 - accuracy: 0.8461 - val_loss: 0.3411 - val_accuracy: 0.8460\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 812us/step - loss: 0.3346 - accuracy: 0.8490 - val_loss: 0.3413 - val_accuracy: 0.8456\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3329 - accuracy: 0.8502 - val_loss: 0.3415 - val_accuracy: 0.8470\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3380 - accuracy: 0.8504 - val_loss: 0.3421 - val_accuracy: 0.8464\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3327 - accuracy: 0.8517 - val_loss: 0.3390 - val_accuracy: 0.8480\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3250 - accuracy: 0.8532 - val_loss: 0.3392 - val_accuracy: 0.8470\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3287 - accuracy: 0.8508 - val_loss: 0.3417 - val_accuracy: 0.8484\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 683us/step - loss: 0.3342 - accuracy: 0.8461 - val_loss: 0.3403 - val_accuracy: 0.8460\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 859us/step - loss: 0.3306 - accuracy: 0.8531 - val_loss: 0.3418 - val_accuracy: 0.8480\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3361 - accuracy: 0.8499 - val_loss: 0.3514 - val_accuracy: 0.8472\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 887us/step - loss: 0.3361 - accuracy: 0.8463 - val_loss: 0.3411 - val_accuracy: 0.8448\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3251 - accuracy: 0.8548 - val_loss: 0.3419 - val_accuracy: 0.8438\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 683us/step - loss: 0.3310 - accuracy: 0.8498 - val_loss: 0.3399 - val_accuracy: 0.8462\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3323 - accuracy: 0.8528 - val_loss: 0.3439 - val_accuracy: 0.8460\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 688us/step - loss: 0.3245 - accuracy: 0.8526 - val_loss: 0.3393 - val_accuracy: 0.8482\n",
      "400/400 [==============================] - 0s 730us/step - loss: 0.3393 - accuracy: 0.8495\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 758us/step - loss: 0.4765 - accuracy: 0.7820 - val_loss: 0.3753 - val_accuracy: 0.8176\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3673 - accuracy: 0.8227 - val_loss: 0.3707 - val_accuracy: 0.8168\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 810us/step - loss: 0.3660 - accuracy: 0.8289 - val_loss: 0.3652 - val_accuracy: 0.8242\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3643 - accuracy: 0.8288 - val_loss: 0.3646 - val_accuracy: 0.8310\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3613 - accuracy: 0.8307 - val_loss: 0.3610 - val_accuracy: 0.8262\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3643 - accuracy: 0.8290 - val_loss: 0.3617 - val_accuracy: 0.8340\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3560 - accuracy: 0.8350 - val_loss: 0.3589 - val_accuracy: 0.8320\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3527 - accuracy: 0.8385 - val_loss: 0.3565 - val_accuracy: 0.8276\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3562 - accuracy: 0.8352 - val_loss: 0.3552 - val_accuracy: 0.8322\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3540 - accuracy: 0.8412 - val_loss: 0.3569 - val_accuracy: 0.8278\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3449 - accuracy: 0.8422 - val_loss: 0.3565 - val_accuracy: 0.8306\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 763us/step - loss: 0.3455 - accuracy: 0.8416 - val_loss: 0.3535 - val_accuracy: 0.8342\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3463 - accuracy: 0.8451 - val_loss: 0.3560 - val_accuracy: 0.8322\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3552 - accuracy: 0.8377 - val_loss: 0.3556 - val_accuracy: 0.8398\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 888us/step - loss: 0.3422 - accuracy: 0.8448 - val_loss: 0.3529 - val_accuracy: 0.8374\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3472 - accuracy: 0.8425 - val_loss: 0.3483 - val_accuracy: 0.8372\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3416 - accuracy: 0.8455 - val_loss: 0.3506 - val_accuracy: 0.8354\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3351 - accuracy: 0.8521 - val_loss: 0.3468 - val_accuracy: 0.8404\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 670us/step - loss: 0.3392 - accuracy: 0.8478 - val_loss: 0.3456 - val_accuracy: 0.8420\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3375 - accuracy: 0.8473 - val_loss: 0.3460 - val_accuracy: 0.8410\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 819us/step - loss: 0.3415 - accuracy: 0.8448 - val_loss: 0.3443 - val_accuracy: 0.8440\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3384 - accuracy: 0.8476 - val_loss: 0.3483 - val_accuracy: 0.8440\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3375 - accuracy: 0.8481 - val_loss: 0.3424 - val_accuracy: 0.8438\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3381 - accuracy: 0.8477 - val_loss: 0.3415 - val_accuracy: 0.8458\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3371 - accuracy: 0.8467 - val_loss: 0.3420 - val_accuracy: 0.8456\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3330 - accuracy: 0.8491 - val_loss: 0.3407 - val_accuracy: 0.8452\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3409 - accuracy: 0.8470 - val_loss: 0.3411 - val_accuracy: 0.8470\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3385 - accuracy: 0.8445 - val_loss: 0.3404 - val_accuracy: 0.8436\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 808us/step - loss: 0.4736 - accuracy: 0.7849 - val_loss: 0.3722 - val_accuracy: 0.8208\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3724 - accuracy: 0.8231 - val_loss: 0.3674 - val_accuracy: 0.8290\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 761us/step - loss: 0.3624 - accuracy: 0.8312 - val_loss: 0.3615 - val_accuracy: 0.8250\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 683us/step - loss: 0.3553 - accuracy: 0.8372 - val_loss: 0.3636 - val_accuracy: 0.8370\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 797us/step - loss: 0.3602 - accuracy: 0.8355 - val_loss: 0.3530 - val_accuracy: 0.8352\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3368 - accuracy: 0.8522 - val_loss: 0.3502 - val_accuracy: 0.8396\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3386 - accuracy: 0.8489 - val_loss: 0.3558 - val_accuracy: 0.8438\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3405 - accuracy: 0.8477 - val_loss: 0.3468 - val_accuracy: 0.8446\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 809us/step - loss: 0.3390 - accuracy: 0.8493 - val_loss: 0.3512 - val_accuracy: 0.8366\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 671us/step - loss: 0.3348 - accuracy: 0.8520 - val_loss: 0.3455 - val_accuracy: 0.8406\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 665us/step - loss: 0.3392 - accuracy: 0.8473 - val_loss: 0.3458 - val_accuracy: 0.8398\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 789us/step - loss: 0.3352 - accuracy: 0.8509 - val_loss: 0.3431 - val_accuracy: 0.8434\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 937us/step - loss: 0.3294 - accuracy: 0.8552 - val_loss: 0.3424 - val_accuracy: 0.8470\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3403 - accuracy: 0.8486 - val_loss: 0.3427 - val_accuracy: 0.8474\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3264 - accuracy: 0.8576 - val_loss: 0.3414 - val_accuracy: 0.8492\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3297 - accuracy: 0.8549 - val_loss: 0.3431 - val_accuracy: 0.8468\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3402 - accuracy: 0.8482 - val_loss: 0.3432 - val_accuracy: 0.8468\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 824us/step - loss: 0.3372 - accuracy: 0.8513 - val_loss: 0.3431 - val_accuracy: 0.8454\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 858us/step - loss: 0.3254 - accuracy: 0.8538 - val_loss: 0.3450 - val_accuracy: 0.8448\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3359 - accuracy: 0.8492 - val_loss: 0.3431 - val_accuracy: 0.8444\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3326 - accuracy: 0.8543 - val_loss: 0.3419 - val_accuracy: 0.8474\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 668us/step - loss: 0.3299 - accuracy: 0.8520 - val_loss: 0.3429 - val_accuracy: 0.8462\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3316 - accuracy: 0.8543 - val_loss: 0.3434 - val_accuracy: 0.8484\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 770us/step - loss: 0.3300 - accuracy: 0.8518 - val_loss: 0.3445 - val_accuracy: 0.8474\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3282 - accuracy: 0.8544 - val_loss: 0.3452 - val_accuracy: 0.8456\n",
      "400/400 [==============================] - 0s 862us/step - loss: 0.3433 - accuracy: 0.8413\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4636 - accuracy: 0.7840 - val_loss: 0.3733 - val_accuracy: 0.8174\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3686 - accuracy: 0.8259 - val_loss: 0.3659 - val_accuracy: 0.8222\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 769us/step - loss: 0.3545 - accuracy: 0.8348 - val_loss: 0.3635 - val_accuracy: 0.8258\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3595 - accuracy: 0.8325 - val_loss: 0.3599 - val_accuracy: 0.8276\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 773us/step - loss: 0.3509 - accuracy: 0.8377 - val_loss: 0.3569 - val_accuracy: 0.8300\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3546 - accuracy: 0.8356 - val_loss: 0.3581 - val_accuracy: 0.8326\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3459 - accuracy: 0.8411 - val_loss: 0.3558 - val_accuracy: 0.8342\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3471 - accuracy: 0.8352 - val_loss: 0.3543 - val_accuracy: 0.8338\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3435 - accuracy: 0.8411 - val_loss: 0.3520 - val_accuracy: 0.8418\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3513 - accuracy: 0.8403 - val_loss: 0.3539 - val_accuracy: 0.8334\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3444 - accuracy: 0.8389 - val_loss: 0.3487 - val_accuracy: 0.8422\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3449 - accuracy: 0.8449 - val_loss: 0.3534 - val_accuracy: 0.8362\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3371 - accuracy: 0.8493 - val_loss: 0.3477 - val_accuracy: 0.8428\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3393 - accuracy: 0.8475 - val_loss: 0.3465 - val_accuracy: 0.8434\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3377 - accuracy: 0.8475 - val_loss: 0.3423 - val_accuracy: 0.8452\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3395 - accuracy: 0.8441 - val_loss: 0.3438 - val_accuracy: 0.8460\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3361 - accuracy: 0.8509 - val_loss: 0.3462 - val_accuracy: 0.8430\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 907us/step - loss: 0.3392 - accuracy: 0.8457 - val_loss: 0.3415 - val_accuracy: 0.8460\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 770us/step - loss: 0.3338 - accuracy: 0.8493 - val_loss: 0.3429 - val_accuracy: 0.8454\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 840us/step - loss: 0.3317 - accuracy: 0.8481 - val_loss: 0.3428 - val_accuracy: 0.8486\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3234 - accuracy: 0.8570 - val_loss: 0.3405 - val_accuracy: 0.8478\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 723us/step - loss: 0.3286 - accuracy: 0.8546 - val_loss: 0.3407 - val_accuracy: 0.8476\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 713us/step - loss: 0.3394 - accuracy: 0.8480 - val_loss: 0.3390 - val_accuracy: 0.8468\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3373 - accuracy: 0.8458 - val_loss: 0.3431 - val_accuracy: 0.8476\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 790us/step - loss: 0.3262 - accuracy: 0.8548 - val_loss: 0.3424 - val_accuracy: 0.8476\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.3363 - accuracy: 0.8487 - val_loss: 0.3403 - val_accuracy: 0.8460\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3336 - accuracy: 0.8550 - val_loss: 0.3423 - val_accuracy: 0.8464\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3278 - accuracy: 0.8572 - val_loss: 0.3395 - val_accuracy: 0.8480\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3312 - accuracy: 0.8501 - val_loss: 0.3440 - val_accuracy: 0.8476\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 796us/step - loss: 0.3297 - accuracy: 0.8550 - val_loss: 0.3406 - val_accuracy: 0.8466\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3357 - accuracy: 0.8528 - val_loss: 0.3422 - val_accuracy: 0.8466\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3305 - accuracy: 0.8539 - val_loss: 0.3444 - val_accuracy: 0.8458\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 2s 946us/step - loss: 0.3361 - accuracy: 0.8515 - val_loss: 0.3421 - val_accuracy: 0.8470\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3286 - accuracy: 0.8535\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 902us/step - loss: 0.4640 - accuracy: 0.7839 - val_loss: 0.3722 - val_accuracy: 0.8222\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3723 - accuracy: 0.8229 - val_loss: 0.3670 - val_accuracy: 0.8234\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 861us/step - loss: 0.3606 - accuracy: 0.8341 - val_loss: 0.3615 - val_accuracy: 0.8258\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3626 - accuracy: 0.8320 - val_loss: 0.3600 - val_accuracy: 0.8346\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 796us/step - loss: 0.3588 - accuracy: 0.8333 - val_loss: 0.3574 - val_accuracy: 0.8340\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3466 - accuracy: 0.8428 - val_loss: 0.3538 - val_accuracy: 0.8334\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 853us/step - loss: 0.3500 - accuracy: 0.8415 - val_loss: 0.3520 - val_accuracy: 0.8342\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 673us/step - loss: 0.3461 - accuracy: 0.8440 - val_loss: 0.3489 - val_accuracy: 0.8406\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3446 - accuracy: 0.8462 - val_loss: 0.3528 - val_accuracy: 0.8338\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3434 - accuracy: 0.8459 - val_loss: 0.3456 - val_accuracy: 0.8460\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 658us/step - loss: 0.3414 - accuracy: 0.8492 - val_loss: 0.3486 - val_accuracy: 0.8464\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 926us/step - loss: 0.3383 - accuracy: 0.8486 - val_loss: 0.3447 - val_accuracy: 0.8436\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 786us/step - loss: 0.3408 - accuracy: 0.8488 - val_loss: 0.3443 - val_accuracy: 0.8466\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3326 - accuracy: 0.8494 - val_loss: 0.3470 - val_accuracy: 0.8412\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3386 - accuracy: 0.8463 - val_loss: 0.3436 - val_accuracy: 0.8444\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3282 - accuracy: 0.8560 - val_loss: 0.3428 - val_accuracy: 0.8446\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3386 - accuracy: 0.8486 - val_loss: 0.3409 - val_accuracy: 0.8460\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 827us/step - loss: 0.3370 - accuracy: 0.8510 - val_loss: 0.3424 - val_accuracy: 0.8450\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3321 - accuracy: 0.8523 - val_loss: 0.3413 - val_accuracy: 0.8486\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 668us/step - loss: 0.3318 - accuracy: 0.8524 - val_loss: 0.3430 - val_accuracy: 0.8456\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 822us/step - loss: 0.3300 - accuracy: 0.8527 - val_loss: 0.3439 - val_accuracy: 0.8450\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3444 - accuracy: 0.8462 - val_loss: 0.3425 - val_accuracy: 0.8470\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 792us/step - loss: 0.3327 - accuracy: 0.8503 - val_loss: 0.3415 - val_accuracy: 0.8480\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3287 - accuracy: 0.8514 - val_loss: 0.3442 - val_accuracy: 0.8472\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3325 - accuracy: 0.8535 - val_loss: 0.3427 - val_accuracy: 0.8488\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 785us/step - loss: 0.3276 - accuracy: 0.8549 - val_loss: 0.3441 - val_accuracy: 0.8490\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3338 - accuracy: 0.8530 - val_loss: 0.3444 - val_accuracy: 0.8462\n",
      "400/400 [==============================] - 0s 695us/step - loss: 0.3303 - accuracy: 0.8545\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 778us/step - loss: 0.4722 - accuracy: 0.7761 - val_loss: 0.3732 - val_accuracy: 0.8130\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3734 - accuracy: 0.8226 - val_loss: 0.3669 - val_accuracy: 0.8266\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3631 - accuracy: 0.8291 - val_loss: 0.3624 - val_accuracy: 0.8274\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3626 - accuracy: 0.8299 - val_loss: 0.3610 - val_accuracy: 0.8314\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3536 - accuracy: 0.8336 - val_loss: 0.3573 - val_accuracy: 0.8294\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3502 - accuracy: 0.8359 - val_loss: 0.3535 - val_accuracy: 0.8370\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3516 - accuracy: 0.8410 - val_loss: 0.3523 - val_accuracy: 0.8356\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3497 - accuracy: 0.8418 - val_loss: 0.3516 - val_accuracy: 0.8358\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3453 - accuracy: 0.8437 - val_loss: 0.3512 - val_accuracy: 0.8356\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3461 - accuracy: 0.8434 - val_loss: 0.3481 - val_accuracy: 0.8388\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3365 - accuracy: 0.8496 - val_loss: 0.3469 - val_accuracy: 0.8402\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3350 - accuracy: 0.8474 - val_loss: 0.3434 - val_accuracy: 0.8462\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3358 - accuracy: 0.8483 - val_loss: 0.3459 - val_accuracy: 0.8432\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3382 - accuracy: 0.8479 - val_loss: 0.3469 - val_accuracy: 0.8460\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 985us/step - loss: 0.3312 - accuracy: 0.8542 - val_loss: 0.3434 - val_accuracy: 0.8464\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3352 - accuracy: 0.8492 - val_loss: 0.3422 - val_accuracy: 0.8460\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3365 - accuracy: 0.8485 - val_loss: 0.3427 - val_accuracy: 0.8454\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3283 - accuracy: 0.8529 - val_loss: 0.3424 - val_accuracy: 0.8456\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3307 - accuracy: 0.8530 - val_loss: 0.3416 - val_accuracy: 0.8468\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 651us/step - loss: 0.3296 - accuracy: 0.8535 - val_loss: 0.3433 - val_accuracy: 0.8470\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3327 - accuracy: 0.8486 - val_loss: 0.3428 - val_accuracy: 0.8434\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3447 - accuracy: 0.8438 - val_loss: 0.3431 - val_accuracy: 0.8460\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3286 - accuracy: 0.8527 - val_loss: 0.3473 - val_accuracy: 0.8404\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.3273 - accuracy: 0.8551 - val_loss: 0.3401 - val_accuracy: 0.8466\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 793us/step - loss: 0.3310 - accuracy: 0.8531 - val_loss: 0.3416 - val_accuracy: 0.8466\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3255 - accuracy: 0.8530 - val_loss: 0.3448 - val_accuracy: 0.8440\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 955us/step - loss: 0.3329 - accuracy: 0.8510 - val_loss: 0.3423 - val_accuracy: 0.8452\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3324 - accuracy: 0.8507 - val_loss: 0.3431 - val_accuracy: 0.8468\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3401 - accuracy: 0.8464 - val_loss: 0.3407 - val_accuracy: 0.8478\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 723us/step - loss: 0.3286 - accuracy: 0.8553 - val_loss: 0.3405 - val_accuracy: 0.8470\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3258 - accuracy: 0.8568 - val_loss: 0.3424 - val_accuracy: 0.8448\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3271 - accuracy: 0.8511 - val_loss: 0.3420 - val_accuracy: 0.8448\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 2s 964us/step - loss: 0.3272 - accuracy: 0.8550 - val_loss: 0.3398 - val_accuracy: 0.8470\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3242 - accuracy: 0.8550 - val_loss: 0.3416 - val_accuracy: 0.8474\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3340 - accuracy: 0.8512 - val_loss: 0.3421 - val_accuracy: 0.8456\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3322 - accuracy: 0.8540 - val_loss: 0.3435 - val_accuracy: 0.8484\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3206 - accuracy: 0.8553 - val_loss: 0.3436 - val_accuracy: 0.8474\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3255 - accuracy: 0.8571 - val_loss: 0.3414 - val_accuracy: 0.8462\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3223 - accuracy: 0.8578 - val_loss: 0.3418 - val_accuracy: 0.8486\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 2s 952us/step - loss: 0.3299 - accuracy: 0.8528 - val_loss: 0.3466 - val_accuracy: 0.8482\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 716us/step - loss: 0.3288 - accuracy: 0.8504 - val_loss: 0.3466 - val_accuracy: 0.8472\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3337 - accuracy: 0.8487 - val_loss: 0.3425 - val_accuracy: 0.8474\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3252 - accuracy: 0.8573 - val_loss: 0.3413 - val_accuracy: 0.8478\n",
      "400/400 [==============================] - 0s 710us/step - loss: 0.3394 - accuracy: 0.8520\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 854us/step - loss: 0.4621 - accuracy: 0.7853 - val_loss: 0.3734 - val_accuracy: 0.8154\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3652 - accuracy: 0.8276 - val_loss: 0.3644 - val_accuracy: 0.8214\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3597 - accuracy: 0.8354 - val_loss: 0.3608 - val_accuracy: 0.8310\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3538 - accuracy: 0.8338 - val_loss: 0.3579 - val_accuracy: 0.8294\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3577 - accuracy: 0.8336 - val_loss: 0.3569 - val_accuracy: 0.8316\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 964us/step - loss: 0.3523 - accuracy: 0.8370 - val_loss: 0.3567 - val_accuracy: 0.8332\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3517 - accuracy: 0.8374 - val_loss: 0.3528 - val_accuracy: 0.8320\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3497 - accuracy: 0.8395 - val_loss: 0.3543 - val_accuracy: 0.8326\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3545 - accuracy: 0.8370 - val_loss: 0.3527 - val_accuracy: 0.8358\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3476 - accuracy: 0.8416 - val_loss: 0.3481 - val_accuracy: 0.8402\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3378 - accuracy: 0.8493 - val_loss: 0.3566 - val_accuracy: 0.8312\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3408 - accuracy: 0.8461 - val_loss: 0.3465 - val_accuracy: 0.8422\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 761us/step - loss: 0.3380 - accuracy: 0.8456 - val_loss: 0.3431 - val_accuracy: 0.8450\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3395 - accuracy: 0.8465 - val_loss: 0.3486 - val_accuracy: 0.8470\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3373 - accuracy: 0.8462 - val_loss: 0.3430 - val_accuracy: 0.8438\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3350 - accuracy: 0.8502 - val_loss: 0.3420 - val_accuracy: 0.8472\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 831us/step - loss: 0.3413 - accuracy: 0.8460 - val_loss: 0.3411 - val_accuracy: 0.8434\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 831us/step - loss: 0.3398 - accuracy: 0.8472 - val_loss: 0.3419 - val_accuracy: 0.8428\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 656us/step - loss: 0.3335 - accuracy: 0.8523 - val_loss: 0.3399 - val_accuracy: 0.8474\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3294 - accuracy: 0.8522 - val_loss: 0.3440 - val_accuracy: 0.8454\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3382 - accuracy: 0.8469 - val_loss: 0.3399 - val_accuracy: 0.8476\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3345 - accuracy: 0.8500 - val_loss: 0.3397 - val_accuracy: 0.8470\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3372 - accuracy: 0.8478 - val_loss: 0.3458 - val_accuracy: 0.8456\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3314 - accuracy: 0.8522 - val_loss: 0.3395 - val_accuracy: 0.8476\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 893us/step - loss: 0.3309 - accuracy: 0.8547 - val_loss: 0.3393 - val_accuracy: 0.8480\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.3346 - accuracy: 0.8528 - val_loss: 0.3436 - val_accuracy: 0.8470\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 961us/step - loss: 0.3334 - accuracy: 0.8463 - val_loss: 0.3401 - val_accuracy: 0.8472\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3237 - accuracy: 0.8569 - val_loss: 0.3397 - val_accuracy: 0.8478\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3321 - accuracy: 0.8537 - val_loss: 0.3460 - val_accuracy: 0.8478\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3327 - accuracy: 0.8511 - val_loss: 0.3428 - val_accuracy: 0.8450\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 670us/step - loss: 0.3284 - accuracy: 0.8514 - val_loss: 0.3396 - val_accuracy: 0.8476\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3404 - accuracy: 0.8504 - val_loss: 0.3470 - val_accuracy: 0.8472\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3332 - accuracy: 0.8543 - val_loss: 0.3427 - val_accuracy: 0.8488\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3328 - accuracy: 0.8534 - val_loss: 0.3411 - val_accuracy: 0.8462\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.3306 - accuracy: 0.8514 - val_loss: 0.3394 - val_accuracy: 0.8482\n",
      "400/400 [==============================] - 0s 752us/step - loss: 0.3330 - accuracy: 0.8485\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 753us/step - loss: 0.4602 - accuracy: 0.7896 - val_loss: 0.3746 - val_accuracy: 0.8172\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3709 - accuracy: 0.8247 - val_loss: 0.3692 - val_accuracy: 0.8208\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 769us/step - loss: 0.3676 - accuracy: 0.8264 - val_loss: 0.3654 - val_accuracy: 0.8288\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3524 - accuracy: 0.8360 - val_loss: 0.3615 - val_accuracy: 0.8308\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 723us/step - loss: 0.3490 - accuracy: 0.8411 - val_loss: 0.3571 - val_accuracy: 0.8292\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3517 - accuracy: 0.8381 - val_loss: 0.3580 - val_accuracy: 0.8336\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 680us/step - loss: 0.3492 - accuracy: 0.8424 - val_loss: 0.3564 - val_accuracy: 0.8320\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3461 - accuracy: 0.8417 - val_loss: 0.3521 - val_accuracy: 0.8342\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.3409 - accuracy: 0.8471 - val_loss: 0.3494 - val_accuracy: 0.8376\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3377 - accuracy: 0.8508 - val_loss: 0.3504 - val_accuracy: 0.8386\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.3417 - accuracy: 0.8476 - val_loss: 0.3473 - val_accuracy: 0.8426\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3388 - accuracy: 0.8478 - val_loss: 0.3466 - val_accuracy: 0.8424\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 893us/step - loss: 0.3344 - accuracy: 0.8501 - val_loss: 0.3477 - val_accuracy: 0.8432\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3395 - accuracy: 0.8458 - val_loss: 0.3450 - val_accuracy: 0.8458\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 768us/step - loss: 0.3335 - accuracy: 0.8512 - val_loss: 0.3448 - val_accuracy: 0.8460\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3330 - accuracy: 0.8507 - val_loss: 0.3435 - val_accuracy: 0.8430\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3326 - accuracy: 0.8537 - val_loss: 0.3422 - val_accuracy: 0.8460\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3306 - accuracy: 0.8516 - val_loss: 0.3412 - val_accuracy: 0.8464\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3318 - accuracy: 0.8526 - val_loss: 0.3427 - val_accuracy: 0.8440\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.3385 - accuracy: 0.8538 - val_loss: 0.3443 - val_accuracy: 0.8462\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.3344 - accuracy: 0.8518 - val_loss: 0.3418 - val_accuracy: 0.8480\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 901us/step - loss: 0.3244 - accuracy: 0.8544 - val_loss: 0.3476 - val_accuracy: 0.8426\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3287 - accuracy: 0.8535 - val_loss: 0.3424 - val_accuracy: 0.8480\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 792us/step - loss: 0.3337 - accuracy: 0.8533 - val_loss: 0.3447 - val_accuracy: 0.8470\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 658us/step - loss: 0.3288 - accuracy: 0.8547 - val_loss: 0.3437 - val_accuracy: 0.8460\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3322 - accuracy: 0.8534 - val_loss: 0.3430 - val_accuracy: 0.8466\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3296 - accuracy: 0.8513 - val_loss: 0.3430 - val_accuracy: 0.8458\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 662us/step - loss: 0.3276 - accuracy: 0.8582 - val_loss: 0.3402 - val_accuracy: 0.8488\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 649us/step - loss: 0.3227 - accuracy: 0.8589 - val_loss: 0.3405 - val_accuracy: 0.8482\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3353 - accuracy: 0.8510 - val_loss: 0.3405 - val_accuracy: 0.8480\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3299 - accuracy: 0.8529 - val_loss: 0.3403 - val_accuracy: 0.8492\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 674us/step - loss: 0.3322 - accuracy: 0.8544 - val_loss: 0.3434 - val_accuracy: 0.8482\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 662us/step - loss: 0.3284 - accuracy: 0.8562 - val_loss: 0.3448 - val_accuracy: 0.8482\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.3324 - accuracy: 0.8531 - val_loss: 0.3461 - val_accuracy: 0.8478\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3283 - accuracy: 0.8513 - val_loss: 0.3408 - val_accuracy: 0.8482\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.3300 - accuracy: 0.8552 - val_loss: 0.3401 - val_accuracy: 0.8464\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 643us/step - loss: 0.3312 - accuracy: 0.8545 - val_loss: 0.3430 - val_accuracy: 0.8472\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3369 - accuracy: 0.8536 - val_loss: 0.3504 - val_accuracy: 0.8472\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3273 - accuracy: 0.8534 - val_loss: 0.3442 - val_accuracy: 0.8452\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3251 - accuracy: 0.8572 - val_loss: 0.3411 - val_accuracy: 0.8468\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3290 - accuracy: 0.8555 - val_loss: 0.3431 - val_accuracy: 0.8482\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3294 - accuracy: 0.8553 - val_loss: 0.3452 - val_accuracy: 0.8468\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 682us/step - loss: 0.3323 - accuracy: 0.8527 - val_loss: 0.3459 - val_accuracy: 0.8426\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3318 - accuracy: 0.8517 - val_loss: 0.3419 - val_accuracy: 0.8474\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3242 - accuracy: 0.8570 - val_loss: 0.3444 - val_accuracy: 0.8470\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3224 - accuracy: 0.8568 - val_loss: 0.3425 - val_accuracy: 0.8470\n",
      "400/400 [==============================] - 0s 702us/step - loss: 0.3398 - accuracy: 0.8425\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 798us/step - loss: 0.5083 - accuracy: 0.7628 - val_loss: 0.3888 - val_accuracy: 0.8162\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3833 - accuracy: 0.8228 - val_loss: 0.3803 - val_accuracy: 0.8220\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 914us/step - loss: 0.3812 - accuracy: 0.8189 - val_loss: 0.3749 - val_accuracy: 0.8226\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3691 - accuracy: 0.8267 - val_loss: 0.3708 - val_accuracy: 0.8230\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 822us/step - loss: 0.3679 - accuracy: 0.8287 - val_loss: 0.3643 - val_accuracy: 0.8332\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3590 - accuracy: 0.8381 - val_loss: 0.3627 - val_accuracy: 0.8342\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3577 - accuracy: 0.8357 - val_loss: 0.3642 - val_accuracy: 0.8352\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3635 - accuracy: 0.8355 - val_loss: 0.3601 - val_accuracy: 0.8384\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3536 - accuracy: 0.8418 - val_loss: 0.3604 - val_accuracy: 0.8398\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3557 - accuracy: 0.8405 - val_loss: 0.3610 - val_accuracy: 0.8402\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3563 - accuracy: 0.8454 - val_loss: 0.3625 - val_accuracy: 0.8382\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3553 - accuracy: 0.8427 - val_loss: 0.3580 - val_accuracy: 0.8428\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3552 - accuracy: 0.8409 - val_loss: 0.3594 - val_accuracy: 0.8420\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 763us/step - loss: 0.3586 - accuracy: 0.8401 - val_loss: 0.3572 - val_accuracy: 0.8412\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3564 - accuracy: 0.8398 - val_loss: 0.3574 - val_accuracy: 0.8426\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 996us/step - loss: 0.3490 - accuracy: 0.8442 - val_loss: 0.3596 - val_accuracy: 0.8426\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3550 - accuracy: 0.8420 - val_loss: 0.3559 - val_accuracy: 0.8440\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3560 - accuracy: 0.8458 - val_loss: 0.3591 - val_accuracy: 0.8436\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3555 - accuracy: 0.8411 - val_loss: 0.3607 - val_accuracy: 0.8462\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3526 - accuracy: 0.8446 - val_loss: 0.3553 - val_accuracy: 0.8442\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3545 - accuracy: 0.8424 - val_loss: 0.3547 - val_accuracy: 0.8424\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 772us/step - loss: 0.3471 - accuracy: 0.8509 - val_loss: 0.3561 - val_accuracy: 0.8440\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3539 - accuracy: 0.8489 - val_loss: 0.3556 - val_accuracy: 0.8452\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 723us/step - loss: 0.3475 - accuracy: 0.8458 - val_loss: 0.3573 - val_accuracy: 0.8444\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3458 - accuracy: 0.8473 - val_loss: 0.3532 - val_accuracy: 0.8454\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3497 - accuracy: 0.8492 - val_loss: 0.3521 - val_accuracy: 0.8458\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 840us/step - loss: 0.3504 - accuracy: 0.8482 - val_loss: 0.3510 - val_accuracy: 0.8438\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 765us/step - loss: 0.3503 - accuracy: 0.8465 - val_loss: 0.3523 - val_accuracy: 0.8460\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 854us/step - loss: 0.3559 - accuracy: 0.8429 - val_loss: 0.3496 - val_accuracy: 0.8438\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 756us/step - loss: 0.3390 - accuracy: 0.8524 - val_loss: 0.3513 - val_accuracy: 0.8444\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3391 - accuracy: 0.8512 - val_loss: 0.3586 - val_accuracy: 0.8458\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3412 - accuracy: 0.8544 - val_loss: 0.3509 - val_accuracy: 0.8492\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3439 - accuracy: 0.8470 - val_loss: 0.3520 - val_accuracy: 0.8416\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3471 - accuracy: 0.8477 - val_loss: 0.3488 - val_accuracy: 0.8450\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3429 - accuracy: 0.8511 - val_loss: 0.3500 - val_accuracy: 0.8478\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 716us/step - loss: 0.3468 - accuracy: 0.8501 - val_loss: 0.3495 - val_accuracy: 0.8468\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 876us/step - loss: 0.3389 - accuracy: 0.8516 - val_loss: 0.3531 - val_accuracy: 0.8482\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 866us/step - loss: 0.3439 - accuracy: 0.8498 - val_loss: 0.3531 - val_accuracy: 0.8446\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3361 - accuracy: 0.8512 - val_loss: 0.3491 - val_accuracy: 0.8482\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3467 - accuracy: 0.8475 - val_loss: 0.3482 - val_accuracy: 0.8474\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3401 - accuracy: 0.8529 - val_loss: 0.3480 - val_accuracy: 0.8494\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3343 - accuracy: 0.8587 - val_loss: 0.3567 - val_accuracy: 0.8478\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3452 - accuracy: 0.8476 - val_loss: 0.3476 - val_accuracy: 0.8468\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3366 - accuracy: 0.8508 - val_loss: 0.3518 - val_accuracy: 0.8436\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 2s 999us/step - loss: 0.3430 - accuracy: 0.8546 - val_loss: 0.3515 - val_accuracy: 0.8432\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3434 - accuracy: 0.8483 - val_loss: 0.3514 - val_accuracy: 0.8470\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3376 - accuracy: 0.8549 - val_loss: 0.3517 - val_accuracy: 0.8478\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3434 - accuracy: 0.8485 - val_loss: 0.3504 - val_accuracy: 0.8480\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 759us/step - loss: 0.3463 - accuracy: 0.8472 - val_loss: 0.3522 - val_accuracy: 0.8474\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3494 - accuracy: 0.8464 - val_loss: 0.3541 - val_accuracy: 0.8458\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3466 - accuracy: 0.8534 - val_loss: 0.3543 - val_accuracy: 0.8466\n",
      "Epoch 52/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3414 - accuracy: 0.8522 - val_loss: 0.3480 - val_accuracy: 0.8492\n",
      "Epoch 53/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3371 - accuracy: 0.8564 - val_loss: 0.3492 - val_accuracy: 0.8470\n",
      "400/400 [==============================] - 0s 705us/step - loss: 0.3375 - accuracy: 0.8515\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 791us/step - loss: 0.4960 - accuracy: 0.7726 - val_loss: 0.3800 - val_accuracy: 0.8142\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 731us/step - loss: 0.3794 - accuracy: 0.8205 - val_loss: 0.3697 - val_accuracy: 0.8188\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 846us/step - loss: 0.3755 - accuracy: 0.8218 - val_loss: 0.3653 - val_accuracy: 0.8240\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3652 - accuracy: 0.8294 - val_loss: 0.3635 - val_accuracy: 0.8242\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 993us/step - loss: 0.3660 - accuracy: 0.8308 - val_loss: 0.3628 - val_accuracy: 0.8254\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3588 - accuracy: 0.8333 - val_loss: 0.3610 - val_accuracy: 0.8246\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3616 - accuracy: 0.8377 - val_loss: 0.3576 - val_accuracy: 0.8290\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 842us/step - loss: 0.3559 - accuracy: 0.8369 - val_loss: 0.3547 - val_accuracy: 0.8304\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 859us/step - loss: 0.3435 - accuracy: 0.8449 - val_loss: 0.3543 - val_accuracy: 0.8304\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 767us/step - loss: 0.3478 - accuracy: 0.8418 - val_loss: 0.3510 - val_accuracy: 0.8384\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3437 - accuracy: 0.8445 - val_loss: 0.3578 - val_accuracy: 0.8444\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3415 - accuracy: 0.8456 - val_loss: 0.3466 - val_accuracy: 0.8398\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 723us/step - loss: 0.3482 - accuracy: 0.8405 - val_loss: 0.3467 - val_accuracy: 0.8390\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3375 - accuracy: 0.8465 - val_loss: 0.3453 - val_accuracy: 0.8400\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3410 - accuracy: 0.8488 - val_loss: 0.3445 - val_accuracy: 0.8436\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3425 - accuracy: 0.8459 - val_loss: 0.3485 - val_accuracy: 0.8466\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.3342 - accuracy: 0.8458 - val_loss: 0.3462 - val_accuracy: 0.8432\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 793us/step - loss: 0.3328 - accuracy: 0.8533 - val_loss: 0.3455 - val_accuracy: 0.8444\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 960us/step - loss: 0.3380 - accuracy: 0.8461 - val_loss: 0.3481 - val_accuracy: 0.8434\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3315 - accuracy: 0.8538 - val_loss: 0.3426 - val_accuracy: 0.8420\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 893us/step - loss: 0.3397 - accuracy: 0.8501 - val_loss: 0.3465 - val_accuracy: 0.8426\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 736us/step - loss: 0.3313 - accuracy: 0.8532 - val_loss: 0.3413 - val_accuracy: 0.8452\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3410 - accuracy: 0.8487 - val_loss: 0.3404 - val_accuracy: 0.8456\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3353 - accuracy: 0.8520 - val_loss: 0.3421 - val_accuracy: 0.8480\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3364 - accuracy: 0.8486 - val_loss: 0.3398 - val_accuracy: 0.8444\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 836us/step - loss: 0.3381 - accuracy: 0.8477 - val_loss: 0.3393 - val_accuracy: 0.8450\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3388 - accuracy: 0.8473 - val_loss: 0.3412 - val_accuracy: 0.8438\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 767us/step - loss: 0.3335 - accuracy: 0.8500 - val_loss: 0.3380 - val_accuracy: 0.8460\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 735us/step - loss: 0.3334 - accuracy: 0.8530 - val_loss: 0.3430 - val_accuracy: 0.8484\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 868us/step - loss: 0.3270 - accuracy: 0.8521 - val_loss: 0.3382 - val_accuracy: 0.8488\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3286 - accuracy: 0.8525 - val_loss: 0.3419 - val_accuracy: 0.8430\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 924us/step - loss: 0.3373 - accuracy: 0.8487 - val_loss: 0.3455 - val_accuracy: 0.8446\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3380 - accuracy: 0.8486 - val_loss: 0.3417 - val_accuracy: 0.8420\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 823us/step - loss: 0.3342 - accuracy: 0.8448 - val_loss: 0.3415 - val_accuracy: 0.8492\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3315 - accuracy: 0.8536 - val_loss: 0.3385 - val_accuracy: 0.8468\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 785us/step - loss: 0.3345 - accuracy: 0.8504 - val_loss: 0.3379 - val_accuracy: 0.8464\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3349 - accuracy: 0.8508 - val_loss: 0.3456 - val_accuracy: 0.8402\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3339 - accuracy: 0.8484 - val_loss: 0.3444 - val_accuracy: 0.8466\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 728us/step - loss: 0.3380 - accuracy: 0.8443 - val_loss: 0.3407 - val_accuracy: 0.8452\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 2s 991us/step - loss: 0.3324 - accuracy: 0.8507 - val_loss: 0.3434 - val_accuracy: 0.8412\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3379 - accuracy: 0.8483 - val_loss: 0.3485 - val_accuracy: 0.8402\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 855us/step - loss: 0.3325 - accuracy: 0.8522 - val_loss: 0.3390 - val_accuracy: 0.8466\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.3431 - accuracy: 0.8448 - val_loss: 0.3397 - val_accuracy: 0.8448\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3298 - accuracy: 0.8560 - val_loss: 0.3380 - val_accuracy: 0.8474\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3327 - accuracy: 0.8491 - val_loss: 0.3458 - val_accuracy: 0.8454\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 835us/step - loss: 0.3366 - accuracy: 0.8494 - val_loss: 0.3396 - val_accuracy: 0.8472\n",
      "400/400 [==============================] - 0s 697us/step - loss: 0.3284 - accuracy: 0.8528\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 772us/step - loss: 0.5021 - accuracy: 0.7679 - val_loss: 0.3844 - val_accuracy: 0.8094\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 688us/step - loss: 0.3730 - accuracy: 0.8246 - val_loss: 0.3727 - val_accuracy: 0.8242\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3613 - accuracy: 0.8288 - val_loss: 0.3657 - val_accuracy: 0.8268\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3697 - accuracy: 0.8253 - val_loss: 0.3678 - val_accuracy: 0.8278\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3609 - accuracy: 0.8337 - val_loss: 0.3607 - val_accuracy: 0.8306\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 813us/step - loss: 0.3550 - accuracy: 0.8350 - val_loss: 0.3595 - val_accuracy: 0.8366\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3605 - accuracy: 0.8324 - val_loss: 0.3558 - val_accuracy: 0.8358\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3550 - accuracy: 0.8393 - val_loss: 0.3559 - val_accuracy: 0.8368\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 736us/step - loss: 0.3482 - accuracy: 0.8415 - val_loss: 0.3514 - val_accuracy: 0.8404\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3502 - accuracy: 0.8445 - val_loss: 0.3534 - val_accuracy: 0.8416\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3386 - accuracy: 0.8493 - val_loss: 0.3510 - val_accuracy: 0.8430\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3439 - accuracy: 0.8460 - val_loss: 0.3471 - val_accuracy: 0.8428\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3456 - accuracy: 0.8403 - val_loss: 0.3530 - val_accuracy: 0.8436\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.3420 - accuracy: 0.8466 - val_loss: 0.3472 - val_accuracy: 0.8442\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3391 - accuracy: 0.8486 - val_loss: 0.3458 - val_accuracy: 0.8430\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3363 - accuracy: 0.8491 - val_loss: 0.3462 - val_accuracy: 0.8434\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3322 - accuracy: 0.8494 - val_loss: 0.3430 - val_accuracy: 0.8462\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3391 - accuracy: 0.8466 - val_loss: 0.3415 - val_accuracy: 0.8474\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3263 - accuracy: 0.8554 - val_loss: 0.3417 - val_accuracy: 0.8466\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3412 - accuracy: 0.8469 - val_loss: 0.3438 - val_accuracy: 0.8480\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3323 - accuracy: 0.8504 - val_loss: 0.3473 - val_accuracy: 0.8448\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 944us/step - loss: 0.3287 - accuracy: 0.8521 - val_loss: 0.3497 - val_accuracy: 0.8414\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3276 - accuracy: 0.8520 - val_loss: 0.3472 - val_accuracy: 0.8442\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 844us/step - loss: 0.3300 - accuracy: 0.8475 - val_loss: 0.3412 - val_accuracy: 0.8476\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3285 - accuracy: 0.8519 - val_loss: 0.3435 - val_accuracy: 0.8460\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 815us/step - loss: 0.3240 - accuracy: 0.8564 - val_loss: 0.3403 - val_accuracy: 0.8460\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.3229 - accuracy: 0.8559 - val_loss: 0.3384 - val_accuracy: 0.8466\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3327 - accuracy: 0.8516 - val_loss: 0.3439 - val_accuracy: 0.8460\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3284 - accuracy: 0.8525 - val_loss: 0.3447 - val_accuracy: 0.8456\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3284 - accuracy: 0.8540 - val_loss: 0.3415 - val_accuracy: 0.8462\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3295 - accuracy: 0.8507 - val_loss: 0.3432 - val_accuracy: 0.8468\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3321 - accuracy: 0.8521 - val_loss: 0.3404 - val_accuracy: 0.8462\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3296 - accuracy: 0.8513 - val_loss: 0.3400 - val_accuracy: 0.8480\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3303 - accuracy: 0.8541 - val_loss: 0.3417 - val_accuracy: 0.8474\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 851us/step - loss: 0.3276 - accuracy: 0.8515 - val_loss: 0.3432 - val_accuracy: 0.8470\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3252 - accuracy: 0.8545 - val_loss: 0.3385 - val_accuracy: 0.8472\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 927us/step - loss: 0.3361 - accuracy: 0.8494 - val_loss: 0.3445 - val_accuracy: 0.8476\n",
      "400/400 [==============================] - 0s 710us/step - loss: 0.3395 - accuracy: 0.8500\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 787us/step - loss: 0.5153 - accuracy: 0.7632 - val_loss: 0.3904 - val_accuracy: 0.8152\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3909 - accuracy: 0.8182 - val_loss: 0.3831 - val_accuracy: 0.8188\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3749 - accuracy: 0.8264 - val_loss: 0.3791 - val_accuracy: 0.8178\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3689 - accuracy: 0.8296 - val_loss: 0.3758 - val_accuracy: 0.8204\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3737 - accuracy: 0.8256 - val_loss: 0.3705 - val_accuracy: 0.8206\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3646 - accuracy: 0.8301 - val_loss: 0.3666 - val_accuracy: 0.8220\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 989us/step - loss: 0.3586 - accuracy: 0.8330 - val_loss: 0.3651 - val_accuracy: 0.8222\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3677 - accuracy: 0.8238 - val_loss: 0.3621 - val_accuracy: 0.8222\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3554 - accuracy: 0.8352 - val_loss: 0.3609 - val_accuracy: 0.8230\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 736us/step - loss: 0.3629 - accuracy: 0.8323 - val_loss: 0.3629 - val_accuracy: 0.8326\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3598 - accuracy: 0.8365 - val_loss: 0.3614 - val_accuracy: 0.8330\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 731us/step - loss: 0.3579 - accuracy: 0.8360 - val_loss: 0.3624 - val_accuracy: 0.8330\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3527 - accuracy: 0.8406 - val_loss: 0.3585 - val_accuracy: 0.8374\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 756us/step - loss: 0.3495 - accuracy: 0.8418 - val_loss: 0.3576 - val_accuracy: 0.8356\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 749us/step - loss: 0.3663 - accuracy: 0.8350 - val_loss: 0.3595 - val_accuracy: 0.8362\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3567 - accuracy: 0.8383 - val_loss: 0.3595 - val_accuracy: 0.8368\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 751us/step - loss: 0.3564 - accuracy: 0.8385 - val_loss: 0.3611 - val_accuracy: 0.8392\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3559 - accuracy: 0.8356 - val_loss: 0.3569 - val_accuracy: 0.8380\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3585 - accuracy: 0.8378 - val_loss: 0.3580 - val_accuracy: 0.8390\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 879us/step - loss: 0.3608 - accuracy: 0.8380 - val_loss: 0.3605 - val_accuracy: 0.8394\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3580 - accuracy: 0.8403 - val_loss: 0.3584 - val_accuracy: 0.8384\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 904us/step - loss: 0.3545 - accuracy: 0.8428 - val_loss: 0.3575 - val_accuracy: 0.8396\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3487 - accuracy: 0.8444 - val_loss: 0.3609 - val_accuracy: 0.8382\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 773us/step - loss: 0.3560 - accuracy: 0.8435 - val_loss: 0.3585 - val_accuracy: 0.8402\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3576 - accuracy: 0.8401 - val_loss: 0.3583 - val_accuracy: 0.8402\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 713us/step - loss: 0.3517 - accuracy: 0.8443 - val_loss: 0.3581 - val_accuracy: 0.8398\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3507 - accuracy: 0.8400 - val_loss: 0.3575 - val_accuracy: 0.8382\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3499 - accuracy: 0.8417 - val_loss: 0.3558 - val_accuracy: 0.8384\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 713us/step - loss: 0.3521 - accuracy: 0.8449 - val_loss: 0.3602 - val_accuracy: 0.8394\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3513 - accuracy: 0.8432 - val_loss: 0.3582 - val_accuracy: 0.8380\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 2s 999us/step - loss: 0.3499 - accuracy: 0.8436 - val_loss: 0.3627 - val_accuracy: 0.8384\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3540 - accuracy: 0.8408 - val_loss: 0.3609 - val_accuracy: 0.8382\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3484 - accuracy: 0.8436 - val_loss: 0.3557 - val_accuracy: 0.8370\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3521 - accuracy: 0.8421 - val_loss: 0.3604 - val_accuracy: 0.8378\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 744us/step - loss: 0.3416 - accuracy: 0.8496 - val_loss: 0.3565 - val_accuracy: 0.8382\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3570 - accuracy: 0.8433 - val_loss: 0.3645 - val_accuracy: 0.8392\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3656 - accuracy: 0.8371 - val_loss: 0.3620 - val_accuracy: 0.8426\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3514 - accuracy: 0.8454 - val_loss: 0.3563 - val_accuracy: 0.8416\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3589 - accuracy: 0.8429 - val_loss: 0.3534 - val_accuracy: 0.8402\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3509 - accuracy: 0.8457 - val_loss: 0.3543 - val_accuracy: 0.8428\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 778us/step - loss: 0.3536 - accuracy: 0.8431 - val_loss: 0.3579 - val_accuracy: 0.8410\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3484 - accuracy: 0.8481 - val_loss: 0.3542 - val_accuracy: 0.8414\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3477 - accuracy: 0.8454 - val_loss: 0.3578 - val_accuracy: 0.8398\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 806us/step - loss: 0.3505 - accuracy: 0.8468 - val_loss: 0.3558 - val_accuracy: 0.8406\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3453 - accuracy: 0.8511 - val_loss: 0.3541 - val_accuracy: 0.8430\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 736us/step - loss: 0.3446 - accuracy: 0.8485 - val_loss: 0.3526 - val_accuracy: 0.8430\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3455 - accuracy: 0.8505 - val_loss: 0.3622 - val_accuracy: 0.8404\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3380 - accuracy: 0.8528 - val_loss: 0.3534 - val_accuracy: 0.8450\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 716us/step - loss: 0.3427 - accuracy: 0.8516 - val_loss: 0.3575 - val_accuracy: 0.8432\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3462 - accuracy: 0.8510 - val_loss: 0.3589 - val_accuracy: 0.8414\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3509 - accuracy: 0.8464 - val_loss: 0.3556 - val_accuracy: 0.8446\n",
      "Epoch 52/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3444 - accuracy: 0.8521 - val_loss: 0.3554 - val_accuracy: 0.8424\n",
      "Epoch 53/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3438 - accuracy: 0.8515 - val_loss: 0.3623 - val_accuracy: 0.8400\n",
      "Epoch 54/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3481 - accuracy: 0.8499 - val_loss: 0.3546 - val_accuracy: 0.8404\n",
      "Epoch 55/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3379 - accuracy: 0.8537 - val_loss: 0.3569 - val_accuracy: 0.8444\n",
      "Epoch 56/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3530 - accuracy: 0.8471 - val_loss: 0.3561 - val_accuracy: 0.8418\n",
      "400/400 [==============================] - 0s 740us/step - loss: 0.3528 - accuracy: 0.8447\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 778us/step - loss: 0.5271 - accuracy: 0.7568 - val_loss: 0.3926 - val_accuracy: 0.8130\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3917 - accuracy: 0.8182 - val_loss: 0.3829 - val_accuracy: 0.8176\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3786 - accuracy: 0.8266 - val_loss: 0.3791 - val_accuracy: 0.8196\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 853us/step - loss: 0.3758 - accuracy: 0.8236 - val_loss: 0.3706 - val_accuracy: 0.8206\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3677 - accuracy: 0.8278 - val_loss: 0.3669 - val_accuracy: 0.8250\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 864us/step - loss: 0.3658 - accuracy: 0.8372 - val_loss: 0.3652 - val_accuracy: 0.8324\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 713us/step - loss: 0.3630 - accuracy: 0.8364 - val_loss: 0.3652 - val_accuracy: 0.8318\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3547 - accuracy: 0.8420 - val_loss: 0.3658 - val_accuracy: 0.8330\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3558 - accuracy: 0.8428 - val_loss: 0.3637 - val_accuracy: 0.8362\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3578 - accuracy: 0.8373 - val_loss: 0.3614 - val_accuracy: 0.8360\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3566 - accuracy: 0.8424 - val_loss: 0.3636 - val_accuracy: 0.8360\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3662 - accuracy: 0.8372 - val_loss: 0.3617 - val_accuracy: 0.8384\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3513 - accuracy: 0.8453 - val_loss: 0.3609 - val_accuracy: 0.8384\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3582 - accuracy: 0.8369 - val_loss: 0.3614 - val_accuracy: 0.8376\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3526 - accuracy: 0.8427 - val_loss: 0.3633 - val_accuracy: 0.8378\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3531 - accuracy: 0.8443 - val_loss: 0.3613 - val_accuracy: 0.8390\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3570 - accuracy: 0.8446 - val_loss: 0.3608 - val_accuracy: 0.8382\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3608 - accuracy: 0.8414 - val_loss: 0.3615 - val_accuracy: 0.8374\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3473 - accuracy: 0.8471 - val_loss: 0.3649 - val_accuracy: 0.8364\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3578 - accuracy: 0.8427 - val_loss: 0.3637 - val_accuracy: 0.8384\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3574 - accuracy: 0.8423 - val_loss: 0.3621 - val_accuracy: 0.8382\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3519 - accuracy: 0.8483 - val_loss: 0.3633 - val_accuracy: 0.8402\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3522 - accuracy: 0.8456 - val_loss: 0.3618 - val_accuracy: 0.8388\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3494 - accuracy: 0.8474 - val_loss: 0.3587 - val_accuracy: 0.8428\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3509 - accuracy: 0.8488 - val_loss: 0.3595 - val_accuracy: 0.8412\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3538 - accuracy: 0.8430 - val_loss: 0.3625 - val_accuracy: 0.8406\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3461 - accuracy: 0.8501 - val_loss: 0.3593 - val_accuracy: 0.8402\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 775us/step - loss: 0.3447 - accuracy: 0.8514 - val_loss: 0.3591 - val_accuracy: 0.8406\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.3466 - accuracy: 0.8491 - val_loss: 0.3608 - val_accuracy: 0.8406\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3539 - accuracy: 0.8450 - val_loss: 0.3651 - val_accuracy: 0.8386\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3528 - accuracy: 0.8455 - val_loss: 0.3694 - val_accuracy: 0.8412\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3521 - accuracy: 0.8454 - val_loss: 0.3576 - val_accuracy: 0.8420\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3493 - accuracy: 0.8503 - val_loss: 0.3601 - val_accuracy: 0.8410\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3447 - accuracy: 0.8522 - val_loss: 0.3590 - val_accuracy: 0.8360\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3521 - accuracy: 0.8496 - val_loss: 0.3607 - val_accuracy: 0.8418\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 723us/step - loss: 0.3441 - accuracy: 0.8544 - val_loss: 0.3651 - val_accuracy: 0.8400\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 921us/step - loss: 0.3445 - accuracy: 0.8515 - val_loss: 0.3601 - val_accuracy: 0.8376\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3573 - accuracy: 0.8467 - val_loss: 0.3630 - val_accuracy: 0.8422\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 861us/step - loss: 0.3448 - accuracy: 0.8529 - val_loss: 0.3604 - val_accuracy: 0.8414\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3545 - accuracy: 0.8484 - val_loss: 0.3614 - val_accuracy: 0.8414\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3472 - accuracy: 0.8510 - val_loss: 0.3569 - val_accuracy: 0.8420\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3467 - accuracy: 0.8500 - val_loss: 0.3589 - val_accuracy: 0.8416\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3449 - accuracy: 0.8543 - val_loss: 0.3609 - val_accuracy: 0.8412\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3511 - accuracy: 0.8489 - val_loss: 0.3636 - val_accuracy: 0.8400\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3529 - accuracy: 0.8479 - val_loss: 0.3607 - val_accuracy: 0.8424\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3528 - accuracy: 0.8476 - val_loss: 0.3603 - val_accuracy: 0.8416\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3544 - accuracy: 0.8472 - val_loss: 0.3608 - val_accuracy: 0.8410\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3535 - accuracy: 0.8483 - val_loss: 0.3609 - val_accuracy: 0.8422\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3483 - accuracy: 0.8504 - val_loss: 0.3618 - val_accuracy: 0.8414\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 713us/step - loss: 0.3490 - accuracy: 0.8492 - val_loss: 0.3585 - val_accuracy: 0.8424\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3542 - accuracy: 0.8456 - val_loss: 0.3624 - val_accuracy: 0.8404\n",
      "400/400 [==============================] - 0s 727us/step - loss: 0.3685 - accuracy: 0.8335\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 778us/step - loss: 0.4890 - accuracy: 0.7624 - val_loss: 0.3869 - val_accuracy: 0.8118\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3974 - accuracy: 0.8143 - val_loss: 0.3803 - val_accuracy: 0.8176\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3782 - accuracy: 0.8228 - val_loss: 0.3709 - val_accuracy: 0.8232\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 817us/step - loss: 0.3641 - accuracy: 0.8315 - val_loss: 0.3667 - val_accuracy: 0.8270\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3712 - accuracy: 0.8276 - val_loss: 0.3663 - val_accuracy: 0.8352\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 946us/step - loss: 0.3699 - accuracy: 0.8304 - val_loss: 0.3694 - val_accuracy: 0.8250\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3617 - accuracy: 0.8356 - val_loss: 0.3626 - val_accuracy: 0.8362\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3653 - accuracy: 0.8330 - val_loss: 0.3596 - val_accuracy: 0.8390\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3680 - accuracy: 0.8322 - val_loss: 0.3601 - val_accuracy: 0.8380\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3486 - accuracy: 0.8422 - val_loss: 0.3579 - val_accuracy: 0.8400\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 818us/step - loss: 0.3540 - accuracy: 0.8408 - val_loss: 0.3591 - val_accuracy: 0.8400\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 716us/step - loss: 0.3518 - accuracy: 0.8393 - val_loss: 0.3604 - val_accuracy: 0.8406\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3567 - accuracy: 0.8394 - val_loss: 0.3604 - val_accuracy: 0.8422\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 889us/step - loss: 0.3546 - accuracy: 0.8373 - val_loss: 0.3584 - val_accuracy: 0.8416\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3488 - accuracy: 0.8435 - val_loss: 0.3579 - val_accuracy: 0.8418\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 835us/step - loss: 0.3578 - accuracy: 0.8428 - val_loss: 0.3571 - val_accuracy: 0.8440\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3431 - accuracy: 0.8484 - val_loss: 0.3585 - val_accuracy: 0.8422\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3451 - accuracy: 0.8463 - val_loss: 0.3510 - val_accuracy: 0.8404\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3501 - accuracy: 0.8453 - val_loss: 0.3556 - val_accuracy: 0.8440\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3501 - accuracy: 0.8466 - val_loss: 0.3502 - val_accuracy: 0.8466\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 766us/step - loss: 0.3483 - accuracy: 0.8467 - val_loss: 0.3469 - val_accuracy: 0.8444\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3493 - accuracy: 0.8479 - val_loss: 0.3527 - val_accuracy: 0.8436\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3457 - accuracy: 0.8498 - val_loss: 0.3511 - val_accuracy: 0.8440\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3450 - accuracy: 0.8488 - val_loss: 0.3523 - val_accuracy: 0.8484\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3398 - accuracy: 0.8535 - val_loss: 0.3564 - val_accuracy: 0.8380\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3407 - accuracy: 0.8511 - val_loss: 0.3492 - val_accuracy: 0.8480\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3459 - accuracy: 0.8503 - val_loss: 0.3456 - val_accuracy: 0.8442\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3384 - accuracy: 0.8527 - val_loss: 0.3428 - val_accuracy: 0.8484\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3381 - accuracy: 0.8511 - val_loss: 0.3471 - val_accuracy: 0.8482\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 723us/step - loss: 0.3408 - accuracy: 0.8515 - val_loss: 0.3502 - val_accuracy: 0.8492\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 778us/step - loss: 0.3412 - accuracy: 0.8529 - val_loss: 0.3466 - val_accuracy: 0.8492\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3360 - accuracy: 0.8520 - val_loss: 0.3463 - val_accuracy: 0.8514\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3357 - accuracy: 0.8531 - val_loss: 0.3417 - val_accuracy: 0.8484\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3381 - accuracy: 0.8525 - val_loss: 0.3464 - val_accuracy: 0.8434\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3426 - accuracy: 0.8476 - val_loss: 0.3441 - val_accuracy: 0.8468\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3400 - accuracy: 0.8491 - val_loss: 0.3489 - val_accuracy: 0.8434\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.3389 - accuracy: 0.8507 - val_loss: 0.3456 - val_accuracy: 0.8502\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3418 - accuracy: 0.8473 - val_loss: 0.3469 - val_accuracy: 0.8440\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3362 - accuracy: 0.8502 - val_loss: 0.3465 - val_accuracy: 0.8470\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3387 - accuracy: 0.8473 - val_loss: 0.3409 - val_accuracy: 0.8486\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 773us/step - loss: 0.3281 - accuracy: 0.8550 - val_loss: 0.3465 - val_accuracy: 0.8432\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 763us/step - loss: 0.3404 - accuracy: 0.8487 - val_loss: 0.3415 - val_accuracy: 0.8510\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3406 - accuracy: 0.8486 - val_loss: 0.3429 - val_accuracy: 0.8420\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3402 - accuracy: 0.8476 - val_loss: 0.3447 - val_accuracy: 0.8508\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3391 - accuracy: 0.8480 - val_loss: 0.3439 - val_accuracy: 0.8490\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3446 - accuracy: 0.8507 - val_loss: 0.3443 - val_accuracy: 0.8482\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3424 - accuracy: 0.8488 - val_loss: 0.3432 - val_accuracy: 0.8508\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3328 - accuracy: 0.8525 - val_loss: 0.3409 - val_accuracy: 0.8498\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3438 - accuracy: 0.8511 - val_loss: 0.3520 - val_accuracy: 0.8424\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 879us/step - loss: 0.3360 - accuracy: 0.8519 - val_loss: 0.3459 - val_accuracy: 0.8526\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 1s 713us/step - loss: 0.3345 - accuracy: 0.8534 - val_loss: 0.3478 - val_accuracy: 0.8488\n",
      "Epoch 52/1000\n",
      "1600/1600 [==============================] - 1s 788us/step - loss: 0.3409 - accuracy: 0.8476 - val_loss: 0.3446 - val_accuracy: 0.8460\n",
      "Epoch 53/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3417 - accuracy: 0.8486 - val_loss: 0.3556 - val_accuracy: 0.8464\n",
      "Epoch 54/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3380 - accuracy: 0.8513 - val_loss: 0.3650 - val_accuracy: 0.8484\n",
      "Epoch 55/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3332 - accuracy: 0.8565 - val_loss: 0.3472 - val_accuracy: 0.8476\n",
      "Epoch 56/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3298 - accuracy: 0.8560 - val_loss: 0.3467 - val_accuracy: 0.8528\n",
      "Epoch 57/1000\n",
      "1600/1600 [==============================] - 1s 850us/step - loss: 0.3272 - accuracy: 0.8568 - val_loss: 0.3525 - val_accuracy: 0.8482\n",
      "Epoch 58/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3387 - accuracy: 0.8491 - val_loss: 0.3533 - val_accuracy: 0.8486\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3278 - accuracy: 0.8550\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 773us/step - loss: 0.4847 - accuracy: 0.7735 - val_loss: 0.3847 - val_accuracy: 0.8170\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3853 - accuracy: 0.8196 - val_loss: 0.3764 - val_accuracy: 0.8210\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 803us/step - loss: 0.3699 - accuracy: 0.8261 - val_loss: 0.3702 - val_accuracy: 0.8232\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3661 - accuracy: 0.8304 - val_loss: 0.3654 - val_accuracy: 0.8318\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3578 - accuracy: 0.8393 - val_loss: 0.3658 - val_accuracy: 0.8306\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.3515 - accuracy: 0.8460 - val_loss: 0.3629 - val_accuracy: 0.8336\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3532 - accuracy: 0.8417 - val_loss: 0.3644 - val_accuracy: 0.8394\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 772us/step - loss: 0.3547 - accuracy: 0.8418 - val_loss: 0.3617 - val_accuracy: 0.8392\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3587 - accuracy: 0.8396 - val_loss: 0.3598 - val_accuracy: 0.8396\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3583 - accuracy: 0.8419 - val_loss: 0.3669 - val_accuracy: 0.8398\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3621 - accuracy: 0.8387 - val_loss: 0.3614 - val_accuracy: 0.8418\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3635 - accuracy: 0.8416 - val_loss: 0.3635 - val_accuracy: 0.8384\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3510 - accuracy: 0.8464 - val_loss: 0.3585 - val_accuracy: 0.8408\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3524 - accuracy: 0.8454 - val_loss: 0.3589 - val_accuracy: 0.8416\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3516 - accuracy: 0.8426 - val_loss: 0.3556 - val_accuracy: 0.8412\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3551 - accuracy: 0.8454 - val_loss: 0.3594 - val_accuracy: 0.8414\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3488 - accuracy: 0.8504 - val_loss: 0.3517 - val_accuracy: 0.8428\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3466 - accuracy: 0.8462 - val_loss: 0.3568 - val_accuracy: 0.8424\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3470 - accuracy: 0.8473 - val_loss: 0.3643 - val_accuracy: 0.8380\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3479 - accuracy: 0.8444 - val_loss: 0.3570 - val_accuracy: 0.8440\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3434 - accuracy: 0.8524 - val_loss: 0.3537 - val_accuracy: 0.8434\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3414 - accuracy: 0.8519 - val_loss: 0.3529 - val_accuracy: 0.8412\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3485 - accuracy: 0.8490 - val_loss: 0.3512 - val_accuracy: 0.8428\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3413 - accuracy: 0.8511 - val_loss: 0.3503 - val_accuracy: 0.8440\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3510 - accuracy: 0.8453 - val_loss: 0.3561 - val_accuracy: 0.8444\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3407 - accuracy: 0.8515 - val_loss: 0.3525 - val_accuracy: 0.8440\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 835us/step - loss: 0.3432 - accuracy: 0.8520 - val_loss: 0.3528 - val_accuracy: 0.8408\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 888us/step - loss: 0.3366 - accuracy: 0.8583 - val_loss: 0.3567 - val_accuracy: 0.8416\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 770us/step - loss: 0.3386 - accuracy: 0.8532 - val_loss: 0.3502 - val_accuracy: 0.8444\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3393 - accuracy: 0.8535 - val_loss: 0.3574 - val_accuracy: 0.8436\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3425 - accuracy: 0.8555 - val_loss: 0.3530 - val_accuracy: 0.8444\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3445 - accuracy: 0.8492 - val_loss: 0.3548 - val_accuracy: 0.8470\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3482 - accuracy: 0.8507 - val_loss: 0.3580 - val_accuracy: 0.8440\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3410 - accuracy: 0.8532 - val_loss: 0.3583 - val_accuracy: 0.8426\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3363 - accuracy: 0.8561 - val_loss: 0.3583 - val_accuracy: 0.8422\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 716us/step - loss: 0.3421 - accuracy: 0.8556 - val_loss: 0.3531 - val_accuracy: 0.8432\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3454 - accuracy: 0.8502 - val_loss: 0.3667 - val_accuracy: 0.8450\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3395 - accuracy: 0.8563 - val_loss: 0.3598 - val_accuracy: 0.8450\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3419 - accuracy: 0.8566 - val_loss: 0.3562 - val_accuracy: 0.8450\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3414 - accuracy: 0.8547\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 790us/step - loss: 0.4907 - accuracy: 0.7713 - val_loss: 0.3866 - val_accuracy: 0.8172\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3901 - accuracy: 0.8162 - val_loss: 0.3837 - val_accuracy: 0.8144\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3854 - accuracy: 0.8209 - val_loss: 0.3786 - val_accuracy: 0.8218\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3702 - accuracy: 0.8249 - val_loss: 0.3732 - val_accuracy: 0.8240\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3583 - accuracy: 0.8313 - val_loss: 0.3702 - val_accuracy: 0.8240\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 723us/step - loss: 0.3699 - accuracy: 0.8236 - val_loss: 0.3693 - val_accuracy: 0.8246\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3667 - accuracy: 0.8265 - val_loss: 0.3670 - val_accuracy: 0.8232\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 801us/step - loss: 0.3686 - accuracy: 0.8255 - val_loss: 0.3665 - val_accuracy: 0.8238\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 2s 957us/step - loss: 0.3570 - accuracy: 0.8328 - val_loss: 0.3655 - val_accuracy: 0.8238\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3598 - accuracy: 0.8349 - val_loss: 0.3647 - val_accuracy: 0.8258\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3585 - accuracy: 0.8337 - val_loss: 0.3668 - val_accuracy: 0.8286\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 735us/step - loss: 0.3663 - accuracy: 0.8297 - val_loss: 0.3624 - val_accuracy: 0.8266\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3669 - accuracy: 0.8307 - val_loss: 0.3658 - val_accuracy: 0.8332\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3605 - accuracy: 0.8319 - val_loss: 0.3582 - val_accuracy: 0.8338\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3576 - accuracy: 0.8368 - val_loss: 0.3598 - val_accuracy: 0.8354\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3499 - accuracy: 0.8453 - val_loss: 0.3560 - val_accuracy: 0.8388\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3535 - accuracy: 0.8428 - val_loss: 0.3593 - val_accuracy: 0.8398\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3431 - accuracy: 0.8481 - val_loss: 0.3618 - val_accuracy: 0.8348\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3462 - accuracy: 0.8463 - val_loss: 0.3542 - val_accuracy: 0.8398\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3472 - accuracy: 0.8500 - val_loss: 0.3541 - val_accuracy: 0.8416\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3466 - accuracy: 0.8498 - val_loss: 0.3593 - val_accuracy: 0.8410\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 782us/step - loss: 0.3453 - accuracy: 0.8497 - val_loss: 0.3506 - val_accuracy: 0.8414\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3490 - accuracy: 0.8463 - val_loss: 0.3559 - val_accuracy: 0.8422\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3487 - accuracy: 0.8427 - val_loss: 0.3521 - val_accuracy: 0.8406\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 853us/step - loss: 0.3525 - accuracy: 0.8445 - val_loss: 0.3535 - val_accuracy: 0.8410\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3537 - accuracy: 0.8456 - val_loss: 0.3564 - val_accuracy: 0.8428\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 931us/step - loss: 0.3449 - accuracy: 0.8457 - val_loss: 0.3523 - val_accuracy: 0.8428\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 798us/step - loss: 0.3420 - accuracy: 0.8473 - val_loss: 0.3561 - val_accuracy: 0.8426\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3331 - accuracy: 0.8527 - val_loss: 0.3528 - val_accuracy: 0.8410\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 2s 973us/step - loss: 0.3401 - accuracy: 0.8456 - val_loss: 0.3535 - val_accuracy: 0.8434\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3392 - accuracy: 0.8482 - val_loss: 0.3503 - val_accuracy: 0.8440\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3387 - accuracy: 0.8535 - val_loss: 0.3461 - val_accuracy: 0.8452\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3368 - accuracy: 0.8542 - val_loss: 0.3465 - val_accuracy: 0.8440\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3392 - accuracy: 0.8471 - val_loss: 0.3519 - val_accuracy: 0.8434\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3382 - accuracy: 0.8500 - val_loss: 0.3528 - val_accuracy: 0.8422\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3331 - accuracy: 0.8559 - val_loss: 0.3466 - val_accuracy: 0.8438\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3377 - accuracy: 0.8511 - val_loss: 0.3698 - val_accuracy: 0.8272\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3413 - accuracy: 0.8473 - val_loss: 0.3546 - val_accuracy: 0.8364\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3299 - accuracy: 0.8547 - val_loss: 0.3458 - val_accuracy: 0.8456\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 840us/step - loss: 0.3382 - accuracy: 0.8527 - val_loss: 0.3488 - val_accuracy: 0.8440\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3357 - accuracy: 0.8525 - val_loss: 0.3446 - val_accuracy: 0.8462\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3278 - accuracy: 0.8546 - val_loss: 0.3426 - val_accuracy: 0.8474\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 736us/step - loss: 0.3289 - accuracy: 0.8551 - val_loss: 0.3426 - val_accuracy: 0.8472\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 820us/step - loss: 0.3368 - accuracy: 0.8505 - val_loss: 0.3458 - val_accuracy: 0.8454\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3307 - accuracy: 0.8549 - val_loss: 0.3431 - val_accuracy: 0.8472\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3341 - accuracy: 0.8550 - val_loss: 0.3467 - val_accuracy: 0.8438\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3307 - accuracy: 0.8604 - val_loss: 0.3437 - val_accuracy: 0.8462\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3342 - accuracy: 0.8515 - val_loss: 0.3454 - val_accuracy: 0.8474\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 788us/step - loss: 0.3420 - accuracy: 0.8476 - val_loss: 0.3463 - val_accuracy: 0.8456\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3286 - accuracy: 0.8569 - val_loss: 0.3406 - val_accuracy: 0.8486\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 1s 713us/step - loss: 0.3331 - accuracy: 0.8522 - val_loss: 0.3507 - val_accuracy: 0.8446\n",
      "Epoch 52/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3241 - accuracy: 0.8600 - val_loss: 0.3436 - val_accuracy: 0.8480\n",
      "Epoch 53/1000\n",
      "1600/1600 [==============================] - 1s 894us/step - loss: 0.3356 - accuracy: 0.8576 - val_loss: 0.3509 - val_accuracy: 0.8480\n",
      "Epoch 54/1000\n",
      "1600/1600 [==============================] - 1s 736us/step - loss: 0.3315 - accuracy: 0.8569 - val_loss: 0.3530 - val_accuracy: 0.8464\n",
      "Epoch 55/1000\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.3346 - accuracy: 0.8546 - val_loss: 0.3482 - val_accuracy: 0.8486\n",
      "Epoch 56/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3348 - accuracy: 0.8543 - val_loss: 0.3558 - val_accuracy: 0.8438\n",
      "Epoch 57/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3351 - accuracy: 0.8567 - val_loss: 0.3493 - val_accuracy: 0.8458\n",
      "Epoch 58/1000\n",
      "1600/1600 [==============================] - 1s 728us/step - loss: 0.3350 - accuracy: 0.8547 - val_loss: 0.3518 - val_accuracy: 0.8474\n",
      "Epoch 59/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3274 - accuracy: 0.8574 - val_loss: 0.3447 - val_accuracy: 0.8472\n",
      "Epoch 60/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3305 - accuracy: 0.8573 - val_loss: 0.3455 - val_accuracy: 0.8468\n",
      "400/400 [==============================] - 0s 880us/step - loss: 0.3403 - accuracy: 0.8535\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 800us/step - loss: 0.4759 - accuracy: 0.7789 - val_loss: 0.3827 - val_accuracy: 0.8168\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 854us/step - loss: 0.3766 - accuracy: 0.8241 - val_loss: 0.3715 - val_accuracy: 0.8244\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 767us/step - loss: 0.3669 - accuracy: 0.8331 - val_loss: 0.3648 - val_accuracy: 0.8344\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3653 - accuracy: 0.8332 - val_loss: 0.3677 - val_accuracy: 0.8368\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 754us/step - loss: 0.3607 - accuracy: 0.8409 - val_loss: 0.3609 - val_accuracy: 0.8410\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3502 - accuracy: 0.8428 - val_loss: 0.3605 - val_accuracy: 0.8416\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 937us/step - loss: 0.3548 - accuracy: 0.8449 - val_loss: 0.3604 - val_accuracy: 0.8370\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3533 - accuracy: 0.8382 - val_loss: 0.3604 - val_accuracy: 0.8378\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 816us/step - loss: 0.3530 - accuracy: 0.8402 - val_loss: 0.3579 - val_accuracy: 0.8380\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3536 - accuracy: 0.8430 - val_loss: 0.3590 - val_accuracy: 0.8332\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3546 - accuracy: 0.8401 - val_loss: 0.3578 - val_accuracy: 0.8402\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3574 - accuracy: 0.8439 - val_loss: 0.3595 - val_accuracy: 0.8418\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 763us/step - loss: 0.3603 - accuracy: 0.8430 - val_loss: 0.3644 - val_accuracy: 0.8376\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3513 - accuracy: 0.8433 - val_loss: 0.3602 - val_accuracy: 0.8412\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3572 - accuracy: 0.8419 - val_loss: 0.3553 - val_accuracy: 0.8470\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 792us/step - loss: 0.3466 - accuracy: 0.8475 - val_loss: 0.3534 - val_accuracy: 0.8400\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 808us/step - loss: 0.3397 - accuracy: 0.8512 - val_loss: 0.3550 - val_accuracy: 0.8414\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 801us/step - loss: 0.3465 - accuracy: 0.8473 - val_loss: 0.3639 - val_accuracy: 0.8344\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3473 - accuracy: 0.8473 - val_loss: 0.3572 - val_accuracy: 0.8464\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 723us/step - loss: 0.3462 - accuracy: 0.8503 - val_loss: 0.3532 - val_accuracy: 0.8412\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3447 - accuracy: 0.8461 - val_loss: 0.3487 - val_accuracy: 0.8434\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3457 - accuracy: 0.8499 - val_loss: 0.3482 - val_accuracy: 0.8466\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 798us/step - loss: 0.3406 - accuracy: 0.8490 - val_loss: 0.3499 - val_accuracy: 0.8432\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3438 - accuracy: 0.8490 - val_loss: 0.3522 - val_accuracy: 0.8450\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3441 - accuracy: 0.8530 - val_loss: 0.3510 - val_accuracy: 0.8450\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3378 - accuracy: 0.8529 - val_loss: 0.3443 - val_accuracy: 0.8460\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3423 - accuracy: 0.8507 - val_loss: 0.3603 - val_accuracy: 0.8404\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3412 - accuracy: 0.8491 - val_loss: 0.3595 - val_accuracy: 0.8454\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3400 - accuracy: 0.8488 - val_loss: 0.3563 - val_accuracy: 0.8446\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3365 - accuracy: 0.8551 - val_loss: 0.3585 - val_accuracy: 0.8448\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3403 - accuracy: 0.8530 - val_loss: 0.3516 - val_accuracy: 0.8472\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 728us/step - loss: 0.3356 - accuracy: 0.8532 - val_loss: 0.3500 - val_accuracy: 0.8436\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3420 - accuracy: 0.8515 - val_loss: 0.3531 - val_accuracy: 0.8446\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3441 - accuracy: 0.8489 - val_loss: 0.3504 - val_accuracy: 0.8456\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3439 - accuracy: 0.8473 - val_loss: 0.3544 - val_accuracy: 0.8456\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3355 - accuracy: 0.8524 - val_loss: 0.3546 - val_accuracy: 0.8456\n",
      "400/400 [==============================] - 0s 722us/step - loss: 0.3399 - accuracy: 0.8472\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 942us/step - loss: 0.4830 - accuracy: 0.7771 - val_loss: 0.3780 - val_accuracy: 0.8144\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3760 - accuracy: 0.8250 - val_loss: 0.3678 - val_accuracy: 0.8222\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3535 - accuracy: 0.8332 - val_loss: 0.3613 - val_accuracy: 0.8288\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3580 - accuracy: 0.8381 - val_loss: 0.3588 - val_accuracy: 0.8332\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3521 - accuracy: 0.8393 - val_loss: 0.3557 - val_accuracy: 0.8362\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3516 - accuracy: 0.8455 - val_loss: 0.3569 - val_accuracy: 0.8336\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3478 - accuracy: 0.8466 - val_loss: 0.3579 - val_accuracy: 0.8416\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 788us/step - loss: 0.3492 - accuracy: 0.8419 - val_loss: 0.3550 - val_accuracy: 0.8404\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3501 - accuracy: 0.8454 - val_loss: 0.3513 - val_accuracy: 0.8430\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 995us/step - loss: 0.3489 - accuracy: 0.8460 - val_loss: 0.3516 - val_accuracy: 0.8422\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3531 - accuracy: 0.8412 - val_loss: 0.3497 - val_accuracy: 0.8424\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3446 - accuracy: 0.8459 - val_loss: 0.3479 - val_accuracy: 0.8422\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 688us/step - loss: 0.3329 - accuracy: 0.8514 - val_loss: 0.3482 - val_accuracy: 0.8442\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3322 - accuracy: 0.8566 - val_loss: 0.3460 - val_accuracy: 0.8456\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3330 - accuracy: 0.8526 - val_loss: 0.3457 - val_accuracy: 0.8448\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 859us/step - loss: 0.3377 - accuracy: 0.8492 - val_loss: 0.3518 - val_accuracy: 0.8418\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3306 - accuracy: 0.8526 - val_loss: 0.3456 - val_accuracy: 0.8420\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 926us/step - loss: 0.3329 - accuracy: 0.8535 - val_loss: 0.3440 - val_accuracy: 0.8430\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 713us/step - loss: 0.3309 - accuracy: 0.8581 - val_loss: 0.3429 - val_accuracy: 0.8448\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3339 - accuracy: 0.8526 - val_loss: 0.3463 - val_accuracy: 0.8482\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 769us/step - loss: 0.3393 - accuracy: 0.8523 - val_loss: 0.3443 - val_accuracy: 0.8432\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3317 - accuracy: 0.8552 - val_loss: 0.3439 - val_accuracy: 0.8486\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 754us/step - loss: 0.3362 - accuracy: 0.8542 - val_loss: 0.3411 - val_accuracy: 0.8464\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3274 - accuracy: 0.8588 - val_loss: 0.3429 - val_accuracy: 0.8478\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3317 - accuracy: 0.8541 - val_loss: 0.3428 - val_accuracy: 0.8484\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 766us/step - loss: 0.3313 - accuracy: 0.8564 - val_loss: 0.3450 - val_accuracy: 0.8462\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3277 - accuracy: 0.8566 - val_loss: 0.3464 - val_accuracy: 0.8474\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 960us/step - loss: 0.3323 - accuracy: 0.8557 - val_loss: 0.3426 - val_accuracy: 0.8478\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3242 - accuracy: 0.8579 - val_loss: 0.3413 - val_accuracy: 0.8476\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3293 - accuracy: 0.8578 - val_loss: 0.3399 - val_accuracy: 0.8486\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3276 - accuracy: 0.8578 - val_loss: 0.3466 - val_accuracy: 0.8496\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3288 - accuracy: 0.8578 - val_loss: 0.3463 - val_accuracy: 0.8450\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3287 - accuracy: 0.8585 - val_loss: 0.3427 - val_accuracy: 0.8494\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 845us/step - loss: 0.3326 - accuracy: 0.8530 - val_loss: 0.3437 - val_accuracy: 0.8484\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3252 - accuracy: 0.8576 - val_loss: 0.3472 - val_accuracy: 0.8458\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 2s 939us/step - loss: 0.3244 - accuracy: 0.8583 - val_loss: 0.3426 - val_accuracy: 0.8504\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3273 - accuracy: 0.8589 - val_loss: 0.3489 - val_accuracy: 0.8484\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3243 - accuracy: 0.8612 - val_loss: 0.3441 - val_accuracy: 0.8470\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3300 - accuracy: 0.8560 - val_loss: 0.3425 - val_accuracy: 0.8478\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3277 - accuracy: 0.8513 - val_loss: 0.3446 - val_accuracy: 0.8468\n",
      "400/400 [==============================] - 0s 740us/step - loss: 0.3466 - accuracy: 0.8382\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 760us/step - loss: 0.4749 - accuracy: 0.7832 - val_loss: 0.3791 - val_accuracy: 0.8102\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 874us/step - loss: 0.3656 - accuracy: 0.8292 - val_loss: 0.3661 - val_accuracy: 0.8214\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3613 - accuracy: 0.8322 - val_loss: 0.3604 - val_accuracy: 0.8296\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 836us/step - loss: 0.3606 - accuracy: 0.8289 - val_loss: 0.3565 - val_accuracy: 0.8328\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3466 - accuracy: 0.8417 - val_loss: 0.3533 - val_accuracy: 0.8350\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3490 - accuracy: 0.8405 - val_loss: 0.3530 - val_accuracy: 0.8360\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3422 - accuracy: 0.8438 - val_loss: 0.3480 - val_accuracy: 0.8404\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 772us/step - loss: 0.3411 - accuracy: 0.8436 - val_loss: 0.3476 - val_accuracy: 0.8446\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3494 - accuracy: 0.8388 - val_loss: 0.3446 - val_accuracy: 0.8434\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3343 - accuracy: 0.8482 - val_loss: 0.3412 - val_accuracy: 0.8438\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3406 - accuracy: 0.8458 - val_loss: 0.3480 - val_accuracy: 0.8470\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 687us/step - loss: 0.3366 - accuracy: 0.8464 - val_loss: 0.3469 - val_accuracy: 0.8422\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 689us/step - loss: 0.3243 - accuracy: 0.8566 - val_loss: 0.3555 - val_accuracy: 0.8474\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3264 - accuracy: 0.8538 - val_loss: 0.3402 - val_accuracy: 0.8450\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3336 - accuracy: 0.8518 - val_loss: 0.3450 - val_accuracy: 0.8454\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3268 - accuracy: 0.8528 - val_loss: 0.3459 - val_accuracy: 0.8488\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3275 - accuracy: 0.8550 - val_loss: 0.3400 - val_accuracy: 0.8468\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 679us/step - loss: 0.3266 - accuracy: 0.8523 - val_loss: 0.3364 - val_accuracy: 0.8482\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3320 - accuracy: 0.8528 - val_loss: 0.3372 - val_accuracy: 0.8464\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3341 - accuracy: 0.8525 - val_loss: 0.3360 - val_accuracy: 0.8478\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3400 - accuracy: 0.8479 - val_loss: 0.3416 - val_accuracy: 0.8496\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 817us/step - loss: 0.3253 - accuracy: 0.8535 - val_loss: 0.3406 - val_accuracy: 0.8506\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3296 - accuracy: 0.8522 - val_loss: 0.3402 - val_accuracy: 0.8472\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3332 - accuracy: 0.8514 - val_loss: 0.3441 - val_accuracy: 0.8482\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 769us/step - loss: 0.3327 - accuracy: 0.8498 - val_loss: 0.3373 - val_accuracy: 0.8486\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3311 - accuracy: 0.8532 - val_loss: 0.3434 - val_accuracy: 0.8474\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3338 - accuracy: 0.8509 - val_loss: 0.3535 - val_accuracy: 0.8436\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.3383 - accuracy: 0.8476 - val_loss: 0.3413 - val_accuracy: 0.8482\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3323 - accuracy: 0.8500 - val_loss: 0.3428 - val_accuracy: 0.8444\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3231 - accuracy: 0.8548 - val_loss: 0.3398 - val_accuracy: 0.8482\n",
      "400/400 [==============================] - 0s 705us/step - loss: 0.3288 - accuracy: 0.8530\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4637 - accuracy: 0.7864 - val_loss: 0.3750 - val_accuracy: 0.8246\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3729 - accuracy: 0.8222 - val_loss: 0.3647 - val_accuracy: 0.8230\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3644 - accuracy: 0.8306 - val_loss: 0.3639 - val_accuracy: 0.8244\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3653 - accuracy: 0.8305 - val_loss: 0.3598 - val_accuracy: 0.8318\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 810us/step - loss: 0.3617 - accuracy: 0.8370 - val_loss: 0.3591 - val_accuracy: 0.8300\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 728us/step - loss: 0.3568 - accuracy: 0.8338 - val_loss: 0.3559 - val_accuracy: 0.8376\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3509 - accuracy: 0.8402 - val_loss: 0.3555 - val_accuracy: 0.8402\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3495 - accuracy: 0.8417 - val_loss: 0.3563 - val_accuracy: 0.8366\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 782us/step - loss: 0.3504 - accuracy: 0.8460 - val_loss: 0.3492 - val_accuracy: 0.8406\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 757us/step - loss: 0.3377 - accuracy: 0.8465 - val_loss: 0.3561 - val_accuracy: 0.8366\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3390 - accuracy: 0.8464 - val_loss: 0.3525 - val_accuracy: 0.8462\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 829us/step - loss: 0.3457 - accuracy: 0.8462 - val_loss: 0.3477 - val_accuracy: 0.8434\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3390 - accuracy: 0.8502 - val_loss: 0.3459 - val_accuracy: 0.8470\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 910us/step - loss: 0.3364 - accuracy: 0.8489 - val_loss: 0.3417 - val_accuracy: 0.8444\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3317 - accuracy: 0.8546 - val_loss: 0.3402 - val_accuracy: 0.8456\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3368 - accuracy: 0.8504 - val_loss: 0.3401 - val_accuracy: 0.8478\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 721us/step - loss: 0.3359 - accuracy: 0.8511 - val_loss: 0.3505 - val_accuracy: 0.8456\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3397 - accuracy: 0.8480 - val_loss: 0.3405 - val_accuracy: 0.8472\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 788us/step - loss: 0.3374 - accuracy: 0.8464 - val_loss: 0.3422 - val_accuracy: 0.8464\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3402 - accuracy: 0.8454 - val_loss: 0.3423 - val_accuracy: 0.8476\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 809us/step - loss: 0.3342 - accuracy: 0.8525 - val_loss: 0.3396 - val_accuracy: 0.8470\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3313 - accuracy: 0.8483 - val_loss: 0.3424 - val_accuracy: 0.8456\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 811us/step - loss: 0.3342 - accuracy: 0.8511 - val_loss: 0.3421 - val_accuracy: 0.8450\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.8514 - val_loss: 0.3418 - val_accuracy: 0.8450\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 2s 990us/step - loss: 0.3401 - accuracy: 0.8517 - val_loss: 0.3450 - val_accuracy: 0.8454\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3413 - accuracy: 0.8486 - val_loss: 0.3410 - val_accuracy: 0.8464\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3305 - accuracy: 0.8513 - val_loss: 0.3396 - val_accuracy: 0.8472\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3292 - accuracy: 0.8559 - val_loss: 0.3451 - val_accuracy: 0.8452\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3371 - accuracy: 0.8525 - val_loss: 0.3415 - val_accuracy: 0.8472\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3292 - accuracy: 0.8492 - val_loss: 0.3399 - val_accuracy: 0.8476\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 760us/step - loss: 0.3264 - accuracy: 0.8565 - val_loss: 0.3405 - val_accuracy: 0.8474\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3352 - accuracy: 0.8525 - val_loss: 0.3458 - val_accuracy: 0.8464\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3427 - accuracy: 0.8498 - val_loss: 0.3452 - val_accuracy: 0.8448\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 811us/step - loss: 0.3307 - accuracy: 0.8546 - val_loss: 0.3443 - val_accuracy: 0.8458\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3364 - accuracy: 0.8513 - val_loss: 0.3471 - val_accuracy: 0.8446\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 2s 979us/step - loss: 0.3251 - accuracy: 0.8552 - val_loss: 0.3450 - val_accuracy: 0.8462\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3248 - accuracy: 0.8567 - val_loss: 0.3395 - val_accuracy: 0.8458\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3321 - accuracy: 0.8523 - val_loss: 0.3437 - val_accuracy: 0.8458\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3218 - accuracy: 0.8603 - val_loss: 0.3413 - val_accuracy: 0.8444\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 780us/step - loss: 0.3281 - accuracy: 0.8529 - val_loss: 0.3372 - val_accuracy: 0.8470\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 770us/step - loss: 0.3259 - accuracy: 0.8564 - val_loss: 0.3366 - val_accuracy: 0.8452\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3321 - accuracy: 0.8515 - val_loss: 0.3403 - val_accuracy: 0.8450\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3256 - accuracy: 0.8560 - val_loss: 0.3393 - val_accuracy: 0.8436\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 716us/step - loss: 0.3315 - accuracy: 0.8540 - val_loss: 0.3403 - val_accuracy: 0.8452\n",
      "Epoch 45/1000\n",
      "1600/1600 [==============================] - 1s 723us/step - loss: 0.3261 - accuracy: 0.8586 - val_loss: 0.3475 - val_accuracy: 0.8476\n",
      "Epoch 46/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3218 - accuracy: 0.8534 - val_loss: 0.3480 - val_accuracy: 0.8440\n",
      "Epoch 47/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3333 - accuracy: 0.8572 - val_loss: 0.3483 - val_accuracy: 0.8454\n",
      "Epoch 48/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3316 - accuracy: 0.8564 - val_loss: 0.3450 - val_accuracy: 0.8454\n",
      "Epoch 49/1000\n",
      "1600/1600 [==============================] - 1s 728us/step - loss: 0.3356 - accuracy: 0.8534 - val_loss: 0.3496 - val_accuracy: 0.8418\n",
      "Epoch 50/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3338 - accuracy: 0.8536 - val_loss: 0.3488 - val_accuracy: 0.8412\n",
      "Epoch 51/1000\n",
      "1600/1600 [==============================] - 1s 840us/step - loss: 0.3278 - accuracy: 0.8557 - val_loss: 0.3467 - val_accuracy: 0.8430\n",
      "400/400 [==============================] - 0s 720us/step - loss: 0.3261 - accuracy: 0.8610\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 762us/step - loss: 0.4660 - accuracy: 0.7811 - val_loss: 0.3744 - val_accuracy: 0.8208\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3718 - accuracy: 0.8228 - val_loss: 0.3664 - val_accuracy: 0.8288\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3622 - accuracy: 0.8315 - val_loss: 0.3631 - val_accuracy: 0.8214\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3605 - accuracy: 0.8269 - val_loss: 0.3624 - val_accuracy: 0.8260\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3591 - accuracy: 0.8329 - val_loss: 0.3535 - val_accuracy: 0.8358\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3485 - accuracy: 0.8372 - val_loss: 0.3537 - val_accuracy: 0.8384\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3469 - accuracy: 0.8426 - val_loss: 0.3546 - val_accuracy: 0.8432\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3416 - accuracy: 0.8451 - val_loss: 0.3503 - val_accuracy: 0.8376\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 698us/step - loss: 0.3423 - accuracy: 0.8470 - val_loss: 0.3462 - val_accuracy: 0.8416\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 759us/step - loss: 0.3387 - accuracy: 0.8519 - val_loss: 0.3487 - val_accuracy: 0.8390\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3355 - accuracy: 0.8492 - val_loss: 0.3462 - val_accuracy: 0.8456\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3306 - accuracy: 0.8529 - val_loss: 0.3444 - val_accuracy: 0.8392\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 880us/step - loss: 0.3254 - accuracy: 0.8546 - val_loss: 0.3405 - val_accuracy: 0.8448\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3304 - accuracy: 0.8523 - val_loss: 0.3415 - val_accuracy: 0.8454\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 907us/step - loss: 0.3341 - accuracy: 0.8505 - val_loss: 0.3406 - val_accuracy: 0.8438\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3365 - accuracy: 0.8487 - val_loss: 0.3423 - val_accuracy: 0.8430\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3353 - accuracy: 0.8447 - val_loss: 0.3399 - val_accuracy: 0.8484\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 761us/step - loss: 0.3374 - accuracy: 0.8474 - val_loss: 0.3421 - val_accuracy: 0.8466\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3290 - accuracy: 0.8562 - val_loss: 0.3440 - val_accuracy: 0.8452\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3338 - accuracy: 0.8514 - val_loss: 0.3392 - val_accuracy: 0.8452\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3315 - accuracy: 0.8515 - val_loss: 0.3408 - val_accuracy: 0.8478\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3332 - accuracy: 0.8486 - val_loss: 0.3387 - val_accuracy: 0.8466\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 929us/step - loss: 0.3300 - accuracy: 0.8537 - val_loss: 0.3382 - val_accuracy: 0.8494\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3338 - accuracy: 0.8511 - val_loss: 0.3367 - val_accuracy: 0.8480\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 873us/step - loss: 0.3310 - accuracy: 0.8520 - val_loss: 0.3442 - val_accuracy: 0.8472\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.3235 - accuracy: 0.8559 - val_loss: 0.3440 - val_accuracy: 0.8448\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3359 - accuracy: 0.8522 - val_loss: 0.3366 - val_accuracy: 0.8476\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3299 - accuracy: 0.8523 - val_loss: 0.3390 - val_accuracy: 0.8466\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3302 - accuracy: 0.8537 - val_loss: 0.3440 - val_accuracy: 0.8494\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3287 - accuracy: 0.8523 - val_loss: 0.3364 - val_accuracy: 0.8486\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3297 - accuracy: 0.8570 - val_loss: 0.3368 - val_accuracy: 0.8490\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3264 - accuracy: 0.8582 - val_loss: 0.3396 - val_accuracy: 0.8474\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 835us/step - loss: 0.3345 - accuracy: 0.8497 - val_loss: 0.3460 - val_accuracy: 0.8446\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3251 - accuracy: 0.8558 - val_loss: 0.3362 - val_accuracy: 0.8496\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3220 - accuracy: 0.8580 - val_loss: 0.3490 - val_accuracy: 0.8402\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 716us/step - loss: 0.3237 - accuracy: 0.8555 - val_loss: 0.3366 - val_accuracy: 0.8474\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3343 - accuracy: 0.8512 - val_loss: 0.3492 - val_accuracy: 0.8472\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.3279 - accuracy: 0.8565 - val_loss: 0.3421 - val_accuracy: 0.8462\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3245 - accuracy: 0.8559 - val_loss: 0.3381 - val_accuracy: 0.8488\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3265 - accuracy: 0.8526 - val_loss: 0.3447 - val_accuracy: 0.8496\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 2s 969us/step - loss: 0.3285 - accuracy: 0.8529 - val_loss: 0.3406 - val_accuracy: 0.8492\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3280 - accuracy: 0.8534 - val_loss: 0.3371 - val_accuracy: 0.8508\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 1s 841us/step - loss: 0.3282 - accuracy: 0.8551 - val_loss: 0.3423 - val_accuracy: 0.8434\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3270 - accuracy: 0.8556 - val_loss: 0.3406 - val_accuracy: 0.8468\n",
      "400/400 [==============================] - 0s 692us/step - loss: 0.3388 - accuracy: 0.8535\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 786us/step - loss: 0.4600 - accuracy: 0.7864 - val_loss: 0.3795 - val_accuracy: 0.8120\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 885us/step - loss: 0.3801 - accuracy: 0.8191 - val_loss: 0.3780 - val_accuracy: 0.8102\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3653 - accuracy: 0.8329 - val_loss: 0.3623 - val_accuracy: 0.8224\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3552 - accuracy: 0.8348 - val_loss: 0.3590 - val_accuracy: 0.8352\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3594 - accuracy: 0.8338 - val_loss: 0.3567 - val_accuracy: 0.8336\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 827us/step - loss: 0.3453 - accuracy: 0.8430 - val_loss: 0.3545 - val_accuracy: 0.8346\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3444 - accuracy: 0.8433 - val_loss: 0.3554 - val_accuracy: 0.8360\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 942us/step - loss: 0.3447 - accuracy: 0.8457 - val_loss: 0.3502 - val_accuracy: 0.8382\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3456 - accuracy: 0.8450 - val_loss: 0.3504 - val_accuracy: 0.8444\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.3434 - accuracy: 0.8485 - val_loss: 0.3500 - val_accuracy: 0.8404\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3407 - accuracy: 0.8474 - val_loss: 0.3457 - val_accuracy: 0.8440\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3454 - accuracy: 0.8459 - val_loss: 0.3461 - val_accuracy: 0.8442\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3281 - accuracy: 0.8529 - val_loss: 0.3411 - val_accuracy: 0.8460\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3402 - accuracy: 0.8503 - val_loss: 0.3473 - val_accuracy: 0.8466\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3320 - accuracy: 0.8520 - val_loss: 0.3430 - val_accuracy: 0.8464\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3387 - accuracy: 0.8509 - val_loss: 0.3404 - val_accuracy: 0.8484\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.3424 - accuracy: 0.8464 - val_loss: 0.3411 - val_accuracy: 0.8476\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 752us/step - loss: 0.3307 - accuracy: 0.8535 - val_loss: 0.3378 - val_accuracy: 0.8486\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3306 - accuracy: 0.8537 - val_loss: 0.3399 - val_accuracy: 0.8464\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 881us/step - loss: 0.3298 - accuracy: 0.8532 - val_loss: 0.3387 - val_accuracy: 0.8484\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3330 - accuracy: 0.8523 - val_loss: 0.3410 - val_accuracy: 0.8446\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.3377 - accuracy: 0.8469 - val_loss: 0.3425 - val_accuracy: 0.8466\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3235 - accuracy: 0.8589 - val_loss: 0.3414 - val_accuracy: 0.8458\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 872us/step - loss: 0.3255 - accuracy: 0.8548 - val_loss: 0.3432 - val_accuracy: 0.8452\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3296 - accuracy: 0.8585 - val_loss: 0.3376 - val_accuracy: 0.8468\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 865us/step - loss: 0.3337 - accuracy: 0.8557 - val_loss: 0.3400 - val_accuracy: 0.8470\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3262 - accuracy: 0.8591 - val_loss: 0.3436 - val_accuracy: 0.8484\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3293 - accuracy: 0.8547 - val_loss: 0.3418 - val_accuracy: 0.8468\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3332 - accuracy: 0.8533 - val_loss: 0.3501 - val_accuracy: 0.8454\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 794us/step - loss: 0.3244 - accuracy: 0.8560 - val_loss: 0.3399 - val_accuracy: 0.8480\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3275 - accuracy: 0.8563 - val_loss: 0.3460 - val_accuracy: 0.8490\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3274 - accuracy: 0.8579 - val_loss: 0.3437 - val_accuracy: 0.8452\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3254 - accuracy: 0.8613 - val_loss: 0.3414 - val_accuracy: 0.8456\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3266 - accuracy: 0.8584 - val_loss: 0.3416 - val_accuracy: 0.8482\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 859us/step - loss: 0.3251 - accuracy: 0.8608 - val_loss: 0.3460 - val_accuracy: 0.8460\n",
      "400/400 [==============================] - 0s 695us/step - loss: 0.3292 - accuracy: 0.8505\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 947us/step - loss: 0.4661 - accuracy: 0.7845 - val_loss: 0.3735 - val_accuracy: 0.8152\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3666 - accuracy: 0.8256 - val_loss: 0.3675 - val_accuracy: 0.8196\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 739us/step - loss: 0.3616 - accuracy: 0.8311 - val_loss: 0.3608 - val_accuracy: 0.8246\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 763us/step - loss: 0.3602 - accuracy: 0.8343 - val_loss: 0.3568 - val_accuracy: 0.8284\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3498 - accuracy: 0.8390 - val_loss: 0.3545 - val_accuracy: 0.8314\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3518 - accuracy: 0.8381 - val_loss: 0.3559 - val_accuracy: 0.8354\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3499 - accuracy: 0.8426 - val_loss: 0.3505 - val_accuracy: 0.8348\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3490 - accuracy: 0.8499 - val_loss: 0.3560 - val_accuracy: 0.8422\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3375 - accuracy: 0.8513 - val_loss: 0.3456 - val_accuracy: 0.8442\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3352 - accuracy: 0.8505 - val_loss: 0.3469 - val_accuracy: 0.8454\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 785us/step - loss: 0.3322 - accuracy: 0.8527 - val_loss: 0.3507 - val_accuracy: 0.8360\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 811us/step - loss: 0.3305 - accuracy: 0.8525 - val_loss: 0.3420 - val_accuracy: 0.8456\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3315 - accuracy: 0.8534 - val_loss: 0.3396 - val_accuracy: 0.8480\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3370 - accuracy: 0.8554 - val_loss: 0.3414 - val_accuracy: 0.8460\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3257 - accuracy: 0.8560 - val_loss: 0.3439 - val_accuracy: 0.8454\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3296 - accuracy: 0.8539 - val_loss: 0.3413 - val_accuracy: 0.8474\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3315 - accuracy: 0.8535 - val_loss: 0.3420 - val_accuracy: 0.8466\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3282 - accuracy: 0.8562 - val_loss: 0.3379 - val_accuracy: 0.8476\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 735us/step - loss: 0.3303 - accuracy: 0.8561 - val_loss: 0.3392 - val_accuracy: 0.8468\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 823us/step - loss: 0.3320 - accuracy: 0.8500 - val_loss: 0.3469 - val_accuracy: 0.8432\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3332 - accuracy: 0.8556 - val_loss: 0.3422 - val_accuracy: 0.8462\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 959us/step - loss: 0.3340 - accuracy: 0.8520 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3251 - accuracy: 0.8562 - val_loss: 0.3521 - val_accuracy: 0.8386\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3296 - accuracy: 0.8543 - val_loss: 0.3418 - val_accuracy: 0.8476\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 688us/step - loss: 0.3265 - accuracy: 0.8572 - val_loss: 0.3413 - val_accuracy: 0.8438\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3289 - accuracy: 0.8569 - val_loss: 0.3532 - val_accuracy: 0.8374\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3279 - accuracy: 0.8575 - val_loss: 0.3378 - val_accuracy: 0.8446\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 999us/step - loss: 0.3297 - accuracy: 0.8564 - val_loss: 0.3383 - val_accuracy: 0.8500\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3298 - accuracy: 0.8565 - val_loss: 0.3397 - val_accuracy: 0.8456\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 822us/step - loss: 0.3301 - accuracy: 0.8548 - val_loss: 0.3411 - val_accuracy: 0.8486\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3382 - accuracy: 0.8505 - val_loss: 0.3473 - val_accuracy: 0.8470\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3367 - accuracy: 0.8510 - val_loss: 0.3412 - val_accuracy: 0.8474\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 846us/step - loss: 0.3303 - accuracy: 0.8569 - val_loss: 0.3515 - val_accuracy: 0.8474\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 819us/step - loss: 0.3286 - accuracy: 0.8539 - val_loss: 0.3445 - val_accuracy: 0.8440\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3305 - accuracy: 0.8530 - val_loss: 0.3415 - val_accuracy: 0.8456\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3285 - accuracy: 0.8558 - val_loss: 0.3491 - val_accuracy: 0.8464\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3273 - accuracy: 0.8570 - val_loss: 0.3383 - val_accuracy: 0.8494\n",
      "400/400 [==============================] - 0s 705us/step - loss: 0.3364 - accuracy: 0.8460\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4645 - accuracy: 0.7843 - val_loss: 0.3757 - val_accuracy: 0.8176\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3697 - accuracy: 0.8264 - val_loss: 0.3694 - val_accuracy: 0.8198\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 838us/step - loss: 0.3625 - accuracy: 0.8275 - val_loss: 0.3705 - val_accuracy: 0.8204\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3600 - accuracy: 0.8331 - val_loss: 0.3619 - val_accuracy: 0.8294\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 818us/step - loss: 0.3586 - accuracy: 0.8360 - val_loss: 0.3642 - val_accuracy: 0.8350\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3562 - accuracy: 0.8363 - val_loss: 0.3525 - val_accuracy: 0.8354\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3426 - accuracy: 0.8432 - val_loss: 0.3538 - val_accuracy: 0.8352\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3528 - accuracy: 0.8378 - val_loss: 0.3517 - val_accuracy: 0.8392\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 713us/step - loss: 0.3440 - accuracy: 0.8461 - val_loss: 0.3477 - val_accuracy: 0.8424\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3379 - accuracy: 0.8497 - val_loss: 0.3457 - val_accuracy: 0.8416\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3417 - accuracy: 0.8453 - val_loss: 0.3406 - val_accuracy: 0.8468\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3373 - accuracy: 0.8499 - val_loss: 0.3386 - val_accuracy: 0.8476\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 994us/step - loss: 0.3383 - accuracy: 0.8519 - val_loss: 0.3395 - val_accuracy: 0.8480\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3327 - accuracy: 0.8523 - val_loss: 0.3431 - val_accuracy: 0.8474\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3303 - accuracy: 0.8512 - val_loss: 0.3410 - val_accuracy: 0.8484\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 792us/step - loss: 0.3327 - accuracy: 0.8508 - val_loss: 0.3391 - val_accuracy: 0.8484\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3448 - accuracy: 0.8423 - val_loss: 0.3386 - val_accuracy: 0.8496\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 748us/step - loss: 0.3338 - accuracy: 0.8537 - val_loss: 0.3401 - val_accuracy: 0.8484\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 957us/step - loss: 0.3361 - accuracy: 0.8487 - val_loss: 0.3435 - val_accuracy: 0.8466\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3312 - accuracy: 0.8531 - val_loss: 0.3424 - val_accuracy: 0.8510\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3336 - accuracy: 0.8543 - val_loss: 0.3377 - val_accuracy: 0.8480\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3288 - accuracy: 0.8507 - val_loss: 0.3382 - val_accuracy: 0.8518\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 736us/step - loss: 0.3355 - accuracy: 0.8473 - val_loss: 0.3502 - val_accuracy: 0.8400\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3340 - accuracy: 0.8496 - val_loss: 0.3424 - val_accuracy: 0.8476\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3271 - accuracy: 0.8589 - val_loss: 0.3403 - val_accuracy: 0.8498\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3319 - accuracy: 0.8531 - val_loss: 0.3442 - val_accuracy: 0.8478\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 891us/step - loss: 0.3380 - accuracy: 0.8500 - val_loss: 0.3368 - val_accuracy: 0.8530\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3280 - accuracy: 0.8566 - val_loss: 0.3408 - val_accuracy: 0.8486\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3228 - accuracy: 0.8592 - val_loss: 0.3384 - val_accuracy: 0.8450\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3301 - accuracy: 0.8543 - val_loss: 0.3454 - val_accuracy: 0.8496\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 708us/step - loss: 0.3248 - accuracy: 0.8564 - val_loss: 0.3381 - val_accuracy: 0.8506\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 801us/step - loss: 0.3266 - accuracy: 0.8542 - val_loss: 0.3442 - val_accuracy: 0.8504\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3292 - accuracy: 0.8554 - val_loss: 0.3407 - val_accuracy: 0.8486\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 2s 999us/step - loss: 0.3298 - accuracy: 0.8517 - val_loss: 0.3411 - val_accuracy: 0.8482\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3271 - accuracy: 0.8544 - val_loss: 0.3390 - val_accuracy: 0.8526\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 1s 843us/step - loss: 0.3266 - accuracy: 0.8555 - val_loss: 0.3424 - val_accuracy: 0.8496\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3245 - accuracy: 0.8596 - val_loss: 0.3443 - val_accuracy: 0.8480\n",
      "400/400 [==============================] - 0s 677us/step - loss: 0.3312 - accuracy: 0.8515\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 812us/step - loss: 0.4634 - accuracy: 0.7890 - val_loss: 0.3739 - val_accuracy: 0.8218\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3695 - accuracy: 0.8248 - val_loss: 0.3719 - val_accuracy: 0.8160\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 810us/step - loss: 0.3685 - accuracy: 0.8275 - val_loss: 0.3652 - val_accuracy: 0.8356\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 764us/step - loss: 0.3599 - accuracy: 0.8325 - val_loss: 0.3556 - val_accuracy: 0.8332\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 941us/step - loss: 0.3573 - accuracy: 0.8330 - val_loss: 0.3670 - val_accuracy: 0.8342\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3561 - accuracy: 0.8357 - val_loss: 0.3511 - val_accuracy: 0.8380\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 930us/step - loss: 0.3492 - accuracy: 0.8426 - val_loss: 0.3500 - val_accuracy: 0.8408\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 728us/step - loss: 0.3468 - accuracy: 0.8458 - val_loss: 0.3456 - val_accuracy: 0.8418\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3367 - accuracy: 0.8499 - val_loss: 0.3439 - val_accuracy: 0.8418\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 742us/step - loss: 0.3460 - accuracy: 0.8460 - val_loss: 0.3435 - val_accuracy: 0.8448\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3432 - accuracy: 0.8476 - val_loss: 0.3439 - val_accuracy: 0.8486\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 892us/step - loss: 0.3352 - accuracy: 0.8495 - val_loss: 0.3401 - val_accuracy: 0.8470\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3405 - accuracy: 0.8460 - val_loss: 0.3436 - val_accuracy: 0.8424\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3343 - accuracy: 0.8513 - val_loss: 0.3400 - val_accuracy: 0.8484\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3355 - accuracy: 0.8518 - val_loss: 0.3396 - val_accuracy: 0.8476\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 735us/step - loss: 0.3378 - accuracy: 0.8471 - val_loss: 0.3441 - val_accuracy: 0.8454\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3400 - accuracy: 0.8497 - val_loss: 0.3490 - val_accuracy: 0.8474\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3349 - accuracy: 0.8482 - val_loss: 0.3429 - val_accuracy: 0.8468\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3366 - accuracy: 0.8474 - val_loss: 0.3394 - val_accuracy: 0.8460\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 937us/step - loss: 0.3268 - accuracy: 0.8569 - val_loss: 0.3388 - val_accuracy: 0.8496\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3385 - accuracy: 0.8508 - val_loss: 0.3378 - val_accuracy: 0.8486\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3286 - accuracy: 0.8568 - val_loss: 0.3421 - val_accuracy: 0.8498\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3312 - accuracy: 0.8540 - val_loss: 0.3394 - val_accuracy: 0.8490\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3286 - accuracy: 0.8507 - val_loss: 0.3363 - val_accuracy: 0.8502\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 743us/step - loss: 0.3268 - accuracy: 0.8568 - val_loss: 0.3391 - val_accuracy: 0.8512\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 843us/step - loss: 0.3258 - accuracy: 0.8536 - val_loss: 0.3405 - val_accuracy: 0.8492\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3301 - accuracy: 0.8512 - val_loss: 0.3479 - val_accuracy: 0.8500\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3308 - accuracy: 0.8537 - val_loss: 0.3421 - val_accuracy: 0.8506\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3369 - accuracy: 0.8475 - val_loss: 0.3394 - val_accuracy: 0.8496\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3296 - accuracy: 0.8543 - val_loss: 0.3375 - val_accuracy: 0.8502\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3247 - accuracy: 0.8555 - val_loss: 0.3386 - val_accuracy: 0.8488\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3368 - accuracy: 0.8457 - val_loss: 0.3415 - val_accuracy: 0.8472\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3295 - accuracy: 0.8539 - val_loss: 0.3408 - val_accuracy: 0.8498\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 765us/step - loss: 0.3301 - accuracy: 0.8504 - val_loss: 0.3396 - val_accuracy: 0.8486\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3275 - accuracy: 0.8547\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 3s 1ms/step - loss: 0.4592 - accuracy: 0.7807 - val_loss: 0.3791 - val_accuracy: 0.8190\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 740us/step - loss: 0.3720 - accuracy: 0.8257 - val_loss: 0.3725 - val_accuracy: 0.8198\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3685 - accuracy: 0.8294 - val_loss: 0.3699 - val_accuracy: 0.8320\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3551 - accuracy: 0.8427 - val_loss: 0.3626 - val_accuracy: 0.8348\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 728us/step - loss: 0.3573 - accuracy: 0.8422 - val_loss: 0.3575 - val_accuracy: 0.8426\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3586 - accuracy: 0.8404 - val_loss: 0.3578 - val_accuracy: 0.8418\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 795us/step - loss: 0.3617 - accuracy: 0.8408 - val_loss: 0.3550 - val_accuracy: 0.8428\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3520 - accuracy: 0.8466 - val_loss: 0.3540 - val_accuracy: 0.8436\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3556 - accuracy: 0.8440 - val_loss: 0.3553 - val_accuracy: 0.8448\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3474 - accuracy: 0.8470 - val_loss: 0.3563 - val_accuracy: 0.8462\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 903us/step - loss: 0.3372 - accuracy: 0.8541 - val_loss: 0.3525 - val_accuracy: 0.8428\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3411 - accuracy: 0.8500 - val_loss: 0.3536 - val_accuracy: 0.8476\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 716us/step - loss: 0.3423 - accuracy: 0.8497 - val_loss: 0.3489 - val_accuracy: 0.8470\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3323 - accuracy: 0.8538 - val_loss: 0.3524 - val_accuracy: 0.8486\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.3302 - accuracy: 0.8559 - val_loss: 0.3525 - val_accuracy: 0.8432\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3395 - accuracy: 0.8526 - val_loss: 0.3668 - val_accuracy: 0.8412\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3409 - accuracy: 0.8506 - val_loss: 0.3511 - val_accuracy: 0.8466\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 752us/step - loss: 0.3370 - accuracy: 0.8518 - val_loss: 0.3521 - val_accuracy: 0.8462\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3365 - accuracy: 0.8530 - val_loss: 0.3538 - val_accuracy: 0.8444\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3290 - accuracy: 0.8607 - val_loss: 0.3502 - val_accuracy: 0.8428\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3464 - accuracy: 0.8523 - val_loss: 0.3512 - val_accuracy: 0.8434\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3413 - accuracy: 0.8553 - val_loss: 0.3500 - val_accuracy: 0.8446\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3325 - accuracy: 0.8612 - val_loss: 0.3550 - val_accuracy: 0.8440\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3494 - accuracy: 0.8505\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 810us/step - loss: 0.4564 - accuracy: 0.7916 - val_loss: 0.3777 - val_accuracy: 0.8204\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3713 - accuracy: 0.8255 - val_loss: 0.3635 - val_accuracy: 0.8252\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3523 - accuracy: 0.8400 - val_loss: 0.3574 - val_accuracy: 0.8268\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3604 - accuracy: 0.8369 - val_loss: 0.3572 - val_accuracy: 0.8412\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 992us/step - loss: 0.3533 - accuracy: 0.8385 - val_loss: 0.3530 - val_accuracy: 0.8388\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3508 - accuracy: 0.8421 - val_loss: 0.3483 - val_accuracy: 0.8440\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 910us/step - loss: 0.3449 - accuracy: 0.8455 - val_loss: 0.3439 - val_accuracy: 0.8440\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3413 - accuracy: 0.8467 - val_loss: 0.3444 - val_accuracy: 0.8414\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3443 - accuracy: 0.8426 - val_loss: 0.3421 - val_accuracy: 0.8460\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3337 - accuracy: 0.8524 - val_loss: 0.3470 - val_accuracy: 0.8472\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3295 - accuracy: 0.8523 - val_loss: 0.3463 - val_accuracy: 0.8392\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 889us/step - loss: 0.3362 - accuracy: 0.8486 - val_loss: 0.3440 - val_accuracy: 0.8444\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3360 - accuracy: 0.8513 - val_loss: 0.3397 - val_accuracy: 0.8422\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3374 - accuracy: 0.8483 - val_loss: 0.3411 - val_accuracy: 0.8480\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3271 - accuracy: 0.8528 - val_loss: 0.3413 - val_accuracy: 0.8422\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3279 - accuracy: 0.8527 - val_loss: 0.3423 - val_accuracy: 0.8432\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3256 - accuracy: 0.8547 - val_loss: 0.3383 - val_accuracy: 0.8494\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3346 - accuracy: 0.8504 - val_loss: 0.3399 - val_accuracy: 0.8484\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 940us/step - loss: 0.3363 - accuracy: 0.8510 - val_loss: 0.3369 - val_accuracy: 0.8444\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3335 - accuracy: 0.8532 - val_loss: 0.3438 - val_accuracy: 0.8468\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 830us/step - loss: 0.3397 - accuracy: 0.8481 - val_loss: 0.3469 - val_accuracy: 0.8442\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3367 - accuracy: 0.8516 - val_loss: 0.3436 - val_accuracy: 0.8458\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3323 - accuracy: 0.8534 - val_loss: 0.3489 - val_accuracy: 0.8426\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3339 - accuracy: 0.8526 - val_loss: 0.3446 - val_accuracy: 0.8456\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 815us/step - loss: 0.3329 - accuracy: 0.8514 - val_loss: 0.3429 - val_accuracy: 0.8470\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3370 - accuracy: 0.8518 - val_loss: 0.3439 - val_accuracy: 0.8468\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3288 - accuracy: 0.8546 - val_loss: 0.3540 - val_accuracy: 0.8440\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3273 - accuracy: 0.8539 - val_loss: 0.3447 - val_accuracy: 0.8444\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 801us/step - loss: 0.3342 - accuracy: 0.8525 - val_loss: 0.3408 - val_accuracy: 0.8434\n",
      "400/400 [==============================] - 0s 702us/step - loss: 0.3344 - accuracy: 0.8495\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 836us/step - loss: 0.4469 - accuracy: 0.7922 - val_loss: 0.3811 - val_accuracy: 0.8142\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 713us/step - loss: 0.3683 - accuracy: 0.8305 - val_loss: 0.3649 - val_accuracy: 0.8252\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3614 - accuracy: 0.8366 - val_loss: 0.3656 - val_accuracy: 0.8270\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3600 - accuracy: 0.8395 - val_loss: 0.3577 - val_accuracy: 0.8384\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 973us/step - loss: 0.3548 - accuracy: 0.8453 - val_loss: 0.3596 - val_accuracy: 0.8392\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3513 - accuracy: 0.8443 - val_loss: 0.3565 - val_accuracy: 0.8388\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 833us/step - loss: 0.3467 - accuracy: 0.8453 - val_loss: 0.3532 - val_accuracy: 0.8454\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3457 - accuracy: 0.8500 - val_loss: 0.3548 - val_accuracy: 0.8428\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3429 - accuracy: 0.8528 - val_loss: 0.3482 - val_accuracy: 0.8462\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 714us/step - loss: 0.3429 - accuracy: 0.8518 - val_loss: 0.3503 - val_accuracy: 0.8466\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3401 - accuracy: 0.8507 - val_loss: 0.3455 - val_accuracy: 0.8462\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3348 - accuracy: 0.8541 - val_loss: 0.3511 - val_accuracy: 0.8454\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 985us/step - loss: 0.3307 - accuracy: 0.8584 - val_loss: 0.3468 - val_accuracy: 0.8438\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3354 - accuracy: 0.8543 - val_loss: 0.3461 - val_accuracy: 0.8458\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3414 - accuracy: 0.8529 - val_loss: 0.3468 - val_accuracy: 0.8448\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 762us/step - loss: 0.3407 - accuracy: 0.8527 - val_loss: 0.3444 - val_accuracy: 0.8442\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 730us/step - loss: 0.3340 - accuracy: 0.8551 - val_loss: 0.3420 - val_accuracy: 0.8440\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3337 - accuracy: 0.8531 - val_loss: 0.3459 - val_accuracy: 0.8478\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3360 - accuracy: 0.8549 - val_loss: 0.3525 - val_accuracy: 0.8430\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 949us/step - loss: 0.3352 - accuracy: 0.8547 - val_loss: 0.3475 - val_accuracy: 0.8436\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3309 - accuracy: 0.8552 - val_loss: 0.3485 - val_accuracy: 0.8464\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3364 - accuracy: 0.8544 - val_loss: 0.3486 - val_accuracy: 0.8448\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3309 - accuracy: 0.8574 - val_loss: 0.3460 - val_accuracy: 0.8458\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3400 - accuracy: 0.8529 - val_loss: 0.3498 - val_accuracy: 0.8468\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3329 - accuracy: 0.8567 - val_loss: 0.3501 - val_accuracy: 0.8468\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 816us/step - loss: 0.3258 - accuracy: 0.8594 - val_loss: 0.3474 - val_accuracy: 0.8468\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3209 - accuracy: 0.8626 - val_loss: 0.3470 - val_accuracy: 0.8452\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3456 - accuracy: 0.8428\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 777us/step - loss: 0.4583 - accuracy: 0.7834 - val_loss: 0.3762 - val_accuracy: 0.8102\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3720 - accuracy: 0.8222 - val_loss: 0.3647 - val_accuracy: 0.8244\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3617 - accuracy: 0.8288 - val_loss: 0.3642 - val_accuracy: 0.8320\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.3580 - accuracy: 0.8331 - val_loss: 0.3631 - val_accuracy: 0.8224\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.3546 - accuracy: 0.8335 - val_loss: 0.3637 - val_accuracy: 0.8414\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3572 - accuracy: 0.8369 - val_loss: 0.3597 - val_accuracy: 0.8412\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3418 - accuracy: 0.8492 - val_loss: 0.3447 - val_accuracy: 0.8424\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 914us/step - loss: 0.3414 - accuracy: 0.8474 - val_loss: 0.3451 - val_accuracy: 0.8446\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3381 - accuracy: 0.8520 - val_loss: 0.3469 - val_accuracy: 0.8422\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 816us/step - loss: 0.3344 - accuracy: 0.8488 - val_loss: 0.3416 - val_accuracy: 0.8470\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 693us/step - loss: 0.3334 - accuracy: 0.8535 - val_loss: 0.3402 - val_accuracy: 0.8476\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3350 - accuracy: 0.8505 - val_loss: 0.3442 - val_accuracy: 0.8424\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 768us/step - loss: 0.3379 - accuracy: 0.8479 - val_loss: 0.3407 - val_accuracy: 0.8470\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.3223 - accuracy: 0.8573 - val_loss: 0.3402 - val_accuracy: 0.8486\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 734us/step - loss: 0.3409 - accuracy: 0.8460 - val_loss: 0.3414 - val_accuracy: 0.8462\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 817us/step - loss: 0.3295 - accuracy: 0.8553 - val_loss: 0.3387 - val_accuracy: 0.8454\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3261 - accuracy: 0.8539 - val_loss: 0.3415 - val_accuracy: 0.8482\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 2s 983us/step - loss: 0.3336 - accuracy: 0.8512 - val_loss: 0.3397 - val_accuracy: 0.8454\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 696us/step - loss: 0.3302 - accuracy: 0.8536 - val_loss: 0.3399 - val_accuracy: 0.8458\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 747us/step - loss: 0.3306 - accuracy: 0.8493 - val_loss: 0.3427 - val_accuracy: 0.8500\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 722us/step - loss: 0.3272 - accuracy: 0.8580 - val_loss: 0.3405 - val_accuracy: 0.8492\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3319 - accuracy: 0.8534 - val_loss: 0.3399 - val_accuracy: 0.8466\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 737us/step - loss: 0.3366 - accuracy: 0.8499 - val_loss: 0.3456 - val_accuracy: 0.8490\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 893us/step - loss: 0.3292 - accuracy: 0.8531 - val_loss: 0.3416 - val_accuracy: 0.8486\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3358 - accuracy: 0.8488 - val_loss: 0.3369 - val_accuracy: 0.8500\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 925us/step - loss: 0.3304 - accuracy: 0.8553 - val_loss: 0.3449 - val_accuracy: 0.8410\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 761us/step - loss: 0.3327 - accuracy: 0.8530 - val_loss: 0.3410 - val_accuracy: 0.8494\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 800us/step - loss: 0.3285 - accuracy: 0.8555 - val_loss: 0.3396 - val_accuracy: 0.8498\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3372 - accuracy: 0.8461 - val_loss: 0.3391 - val_accuracy: 0.8500\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3333 - accuracy: 0.8496 - val_loss: 0.3390 - val_accuracy: 0.8502\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3319 - accuracy: 0.8569 - val_loss: 0.3376 - val_accuracy: 0.8494\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3317 - accuracy: 0.8541 - val_loss: 0.3472 - val_accuracy: 0.8504\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3234 - accuracy: 0.8605 - val_loss: 0.3375 - val_accuracy: 0.8506\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3300 - accuracy: 0.8537 - val_loss: 0.3364 - val_accuracy: 0.8524\n",
      "Epoch 35/1000\n",
      "1600/1600 [==============================] - 2s 971us/step - loss: 0.3256 - accuracy: 0.8549 - val_loss: 0.3388 - val_accuracy: 0.8492\n",
      "Epoch 36/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3240 - accuracy: 0.8598 - val_loss: 0.3505 - val_accuracy: 0.8506\n",
      "Epoch 37/1000\n",
      "1600/1600 [==============================] - 1s 803us/step - loss: 0.3345 - accuracy: 0.8534 - val_loss: 0.3454 - val_accuracy: 0.8504\n",
      "Epoch 38/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3332 - accuracy: 0.8546 - val_loss: 0.3450 - val_accuracy: 0.8494\n",
      "Epoch 39/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3312 - accuracy: 0.8576 - val_loss: 0.3466 - val_accuracy: 0.8456\n",
      "Epoch 40/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3225 - accuracy: 0.8575 - val_loss: 0.3450 - val_accuracy: 0.8494\n",
      "Epoch 41/1000\n",
      "1600/1600 [==============================] - 1s 728us/step - loss: 0.3257 - accuracy: 0.8554 - val_loss: 0.3445 - val_accuracy: 0.8520\n",
      "Epoch 42/1000\n",
      "1600/1600 [==============================] - 1s 852us/step - loss: 0.3304 - accuracy: 0.8555 - val_loss: 0.3426 - val_accuracy: 0.8520\n",
      "Epoch 43/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3273 - accuracy: 0.8567 - val_loss: 0.3411 - val_accuracy: 0.8508\n",
      "Epoch 44/1000\n",
      "1600/1600 [==============================] - 1s 886us/step - loss: 0.3266 - accuracy: 0.8565 - val_loss: 0.3406 - val_accuracy: 0.8546\n",
      "400/400 [==============================] - 0s 802us/step - loss: 0.3293 - accuracy: 0.8522\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 761us/step - loss: 0.4538 - accuracy: 0.7906 - val_loss: 0.3774 - val_accuracy: 0.8150\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 767us/step - loss: 0.3770 - accuracy: 0.8263 - val_loss: 0.3642 - val_accuracy: 0.8234\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 2s 985us/step - loss: 0.3572 - accuracy: 0.8314 - val_loss: 0.3588 - val_accuracy: 0.8300\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3546 - accuracy: 0.8353 - val_loss: 0.3555 - val_accuracy: 0.8348\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 725us/step - loss: 0.3483 - accuracy: 0.8435 - val_loss: 0.3545 - val_accuracy: 0.8390\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 684us/step - loss: 0.3539 - accuracy: 0.8382 - val_loss: 0.3488 - val_accuracy: 0.8430\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 686us/step - loss: 0.3463 - accuracy: 0.8402 - val_loss: 0.3445 - val_accuracy: 0.8434\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 726us/step - loss: 0.3472 - accuracy: 0.8426 - val_loss: 0.3459 - val_accuracy: 0.8460\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3403 - accuracy: 0.8465 - val_loss: 0.3420 - val_accuracy: 0.8466\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 697us/step - loss: 0.3424 - accuracy: 0.8464 - val_loss: 0.3389 - val_accuracy: 0.8444\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 712us/step - loss: 0.3405 - accuracy: 0.8439 - val_loss: 0.3383 - val_accuracy: 0.8472\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 741us/step - loss: 0.3355 - accuracy: 0.8496 - val_loss: 0.3440 - val_accuracy: 0.8414\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3356 - accuracy: 0.8504 - val_loss: 0.3412 - val_accuracy: 0.8434\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3409 - accuracy: 0.8481 - val_loss: 0.3454 - val_accuracy: 0.8466\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3354 - accuracy: 0.8479 - val_loss: 0.3392 - val_accuracy: 0.8452\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3363 - accuracy: 0.8506 - val_loss: 0.3488 - val_accuracy: 0.8444\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 692us/step - loss: 0.3410 - accuracy: 0.8494 - val_loss: 0.3400 - val_accuracy: 0.8452\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 699us/step - loss: 0.3304 - accuracy: 0.8528 - val_loss: 0.3409 - val_accuracy: 0.8452\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 755us/step - loss: 0.3248 - accuracy: 0.8588 - val_loss: 0.3387 - val_accuracy: 0.8456\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 693us/step - loss: 0.3291 - accuracy: 0.8522 - val_loss: 0.3511 - val_accuracy: 0.8478\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 850us/step - loss: 0.3342 - accuracy: 0.8503 - val_loss: 0.3468 - val_accuracy: 0.8480\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3282 - accuracy: 0.8547\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4523 - accuracy: 0.7912 - val_loss: 0.3800 - val_accuracy: 0.8120\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 871us/step - loss: 0.3727 - accuracy: 0.8224 - val_loss: 0.3723 - val_accuracy: 0.8162\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 805us/step - loss: 0.3575 - accuracy: 0.8354 - val_loss: 0.3553 - val_accuracy: 0.8418\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3461 - accuracy: 0.8461 - val_loss: 0.3563 - val_accuracy: 0.8408\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3502 - accuracy: 0.8452 - val_loss: 0.3507 - val_accuracy: 0.8450\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 1s 685us/step - loss: 0.3473 - accuracy: 0.8454 - val_loss: 0.3582 - val_accuracy: 0.8406\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 700us/step - loss: 0.3473 - accuracy: 0.8463 - val_loss: 0.3596 - val_accuracy: 0.8374\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 690us/step - loss: 0.3436 - accuracy: 0.8497 - val_loss: 0.3518 - val_accuracy: 0.8394\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3406 - accuracy: 0.8481 - val_loss: 0.3502 - val_accuracy: 0.8444\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3410 - accuracy: 0.8472 - val_loss: 0.3458 - val_accuracy: 0.8468\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3408 - accuracy: 0.8488 - val_loss: 0.3491 - val_accuracy: 0.8452\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 790us/step - loss: 0.3409 - accuracy: 0.8468 - val_loss: 0.3497 - val_accuracy: 0.8456\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 750us/step - loss: 0.3361 - accuracy: 0.8518 - val_loss: 0.3455 - val_accuracy: 0.8448\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3358 - accuracy: 0.8509 - val_loss: 0.3503 - val_accuracy: 0.8426\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 703us/step - loss: 0.3411 - accuracy: 0.8490 - val_loss: 0.3454 - val_accuracy: 0.8456\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 707us/step - loss: 0.3373 - accuracy: 0.8503 - val_loss: 0.3564 - val_accuracy: 0.8426\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3327 - accuracy: 0.8541 - val_loss: 0.3633 - val_accuracy: 0.8354\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 761us/step - loss: 0.3299 - accuracy: 0.8571 - val_loss: 0.3563 - val_accuracy: 0.8408\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3301 - accuracy: 0.8578 - val_loss: 0.3458 - val_accuracy: 0.8472\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3386 - accuracy: 0.8500 - val_loss: 0.3481 - val_accuracy: 0.8458\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 702us/step - loss: 0.3290 - accuracy: 0.8563 - val_loss: 0.3494 - val_accuracy: 0.8452\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3317 - accuracy: 0.8572 - val_loss: 0.3485 - val_accuracy: 0.8458\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 753us/step - loss: 0.3319 - accuracy: 0.8537 - val_loss: 0.3537 - val_accuracy: 0.8438\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 2s 965us/step - loss: 0.3417 - accuracy: 0.8496 - val_loss: 0.3548 - val_accuracy: 0.8434\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3274 - accuracy: 0.8586 - val_loss: 0.3478 - val_accuracy: 0.8428\n",
      "400/400 [==============================] - 0s 712us/step - loss: 0.3472 - accuracy: 0.8515\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 765us/step - loss: 0.4619 - accuracy: 0.7827 - val_loss: 0.3763 - val_accuracy: 0.8212\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3756 - accuracy: 0.8280 - val_loss: 0.3646 - val_accuracy: 0.8346\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3632 - accuracy: 0.8385 - val_loss: 0.3651 - val_accuracy: 0.8366\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3566 - accuracy: 0.8403 - val_loss: 0.3591 - val_accuracy: 0.8374\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 1s 905us/step - loss: 0.3590 - accuracy: 0.8397 - val_loss: 0.3575 - val_accuracy: 0.8416\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3577 - accuracy: 0.8403 - val_loss: 0.3583 - val_accuracy: 0.8416\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 883us/step - loss: 0.3561 - accuracy: 0.8405 - val_loss: 0.3608 - val_accuracy: 0.8426\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 695us/step - loss: 0.3536 - accuracy: 0.8444 - val_loss: 0.3591 - val_accuracy: 0.8428\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3537 - accuracy: 0.8465 - val_loss: 0.3558 - val_accuracy: 0.8436\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 776us/step - loss: 0.3540 - accuracy: 0.8411 - val_loss: 0.3598 - val_accuracy: 0.8412\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 751us/step - loss: 0.3553 - accuracy: 0.8457 - val_loss: 0.3503 - val_accuracy: 0.8416\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 715us/step - loss: 0.3480 - accuracy: 0.8455 - val_loss: 0.3508 - val_accuracy: 0.8444\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 862us/step - loss: 0.3462 - accuracy: 0.8499 - val_loss: 0.3483 - val_accuracy: 0.8462\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3492 - accuracy: 0.8461 - val_loss: 0.3531 - val_accuracy: 0.8410\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 2s 960us/step - loss: 0.3471 - accuracy: 0.8491 - val_loss: 0.3477 - val_accuracy: 0.8460\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3439 - accuracy: 0.8506 - val_loss: 0.3553 - val_accuracy: 0.8438\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 1s 711us/step - loss: 0.3387 - accuracy: 0.8534 - val_loss: 0.3570 - val_accuracy: 0.8430\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 709us/step - loss: 0.3366 - accuracy: 0.8554 - val_loss: 0.3486 - val_accuracy: 0.8464\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 724us/step - loss: 0.3353 - accuracy: 0.8559 - val_loss: 0.3675 - val_accuracy: 0.8424\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 911us/step - loss: 0.3400 - accuracy: 0.8520 - val_loss: 0.3507 - val_accuracy: 0.8454\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 727us/step - loss: 0.3390 - accuracy: 0.8547 - val_loss: 0.3536 - val_accuracy: 0.8432\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 701us/step - loss: 0.3400 - accuracy: 0.8571 - val_loss: 0.3528 - val_accuracy: 0.8424\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.3386 - accuracy: 0.8581 - val_loss: 0.3474 - val_accuracy: 0.8482\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 704us/step - loss: 0.3352 - accuracy: 0.8575 - val_loss: 0.3465 - val_accuracy: 0.8472\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 843us/step - loss: 0.3389 - accuracy: 0.8529 - val_loss: 0.3544 - val_accuracy: 0.8462\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 1s 812us/step - loss: 0.3326 - accuracy: 0.8595 - val_loss: 0.3507 - val_accuracy: 0.8442\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 1s 785us/step - loss: 0.3312 - accuracy: 0.8560 - val_loss: 0.3551 - val_accuracy: 0.8452\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 861us/step - loss: 0.3361 - accuracy: 0.8592 - val_loss: 0.3559 - val_accuracy: 0.8394\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3351 - accuracy: 0.8593 - val_loss: 0.3497 - val_accuracy: 0.8486\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 2s 957us/step - loss: 0.3401 - accuracy: 0.8544 - val_loss: 0.3527 - val_accuracy: 0.8458\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 717us/step - loss: 0.3365 - accuracy: 0.8551 - val_loss: 0.3486 - val_accuracy: 0.8504\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3389 - accuracy: 0.8589 - val_loss: 0.3598 - val_accuracy: 0.8482\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3391 - accuracy: 0.8559 - val_loss: 0.3564 - val_accuracy: 0.8456\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 1s 713us/step - loss: 0.3356 - accuracy: 0.8586 - val_loss: 0.3581 - val_accuracy: 0.8430\n",
      "400/400 [==============================] - 0s 705us/step - loss: 0.3415 - accuracy: 0.8508\n",
      "Epoch 1/1000\n",
      "1600/1600 [==============================] - 2s 847us/step - loss: 0.4528 - accuracy: 0.7797 - val_loss: 0.3801 - val_accuracy: 0.8210\n",
      "Epoch 2/1000\n",
      "1600/1600 [==============================] - 1s 759us/step - loss: 0.3745 - accuracy: 0.8282 - val_loss: 0.3700 - val_accuracy: 0.8238\n",
      "Epoch 3/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3639 - accuracy: 0.8365 - val_loss: 0.3627 - val_accuracy: 0.8362\n",
      "Epoch 4/1000\n",
      "1600/1600 [==============================] - 1s 803us/step - loss: 0.3612 - accuracy: 0.8385 - val_loss: 0.3810 - val_accuracy: 0.8352\n",
      "Epoch 5/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3573 - accuracy: 0.8437 - val_loss: 0.3628 - val_accuracy: 0.8370\n",
      "Epoch 6/1000\n",
      "1600/1600 [==============================] - 2s 942us/step - loss: 0.3493 - accuracy: 0.8472 - val_loss: 0.3618 - val_accuracy: 0.8406\n",
      "Epoch 7/1000\n",
      "1600/1600 [==============================] - 1s 710us/step - loss: 0.3602 - accuracy: 0.8418 - val_loss: 0.3611 - val_accuracy: 0.8408\n",
      "Epoch 8/1000\n",
      "1600/1600 [==============================] - 1s 736us/step - loss: 0.3506 - accuracy: 0.8484 - val_loss: 0.3588 - val_accuracy: 0.8414\n",
      "Epoch 9/1000\n",
      "1600/1600 [==============================] - 1s 780us/step - loss: 0.3509 - accuracy: 0.8486 - val_loss: 0.3587 - val_accuracy: 0.8414\n",
      "Epoch 10/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3517 - accuracy: 0.8460 - val_loss: 0.3703 - val_accuracy: 0.8390\n",
      "Epoch 11/1000\n",
      "1600/1600 [==============================] - 1s 838us/step - loss: 0.3505 - accuracy: 0.8454 - val_loss: 0.3574 - val_accuracy: 0.8446\n",
      "Epoch 12/1000\n",
      "1600/1600 [==============================] - 1s 738us/step - loss: 0.3546 - accuracy: 0.8488 - val_loss: 0.3669 - val_accuracy: 0.8412\n",
      "Epoch 13/1000\n",
      "1600/1600 [==============================] - 1s 723us/step - loss: 0.3488 - accuracy: 0.8497 - val_loss: 0.3546 - val_accuracy: 0.8456\n",
      "Epoch 14/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3439 - accuracy: 0.8545 - val_loss: 0.3583 - val_accuracy: 0.8440\n",
      "Epoch 15/1000\n",
      "1600/1600 [==============================] - 1s 862us/step - loss: 0.3428 - accuracy: 0.8501 - val_loss: 0.3600 - val_accuracy: 0.8438\n",
      "Epoch 16/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3530 - accuracy: 0.8487 - val_loss: 0.3642 - val_accuracy: 0.8450\n",
      "Epoch 17/1000\n",
      "1600/1600 [==============================] - 2s 950us/step - loss: 0.3393 - accuracy: 0.8545 - val_loss: 0.3536 - val_accuracy: 0.8458\n",
      "Epoch 18/1000\n",
      "1600/1600 [==============================] - 1s 705us/step - loss: 0.3478 - accuracy: 0.8452 - val_loss: 0.3576 - val_accuracy: 0.8456\n",
      "Epoch 19/1000\n",
      "1600/1600 [==============================] - 1s 733us/step - loss: 0.3373 - accuracy: 0.8604 - val_loss: 0.3540 - val_accuracy: 0.8422\n",
      "Epoch 20/1000\n",
      "1600/1600 [==============================] - 1s 706us/step - loss: 0.3372 - accuracy: 0.8555 - val_loss: 0.3560 - val_accuracy: 0.8454\n",
      "Epoch 21/1000\n",
      "1600/1600 [==============================] - 1s 728us/step - loss: 0.3417 - accuracy: 0.8494 - val_loss: 0.3573 - val_accuracy: 0.8392\n",
      "Epoch 22/1000\n",
      "1600/1600 [==============================] - 1s 732us/step - loss: 0.3365 - accuracy: 0.8567 - val_loss: 0.3626 - val_accuracy: 0.8454\n",
      "Epoch 23/1000\n",
      "1600/1600 [==============================] - 1s 758us/step - loss: 0.3321 - accuracy: 0.8601 - val_loss: 0.3585 - val_accuracy: 0.8428\n",
      "Epoch 24/1000\n",
      "1600/1600 [==============================] - 1s 729us/step - loss: 0.3322 - accuracy: 0.8628 - val_loss: 0.3525 - val_accuracy: 0.8474\n",
      "Epoch 25/1000\n",
      "1600/1600 [==============================] - 1s 803us/step - loss: 0.3365 - accuracy: 0.8554 - val_loss: 0.3812 - val_accuracy: 0.8464\n",
      "Epoch 26/1000\n",
      "1600/1600 [==============================] - 2s 969us/step - loss: 0.3423 - accuracy: 0.8559 - val_loss: 0.3562 - val_accuracy: 0.8430\n",
      "Epoch 27/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3367 - accuracy: 0.8568 - val_loss: 0.3601 - val_accuracy: 0.8422\n",
      "Epoch 28/1000\n",
      "1600/1600 [==============================] - 1s 811us/step - loss: 0.3362 - accuracy: 0.8605 - val_loss: 0.3559 - val_accuracy: 0.8388\n",
      "Epoch 29/1000\n",
      "1600/1600 [==============================] - 1s 720us/step - loss: 0.3326 - accuracy: 0.8609 - val_loss: 0.3545 - val_accuracy: 0.8428\n",
      "Epoch 30/1000\n",
      "1600/1600 [==============================] - 1s 718us/step - loss: 0.3275 - accuracy: 0.8616 - val_loss: 0.3550 - val_accuracy: 0.8438\n",
      "Epoch 31/1000\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.3337 - accuracy: 0.8621 - val_loss: 0.3571 - val_accuracy: 0.8464\n",
      "Epoch 32/1000\n",
      "1600/1600 [==============================] - 1s 756us/step - loss: 0.3376 - accuracy: 0.8541 - val_loss: 0.3586 - val_accuracy: 0.8432\n",
      "Epoch 33/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3363 - accuracy: 0.8610 - val_loss: 0.3526 - val_accuracy: 0.8444\n",
      "Epoch 34/1000\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3355 - accuracy: 0.8553 - val_loss: 0.3614 - val_accuracy: 0.8462\n",
      "400/400 [==============================] - 0s 910us/step - loss: 0.3599 - accuracy: 0.8380\n",
      "Epoch 1/1000\n",
      "2000/2000 [==============================] - 2s 753us/step - loss: 0.4643 - accuracy: 0.7807 - val_loss: 0.3807 - val_accuracy: 0.8210\n",
      "Epoch 2/1000\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.3772 - accuracy: 0.8236 - val_loss: 0.3804 - val_accuracy: 0.8324\n",
      "Epoch 3/1000\n",
      "2000/2000 [==============================] - 1s 705us/step - loss: 0.3661 - accuracy: 0.8328 - val_loss: 0.3750 - val_accuracy: 0.8356\n",
      "Epoch 4/1000\n",
      "2000/2000 [==============================] - 1s 698us/step - loss: 0.3661 - accuracy: 0.8346 - val_loss: 0.3609 - val_accuracy: 0.8350\n",
      "Epoch 5/1000\n",
      "2000/2000 [==============================] - 2s 790us/step - loss: 0.3633 - accuracy: 0.8358 - val_loss: 0.3585 - val_accuracy: 0.8392\n",
      "Epoch 6/1000\n",
      "2000/2000 [==============================] - 2s 766us/step - loss: 0.3597 - accuracy: 0.8389 - val_loss: 0.3587 - val_accuracy: 0.8422\n",
      "Epoch 7/1000\n",
      "2000/2000 [==============================] - 2s 764us/step - loss: 0.3621 - accuracy: 0.8393 - val_loss: 0.3569 - val_accuracy: 0.8422\n",
      "Epoch 8/1000\n",
      "2000/2000 [==============================] - 1s 687us/step - loss: 0.3549 - accuracy: 0.8419 - val_loss: 0.3564 - val_accuracy: 0.8402\n",
      "Epoch 9/1000\n",
      "2000/2000 [==============================] - 1s 694us/step - loss: 0.3465 - accuracy: 0.8491 - val_loss: 0.3551 - val_accuracy: 0.8390\n",
      "Epoch 10/1000\n",
      "2000/2000 [==============================] - 2s 817us/step - loss: 0.3482 - accuracy: 0.8465 - val_loss: 0.3624 - val_accuracy: 0.8328\n",
      "Epoch 11/1000\n",
      "2000/2000 [==============================] - 1s 711us/step - loss: 0.3451 - accuracy: 0.8459 - val_loss: 0.3495 - val_accuracy: 0.8434\n",
      "Epoch 12/1000\n",
      "2000/2000 [==============================] - 1s 719us/step - loss: 0.3391 - accuracy: 0.8534 - val_loss: 0.3517 - val_accuracy: 0.8426\n",
      "Epoch 13/1000\n",
      "2000/2000 [==============================] - 2s 829us/step - loss: 0.3433 - accuracy: 0.8475 - val_loss: 0.3526 - val_accuracy: 0.8406\n",
      "Epoch 14/1000\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.3378 - accuracy: 0.8530 - val_loss: 0.3511 - val_accuracy: 0.8466\n",
      "Epoch 15/1000\n",
      "2000/2000 [==============================] - 2s 875us/step - loss: 0.3332 - accuracy: 0.8550 - val_loss: 0.3483 - val_accuracy: 0.8450\n",
      "Epoch 16/1000\n",
      "2000/2000 [==============================] - 1s 708us/step - loss: 0.3445 - accuracy: 0.8497 - val_loss: 0.3475 - val_accuracy: 0.8492\n",
      "Epoch 17/1000\n",
      "2000/2000 [==============================] - 1s 718us/step - loss: 0.3408 - accuracy: 0.8547 - val_loss: 0.3477 - val_accuracy: 0.8458\n",
      "Epoch 18/1000\n",
      "2000/2000 [==============================] - 1s 700us/step - loss: 0.3335 - accuracy: 0.8583 - val_loss: 0.3446 - val_accuracy: 0.8494\n",
      "Epoch 19/1000\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.3356 - accuracy: 0.8576 - val_loss: 0.3506 - val_accuracy: 0.8498\n",
      "Epoch 20/1000\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.3382 - accuracy: 0.8584 - val_loss: 0.3588 - val_accuracy: 0.8426\n",
      "Epoch 21/1000\n",
      "2000/2000 [==============================] - 1s 695us/step - loss: 0.3386 - accuracy: 0.8528 - val_loss: 0.3518 - val_accuracy: 0.8496\n",
      "Epoch 22/1000\n",
      "2000/2000 [==============================] - 1s 694us/step - loss: 0.3395 - accuracy: 0.8548 - val_loss: 0.3462 - val_accuracy: 0.8504\n",
      "Epoch 23/1000\n",
      "2000/2000 [==============================] - 1s 720us/step - loss: 0.3449 - accuracy: 0.8516 - val_loss: 0.3538 - val_accuracy: 0.8482\n",
      "Epoch 24/1000\n",
      "2000/2000 [==============================] - 1s 747us/step - loss: 0.3374 - accuracy: 0.8556 - val_loss: 0.3504 - val_accuracy: 0.8480\n",
      "Epoch 25/1000\n",
      "2000/2000 [==============================] - 1s 693us/step - loss: 0.3366 - accuracy: 0.8565 - val_loss: 0.3571 - val_accuracy: 0.8476\n",
      "Epoch 26/1000\n",
      "2000/2000 [==============================] - 2s 768us/step - loss: 0.3374 - accuracy: 0.8555 - val_loss: 0.3504 - val_accuracy: 0.8450\n",
      "Epoch 27/1000\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.3391 - accuracy: 0.8555 - val_loss: 0.3516 - val_accuracy: 0.8464\n",
      "Epoch 28/1000\n",
      "2000/2000 [==============================] - 2s 863us/step - loss: 0.3375 - accuracy: 0.8542 - val_loss: 0.3478 - val_accuracy: 0.8494\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = ModelCheckpoint(\"Checkpoints/ANN_1000ep_ES_CV.h5\")\n",
    "early_stopping_cb = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 10, restore_best_weights=True)\n",
    "\n",
    "param_grid = {\"n_hidden\": [1, 2],\n",
    "              \"neurons\": [10, 15, 20, 25, 30]}\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs = 1000, batch_size = 10, verbose = 1)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X_train, y_train, epochs=1000, batch_size = 10, verbose=1,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.852800 using {'n_hidden': 2, 'neurons': 20}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan (nan) with {'n_hidden': 1, 'neurons': 10}\n",
      "0.848450 (0.004670) with {'n_hidden': 1, 'neurons': 15}\n",
      "0.846600 (0.008143) with {'n_hidden': 1, 'neurons': 20}\n",
      "nan (nan) with {'n_hidden': 1, 'neurons': 25}\n",
      "0.850200 (0.004354) with {'n_hidden': 1, 'neurons': 30}\n",
      "0.846500 (0.007048) with {'n_hidden': 2, 'neurons': 10}\n",
      "0.849750 (0.006405) with {'n_hidden': 2, 'neurons': 15}\n",
      "0.852800 (0.004885) with {'n_hidden': 2, 'neurons': 20}\n",
      "0.849800 (0.003941) with {'n_hidden': 2, 'neurons': 25}\n",
      "0.849450 (0.005881) with {'n_hidden': 2, 'neurons': 30}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2000/2000 [==============================] - 2s 837us/step - loss: 0.4520 - accuracy: 0.7861 - val_loss: 0.3745 - val_accuracy: 0.8168\n",
      "Epoch 2/1000\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.3716 - accuracy: 0.8245 - val_loss: 0.3637 - val_accuracy: 0.8282\n",
      "Epoch 3/1000\n",
      "2000/2000 [==============================] - 2s 992us/step - loss: 0.3600 - accuracy: 0.8329 - val_loss: 0.3618 - val_accuracy: 0.8342\n",
      "Epoch 4/1000\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.3634 - accuracy: 0.8299 - val_loss: 0.3572 - val_accuracy: 0.8320\n",
      "Epoch 5/1000\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.3500 - accuracy: 0.8414 - val_loss: 0.3586 - val_accuracy: 0.8382\n",
      "Epoch 6/1000\n",
      "2000/2000 [==============================] - 2s 791us/step - loss: 0.3543 - accuracy: 0.8371 - val_loss: 0.3543 - val_accuracy: 0.8332\n",
      "Epoch 7/1000\n",
      "2000/2000 [==============================] - 2s 922us/step - loss: 0.3550 - accuracy: 0.8354 - val_loss: 0.3484 - val_accuracy: 0.8392\n",
      "Epoch 8/1000\n",
      "2000/2000 [==============================] - 2s 832us/step - loss: 0.3449 - accuracy: 0.8456 - val_loss: 0.3510 - val_accuracy: 0.8436\n",
      "Epoch 9/1000\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.3454 - accuracy: 0.8442 - val_loss: 0.3480 - val_accuracy: 0.8390\n",
      "Epoch 10/1000\n",
      "2000/2000 [==============================] - 2s 942us/step - loss: 0.3408 - accuracy: 0.8446 - val_loss: 0.3446 - val_accuracy: 0.8428\n",
      "Epoch 11/1000\n",
      "2000/2000 [==============================] - 2s 892us/step - loss: 0.3366 - accuracy: 0.8499 - val_loss: 0.3483 - val_accuracy: 0.8456\n",
      "Epoch 12/1000\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.3388 - accuracy: 0.8489 - val_loss: 0.3436 - val_accuracy: 0.8456\n",
      "Epoch 13/1000\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.3278 - accuracy: 0.8561 - val_loss: 0.3392 - val_accuracy: 0.8462\n",
      "Epoch 14/1000\n",
      "2000/2000 [==============================] - 1s 699us/step - loss: 0.3329 - accuracy: 0.8507 - val_loss: 0.3389 - val_accuracy: 0.8448\n",
      "Epoch 15/1000\n",
      "2000/2000 [==============================] - 1s 702us/step - loss: 0.3298 - accuracy: 0.8532 - val_loss: 0.3388 - val_accuracy: 0.8468\n",
      "Epoch 16/1000\n",
      "2000/2000 [==============================] - 1s 700us/step - loss: 0.3323 - accuracy: 0.8535 - val_loss: 0.3441 - val_accuracy: 0.8442\n",
      "Epoch 17/1000\n",
      "2000/2000 [==============================] - 2s 900us/step - loss: 0.3342 - accuracy: 0.8506 - val_loss: 0.3386 - val_accuracy: 0.8496\n",
      "Epoch 18/1000\n",
      "2000/2000 [==============================] - 1s 681us/step - loss: 0.3378 - accuracy: 0.8480 - val_loss: 0.3457 - val_accuracy: 0.8462\n",
      "Epoch 19/1000\n",
      "2000/2000 [==============================] - 1s 690us/step - loss: 0.3328 - accuracy: 0.8484 - val_loss: 0.3407 - val_accuracy: 0.8482\n",
      "Epoch 20/1000\n",
      "2000/2000 [==============================] - 1s 708us/step - loss: 0.3365 - accuracy: 0.8514 - val_loss: 0.3462 - val_accuracy: 0.8488\n",
      "Epoch 21/1000\n",
      "2000/2000 [==============================] - 1s 681us/step - loss: 0.3347 - accuracy: 0.8527 - val_loss: 0.3476 - val_accuracy: 0.8464\n",
      "Epoch 22/1000\n",
      "2000/2000 [==============================] - 2s 758us/step - loss: 0.3293 - accuracy: 0.8535 - val_loss: 0.3437 - val_accuracy: 0.8476\n",
      "Epoch 23/1000\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.3363 - accuracy: 0.8526 - val_loss: 0.3428 - val_accuracy: 0.8458\n",
      "Epoch 24/1000\n",
      "2000/2000 [==============================] - 2s 863us/step - loss: 0.3260 - accuracy: 0.8568 - val_loss: 0.3382 - val_accuracy: 0.8514\n",
      "Epoch 25/1000\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.3299 - accuracy: 0.8544 - val_loss: 0.3395 - val_accuracy: 0.8504\n",
      "Epoch 26/1000\n",
      "2000/2000 [==============================] - 2s 941us/step - loss: 0.3381 - accuracy: 0.8469 - val_loss: 0.3521 - val_accuracy: 0.8508\n",
      "Epoch 27/1000\n",
      "2000/2000 [==============================] - 2s 773us/step - loss: 0.3288 - accuracy: 0.8552 - val_loss: 0.3395 - val_accuracy: 0.8516\n",
      "Epoch 28/1000\n",
      "2000/2000 [==============================] - 2s 886us/step - loss: 0.3397 - accuracy: 0.8505 - val_loss: 0.3463 - val_accuracy: 0.8498\n",
      "Epoch 29/1000\n",
      "2000/2000 [==============================] - 1s 714us/step - loss: 0.3312 - accuracy: 0.8520 - val_loss: 0.3402 - val_accuracy: 0.8490\n",
      "Epoch 30/1000\n",
      "2000/2000 [==============================] - 2s 785us/step - loss: 0.3303 - accuracy: 0.8569 - val_loss: 0.3401 - val_accuracy: 0.8494\n",
      "Epoch 31/1000\n",
      "2000/2000 [==============================] - 1s 717us/step - loss: 0.3300 - accuracy: 0.8547 - val_loss: 0.3417 - val_accuracy: 0.8476\n",
      "Epoch 32/1000\n",
      "2000/2000 [==============================] - 1s 723us/step - loss: 0.3311 - accuracy: 0.8556 - val_loss: 0.3432 - val_accuracy: 0.8506\n",
      "Epoch 33/1000\n",
      "2000/2000 [==============================] - 2s 806us/step - loss: 0.3258 - accuracy: 0.8554 - val_loss: 0.3411 - val_accuracy: 0.8490\n",
      "Epoch 34/1000\n",
      "2000/2000 [==============================] - 1s 745us/step - loss: 0.3331 - accuracy: 0.8522 - val_loss: 0.3415 - val_accuracy: 0.8478\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 10, restore_best_weights=True)\n",
    "\n",
    "final_model = create_model(n_hidden=2, neurons=20, activation=\"relu\")\n",
    "\n",
    "history2 = final_model.fit(X_train, y_train, epochs=1000, batch_size = 10, verbose=1,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb])\n",
    "\n",
    "final_model.save(\"Models/ANN_2HLyr_20neurons_10BS_1000ep_ES10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 783us/step - loss: 0.3382 - accuracy: 0.8514\n",
      "Accuracy: 85.14%\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = final_model.evaluate(X_valid, y_valid)\n",
    "print('Accuracy: %.2f' % (accuracy*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history2.history['loss']\n",
    "val_loss = history2.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss)+1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label = 'Trainning loss')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.4430 - accuracy: 0.7939 - val_loss: 0.3688 - val_accuracy: 0.8230\n",
      "Epoch 2/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3688 - accuracy: 0.8247 - val_loss: 0.3650 - val_accuracy: 0.8327\n",
      "Epoch 3/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3728 - accuracy: 0.8244 - val_loss: 0.3552 - val_accuracy: 0.8323\n",
      "Epoch 4/1000\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.3589 - accuracy: 0.8348 - val_loss: 0.3514 - val_accuracy: 0.8387\n",
      "Epoch 5/1000\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.3587 - accuracy: 0.8352 - val_loss: 0.3484 - val_accuracy: 0.8411\n",
      "Epoch 6/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3512 - accuracy: 0.8404 - val_loss: 0.3417 - val_accuracy: 0.8455\n",
      "Epoch 7/1000\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.3438 - accuracy: 0.8479 - val_loss: 0.3399 - val_accuracy: 0.8471\n",
      "Epoch 8/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3407 - accuracy: 0.8448 - val_loss: 0.3361 - val_accuracy: 0.8486\n",
      "Epoch 9/1000\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.3346 - accuracy: 0.8490 - val_loss: 0.3324 - val_accuracy: 0.8502\n",
      "Epoch 10/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3363 - accuracy: 0.8493 - val_loss: 0.3344 - val_accuracy: 0.8488\n",
      "Epoch 11/1000\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.3271 - accuracy: 0.8529 - val_loss: 0.3349 - val_accuracy: 0.8490\n",
      "Epoch 12/1000\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.3357 - accuracy: 0.8505 - val_loss: 0.3315 - val_accuracy: 0.8501\n",
      "Epoch 13/1000\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.3331 - accuracy: 0.8518 - val_loss: 0.3314 - val_accuracy: 0.8501\n",
      "Epoch 14/1000\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.3311 - accuracy: 0.8536 - val_loss: 0.3366 - val_accuracy: 0.8486\n",
      "Epoch 15/1000\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.3445 - accuracy: 0.8460 - val_loss: 0.3317 - val_accuracy: 0.8498\n",
      "Epoch 16/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3295 - accuracy: 0.8538 - val_loss: 0.3435 - val_accuracy: 0.8487\n",
      "Epoch 17/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3327 - accuracy: 0.8532 - val_loss: 0.3350 - val_accuracy: 0.8513\n",
      "Epoch 18/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3336 - accuracy: 0.8516 - val_loss: 0.3425 - val_accuracy: 0.8519\n",
      "Epoch 19/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3315 - accuracy: 0.8525 - val_loss: 0.3308 - val_accuracy: 0.8519\n",
      "Epoch 20/1000\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.3372 - accuracy: 0.8506 - val_loss: 0.3387 - val_accuracy: 0.8509\n",
      "Epoch 21/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3306 - accuracy: 0.8542 - val_loss: 0.3288 - val_accuracy: 0.8530\n",
      "Epoch 22/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3282 - accuracy: 0.8524 - val_loss: 0.3294 - val_accuracy: 0.8518\n",
      "Epoch 23/1000\n",
      "2500/2500 [==============================] - 2s 975us/step - loss: 0.3326 - accuracy: 0.8523 - val_loss: 0.3291 - val_accuracy: 0.8543\n",
      "Epoch 24/1000\n",
      "2500/2500 [==============================] - 2s 977us/step - loss: 0.3248 - accuracy: 0.8573 - val_loss: 0.3293 - val_accuracy: 0.8514\n",
      "Epoch 25/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3321 - accuracy: 0.8514 - val_loss: 0.3344 - val_accuracy: 0.8542\n",
      "Epoch 26/1000\n",
      "2500/2500 [==============================] - 2s 998us/step - loss: 0.3258 - accuracy: 0.8560 - val_loss: 0.3307 - val_accuracy: 0.8554\n",
      "Epoch 27/1000\n",
      "2500/2500 [==============================] - 2s 987us/step - loss: 0.3303 - accuracy: 0.8536 - val_loss: 0.3283 - val_accuracy: 0.8545\n",
      "Epoch 28/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3329 - accuracy: 0.8538 - val_loss: 0.3279 - val_accuracy: 0.8552\n",
      "Epoch 29/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3383 - accuracy: 0.8521 - val_loss: 0.3285 - val_accuracy: 0.8538\n",
      "Epoch 30/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3349 - accuracy: 0.8494 - val_loss: 0.3306 - val_accuracy: 0.8519\n",
      "Epoch 31/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3315 - accuracy: 0.8554 - val_loss: 0.3271 - val_accuracy: 0.8544\n",
      "Epoch 32/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3338 - accuracy: 0.8548 - val_loss: 0.3291 - val_accuracy: 0.8535\n",
      "Epoch 33/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3309 - accuracy: 0.8553 - val_loss: 0.3561 - val_accuracy: 0.8544\n",
      "Epoch 34/1000\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.3260 - accuracy: 0.8531 - val_loss: 0.3306 - val_accuracy: 0.8544\n",
      "Epoch 35/1000\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.3259 - accuracy: 0.8559 - val_loss: 0.3409 - val_accuracy: 0.8530\n",
      "Epoch 36/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3286 - accuracy: 0.8560 - val_loss: 0.3273 - val_accuracy: 0.8549\n",
      "Epoch 37/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3336 - accuracy: 0.8528 - val_loss: 0.3288 - val_accuracy: 0.8548\n",
      "Epoch 38/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3364 - accuracy: 0.8518 - val_loss: 0.3314 - val_accuracy: 0.8534\n",
      "Epoch 39/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3327 - accuracy: 0.8550 - val_loss: 0.3308 - val_accuracy: 0.8532\n",
      "Epoch 40/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3306 - accuracy: 0.8554 - val_loss: 0.3323 - val_accuracy: 0.8534\n",
      "Epoch 41/1000\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3316 - accuracy: 0.8547 - val_loss: 0.3273 - val_accuracy: 0.8554\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 10, restore_best_weights=True)\n",
    "\n",
    "final_model = create_model(n_hidden=2, neurons=20, activation=\"relu\")\n",
    "\n",
    "history2 = final_model.fit(X, y, epochs=1000, batch_size = 10, verbose=1,\n",
    "                   validation_data = (X, y),\n",
    "                   callbacks = [early_stopping_cb])\n",
    "\n",
    "final_model.save(\"final_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['native-country'] = np.where(test_data[\"native-country\"]==\"United-States\", \"US\", \"others\")\n",
    "\n",
    "# drop \"education\" as it's repetitive with \"education_num\"\n",
    "test_data = test_data.drop([\"education\"], axis = 1)\n",
    "\n",
    "# number encoding on categorical variables\n",
    "cat_cols = [\"workclass\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\"]\n",
    "test_data = pd.get_dummies(data=test_data, columns=cat_cols)\n",
    "\n",
    "test_data = test_data.drop([\"workclass_?\", \"marital-status_Divorced\", \"occupation_?\", \"relationship_Husband\", \n",
    "                  \"race_Other\", \"sex_Female\", \"native-country_others\"], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"scaler.pkl\", \"rb\") as infile:\n",
    "    scaler = pkl.load(infile)\n",
    "    test_data_X_scaled = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_model = load_model(\"final_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17e1797d370>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = (final_model.predict(test_data_X_scaled) > 0.5).astype(\"int8\").astype(\"object\").flatten()\n",
    "\n",
    "sns.countplot(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(r'4predictions.txt', predictions, fmt=\"%s\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"final_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 46 columns):\n",
      " #   Column                                Non-Null Count  Dtype\n",
      "---  ------                                --------------  -----\n",
      " 0   age                                   25000 non-null  int64\n",
      " 1   demogweight                           25000 non-null  int64\n",
      " 2   education-num                         25000 non-null  int64\n",
      " 3   capital-gain                          25000 non-null  int64\n",
      " 4   capital-loss                          25000 non-null  int64\n",
      " 5   hours-per-week                        25000 non-null  int64\n",
      " 6   income                                25000 non-null  int32\n",
      " 7   workclass_Federal-gov                 25000 non-null  uint8\n",
      " 8   workclass_Local-gov                   25000 non-null  uint8\n",
      " 9   workclass_Never-worked                25000 non-null  uint8\n",
      " 10  workclass_Private                     25000 non-null  uint8\n",
      " 11  workclass_Self-emp-inc                25000 non-null  uint8\n",
      " 12  workclass_Self-emp-not-inc            25000 non-null  uint8\n",
      " 13  workclass_State-gov                   25000 non-null  uint8\n",
      " 14  workclass_Without-pay                 25000 non-null  uint8\n",
      " 15  marital-status_Married-AF-spouse      25000 non-null  uint8\n",
      " 16  marital-status_Married-civ-spouse     25000 non-null  uint8\n",
      " 17  marital-status_Married-spouse-absent  25000 non-null  uint8\n",
      " 18  marital-status_Never-married          25000 non-null  uint8\n",
      " 19  marital-status_Separated              25000 non-null  uint8\n",
      " 20  marital-status_Widowed                25000 non-null  uint8\n",
      " 21  occupation_Adm-clerical               25000 non-null  uint8\n",
      " 22  occupation_Armed-Forces               25000 non-null  uint8\n",
      " 23  occupation_Craft-repair               25000 non-null  uint8\n",
      " 24  occupation_Exec-managerial            25000 non-null  uint8\n",
      " 25  occupation_Farming-fishing            25000 non-null  uint8\n",
      " 26  occupation_Handlers-cleaners          25000 non-null  uint8\n",
      " 27  occupation_Machine-op-inspct          25000 non-null  uint8\n",
      " 28  occupation_Other-service              25000 non-null  uint8\n",
      " 29  occupation_Priv-house-serv            25000 non-null  uint8\n",
      " 30  occupation_Prof-specialty             25000 non-null  uint8\n",
      " 31  occupation_Protective-serv            25000 non-null  uint8\n",
      " 32  occupation_Sales                      25000 non-null  uint8\n",
      " 33  occupation_Tech-support               25000 non-null  uint8\n",
      " 34  occupation_Transport-moving           25000 non-null  uint8\n",
      " 35  relationship_Not-in-family            25000 non-null  uint8\n",
      " 36  relationship_Other-relative           25000 non-null  uint8\n",
      " 37  relationship_Own-child                25000 non-null  uint8\n",
      " 38  relationship_Unmarried                25000 non-null  uint8\n",
      " 39  relationship_Wife                     25000 non-null  uint8\n",
      " 40  race_Amer-Indian-Eskimo               25000 non-null  uint8\n",
      " 41  race_Asian-Pac-Islander               25000 non-null  uint8\n",
      " 42  race_Black                            25000 non-null  uint8\n",
      " 43  race_White                            25000 non-null  uint8\n",
      " 44  sex_Male                              25000 non-null  uint8\n",
      " 45  native-country_US                     25000 non-null  uint8\n",
      "dtypes: int32(1), int64(6), uint8(39)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>0.345975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>0.140898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demogweight</th>\n",
       "      <td>0.124538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.114438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Importances\n",
       "capital-gain       1.000000\n",
       "capital-loss       0.345975\n",
       "hours-per-week     0.140898\n",
       "demogweight        0.124538\n",
       "age                0.114438"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Feature Importance:\n",
    "Features = np.identity(X_train.shape[1], dtype = float) \n",
    "Features = Features[[0,1,3,4,5]] # only the variables (\"age\", \"demogweight\", \"capital-gain\", \"capital-loss\", \"hours-per-week\") are numeric\n",
    "Importance = model.predict(Features)\n",
    "Feature_names = np.asarray(['age', 'demogweight', 'capital-gain', 'capital-loss', 'hours-per-week'])\n",
    "FeatureImportance = pd.DataFrame(Importance, Feature_names)\n",
    "FeatureImportance.columns = ['Importances']\n",
    "FeatureImportance = FeatureImportance.sort_values(by='Importances', ascending=False)\n",
    "FeatureImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_most = data[['capital-gain','income']]\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x_most.values)\n",
    "x_most = pd.DataFrame(x_scaled, columns=x_most.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Subsetting\n",
    "subset1 = x_most[x_most['income'] == 1]\n",
    "subset0 = x_most[x_most['income'] == 0]\n",
    "\n",
    "input_data = [np.asarray(subset1).flatten(),np.asarray(subset0).flatten()]\n",
    "weight1 = np.ones(len(input_data[0])) / len(input_data[0])\n",
    "weight2 = np.ones(len(input_data[1])) / len(input_data[1])\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(np.asarray(subset1).flatten(), weights = weight1, alpha=0.7, label='income > 50K')\n",
    "plt.hist(np.asarray(subset0).flatten(), weights = weight2, alpha=0.7, label='income <= 50K')\n",
    "plt.legend(prop={'size': 10})\n",
    "plt.title('capital-gain - income')\n",
    "plt.savefig('capital-gain - income.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_least = data[['age', 'income']]\n",
    "x_scaled = min_max_scaler.fit_transform(x_least.values)\n",
    "x_least = pd.DataFrame(x_scaled, columns=x_least.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting\n",
    "subset1 = x_least[x_least['income'] == 1]\n",
    "subset0 = x_least[x_least['income'] == 0]\n",
    "\n",
    "input_data = [np.asarray(subset1).flatten(),np.asarray(subset0).flatten()]\n",
    "weight1 = np.ones(len(input_data[0])) / len(input_data[0])\n",
    "weight2 = np.ones(len(input_data[1])) / len(input_data[1])\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(np.asarray(subset1).flatten(), weights = weight1, alpha=0.7, label='income > 50K')\n",
    "plt.hist(np.asarray(subset0).flatten(), weights = weight2, alpha=0.7, label='income <= 50K')\n",
    "plt.legend(prop={'size': 10})\n",
    "plt.title('age - income')\n",
    "plt.savefig('age - income.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
